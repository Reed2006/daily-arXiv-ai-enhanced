<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 39]
- [cs.AI](#cs.AI) [Total: 17]
- [econ.EM](#econ.EM) [Total: 3]
- [econ.TH](#econ.TH) [Total: 5]
- [cs.LG](#cs.LG) [Total: 101]
- [econ.GN](#econ.GN) [Total: 5]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Entropy-Based Measurement of Value Drift and Alignment Work in Large Language Models](https://arxiv.org/abs/2512.03047)
*Samih Fadli*

Main category: cs.CL

TL;DR: 论文提出用"伦理熵"作为LLM安全性的状态变量，开发了五类行为分类器和监控系统来实时检测价值漂移，发现基础模型熵持续增长而调优模型能降低约80%的伦理熵。


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全评估主要依赖静态基准测试，但关键失效模式是动态的：分布漂移下的价值漂移、越狱攻击、部署中对齐缓慢退化。需要动态监控框架来应对这些实时风险。

Method: 基于"智能第二定律"将伦理熵作为状态变量，定义五类行为分类法，训练分类器从模型转录本估计伦理熵S(t)，在四个前沿模型的基础版和指令调优版上测量熵动态，计算有效对齐工作率gamma_eff，并嵌入监控管道。

Result: 基础模型显示持续的熵增长，而调优变体能抑制漂移并将伦理熵降低约80%。从这些轨迹中估计出有效对齐工作率，并成功将S(t)和gamma_eff嵌入到监控管道中，当熵漂移超过稳定阈值时能发出警报。

Conclusion: 伦理熵框架为LLM安全提供了可操作的动态监控方法，能够实时检测价值漂移，调优模型能显著降低伦理熵，该监控系统可实现运行时监督，提高部署安全性。

Abstract: Large language model safety is usually assessed with static benchmarks, but key failures are dynamic: value drift under distribution shift, jailbreak attacks, and slow degradation of alignment in deployment. Building on a recent Second Law of Intelligence that treats ethical entropy as a state variable which tends to increase unless countered by alignment work, we make this framework operational for large language models. We define a five-way behavioral taxonomy, train a classifier to estimate ethical entropy S(t) from model transcripts, and measure entropy dynamics for base and instruction-tuned variants of four frontier models across stress tests. Base models show sustained entropy growth, while tuned variants suppress drift and reduce ethical entropy by roughly eighty percent. From these trajectories we estimate an effective alignment work rate gamma_eff and embed S(t) and gamma_eff in a monitoring pipeline that raises alerts when entropy drift exceeds a stability threshold, enabling run-time oversight of value drift.

</details>


### [2] [Watermarks for Embeddings-as-a-Service Large Language Models](https://arxiv.org/abs/2512.03079)
*Anudeex Shetty*

Main category: cs.CL

TL;DR: 该论文研究EaaS水印防御技术，发现现有水印可通过文本复述攻击绕过，并提出新的线性变换水印方法WET来抵抗此类攻击。


<details>
  <summary>Details</summary>
Motivation: 随着企业提供嵌入即服务(EaaS)，模型面临模仿攻击风险。虽然已有水印技术保护EaaS知识产权，但现有水印存在新的安全漏洞需要解决。

Method: 首先揭示现有EaaS水印可通过文本复述攻击被绕过；然后提出WET水印技术，使用线性变换嵌入，通过反向变换和相似度比较进行验证。

Result: 研究发现文本复述能有效绕过当前最先进的EaaS水印；提出的WET方法对复述攻击具有鲁棒性，验证准确率接近完美。

Conclusion: 现有EaaS水印存在复述攻击漏洞，WET线性变换水印技术能有效防御此类攻击，为EaaS知识产权保护提供了更可靠的解决方案。

Abstract: Large Language Models (LLMs) have demonstrated exceptional capabilities in natural language understanding and generation. Based on these LLMs, businesses have started to provide Embeddings-as-a-Service (EaaS), offering feature extraction capabilities (in the form of text embeddings) that benefit downstream natural language processing tasks. However, prior research has demonstrated that EaaS is vulnerable to imitation attacks, where an attacker clones the service's model in a black-box manner without access to the model's internal workings. In response, watermarks have been added to the text embeddings to protect the intellectual property of EaaS providers by allowing them to check for model ownership. This thesis focuses on defending against imitation attacks by investigating EaaS watermarks. To achieve this goal, we unveil novel attacks and propose and validate new watermarking techniques.
  Firstly, we show that existing EaaS watermarks can be removed through paraphrasing the input text when attackers clone the model during imitation attacks. Our study illustrates that paraphrasing can effectively bypass current state-of-the-art EaaS watermarks across various attack setups (including different paraphrasing techniques and models) and datasets in most instances. This demonstrates a new vulnerability in recent EaaS watermarking techniques.
  Subsequently, as a countermeasure, we propose a novel watermarking technique, WET (Watermarking EaaS with Linear Transformation), which employs linear transformation of the embeddings. Watermark verification is conducted by applying a reverse transformation and comparing the similarity between recovered and original embeddings. We demonstrate its robustness against paraphrasing attacks with near-perfect verifiability. We conduct detailed ablation studies to assess the significance of each component and hyperparameter in WET.

</details>


### [3] [Alleviating Choice Supportive Bias in LLM with Reasoning Dependency Generation](https://arxiv.org/abs/2512.03082)
*Nan Zhuang,Wenshuo Wang,Lekai Qian,Yuxiao Wang,Boyu Cao,Qi Liu*

Main category: cs.CL

TL;DR: 提出RDG框架，通过生成平衡推理数据来减轻LLM中的选择支持性偏差，实验显示在记忆和评估任务上分别提升81.5%和94.3%


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型存在选择支持性偏差，会系统性地偏向自己选择的选项，影响AI辅助决策的客观性。现有去偏方法主要针对人口统计和社会偏见，对认知偏见的处理方法尚未探索。

Method: 提出推理依赖生成（RDG）框架，自动构建平衡的推理问答对，明确建模选择、证据和理由之间的依赖关系。生成包含上下文依赖数据和依赖解耦数据的大规模跨领域数据集，通过微调减轻选择支持性偏差。

Result: 实验表明，使用RDG生成数据微调的LLM在基于记忆的实验上提升81.5%，在基于评估的实验上提升94.3%，同时在标准BBQ基准测试上保持相似性能。

Conclusion: 该工作首次提出解决LLM中认知偏见的方法，通过RDG框架生成无偏推理数据，有助于开发更可靠的AI辅助决策支持系统。

Abstract: Recent studies have demonstrated that some Large Language Models exhibit choice-supportive bias (CSB) when performing evaluations, systematically favoring their chosen options and potentially compromising the objectivity of AI-assisted decision making. While existing debiasing approaches primarily target demographic and social biases, methods for addressing cognitive biases in LLMs remain largely unexplored. In this work, we present the first solution to address CSB through Reasoning Dependency Generation (RDG), a novel framework for generating unbiased reasoning data to mitigate choice-supportive bias through fine-tuning. RDG automatically constructs balanced reasoning QA pairs, explicitly (un)modeling the dependencies between choices, evidences, and justifications. Our approach is able to generate a large-scale dataset of QA pairs across domains, incorporating Contextual Dependency Data and Dependency Decouple Data. Experiments show that LLMs fine-tuned on RDG-generated data demonstrate a 81.5% improvement in memory-based experiments and 94.3% improvement in the evaluation-based experiment, while maintaining similar performance on standard BBQ benchmarks. This work pioneers an approach for addressing cognitive biases in LLMs and contributes to the development of more reliable AI-assisted decision support systems.

</details>


### [4] [Enhancing Job Matching: Occupation, Skill and Qualification Linking with the ESCO and EQF taxonomies](https://arxiv.org/abs/2512.03195)
*Stylianos Saroglou,Konstantinos Diamantaras,Francesco Preta,Marina Delianidi,Apostolos Benisis,Christian Johannes Meyer*

Main category: cs.CL

TL;DR: 该研究开发了开源工具，结合句子链接和实体链接方法，将职位描述文本链接到ESCO和EQF框架，并创建了评估数据集，探索大语言模型的应用。


<details>
  <summary>Details</summary>
Motivation: 研究动机是改进劳动力市场信息的分类，将职位空缺文本与欧洲技能、能力、资格和职业（ESCO）分类法以及欧洲资格框架（EQF）联系起来，以超越表面技能提取，深入分析职业和资格在职位文本中的表示。

Method: 研究比较了两种主要方法：句子链接和实体链接。开发了开源工具整合这两种方法，创建了两个专门用于评估职业和资格表示的标注数据集，并探索了生成式大语言模型在此任务中的应用。

Result: 研究结果推进了职位实体提取的技术水平，提供了用于分析数字化经济中工作、技能和劳动力市场叙事的计算基础设施。代码已公开可用。

Conclusion: 该研究通过开发开源工具和创建评估数据集，为劳动力分类和就业话语研究提供了实用基础设施，促进了语言模型在劳动力市场信息分类中的应用，有助于更深入地理解数字化经济中的工作和技能叙事。

Abstract: This study investigates the potential of language models to improve the classification of labor market information by linking job vacancy texts to two major European frameworks: the European Skills, Competences, Qualifications and Occupations (ESCO) taxonomy and the European Qualifications Framework (EQF). We examine and compare two prominent methodologies from the literature: Sentence Linking and Entity Linking. In support of ongoing research, we release an open-source tool, incorporating these two methodologies, designed to facilitate further work on labor classification and employment discourse. To move beyond surface-level skill extraction, we introduce two annotated datasets specifically aimed at evaluating how occupations and qualifications are represented within job vacancy texts. Additionally, we examine different ways to utilize generative large language models for this task. Our findings contribute to advancing the state of the art in job entity extraction and offer computational infrastructure for examining work, skills, and labor market narratives in a digitally mediated economy. Our code is made publicly available: https://github.com/tabiya-tech/tabiya-livelihoods-classifier

</details>


### [5] [InvertiTune: High-Quality Data Synthesis for Cost-Effective Single-Shot Text-to-Knowledge Graph Generation](https://arxiv.org/abs/2512.03197)
*Faezeh Faez,Marzieh S. Tahaei,Yaochen Hu,Ali Pourranjbar,Mahdi Biparva,Mark Coates,Yingxue Zhang*

Main category: cs.CL

TL;DR: InvertiTune：通过可控数据生成和监督微调，实现高效单次知识图谱构建的框架


<details>
  <summary>Details</summary>
Motivation: 现有Text2KG方法依赖迭代式LLM提示，计算成本高且容易忽略文本中分布的复杂关系，需要更高效的解决方案

Method: 结合可控数据生成管道（从知识库提取子图、噪声过滤、LLM生成文本描述）和监督微调，训练轻量级模型进行单次KG构建

Result: 在CE12k数据集上优于更大的非微调LLM和最先进的Text2KG方法，在CrossEval-1200上展示更强的跨数据集泛化能力

Conclusion: 现实、高质量的训练数据对于推进高效高性能Text2KG系统至关重要，InvertiTune框架为此提供了有效解决方案

Abstract: Large Language Models (LLMs) have revolutionized the ability to understand and generate text, enabling significant progress in automatic knowledge graph construction from text (Text2KG). Many Text2KG methods, however, rely on iterative LLM prompting, making them computationally expensive and prone to overlooking complex relations distributed throughout the text. To address these limitations, we propose InvertiTune, a framework that combines a controlled data generation pipeline with supervised fine-tuning (SFT). Within this framework, the data-generation pipeline systematically extracts subgraphs from large knowledge bases, applies noise filtering, and leverages LLMs to generate corresponding natural text descriptions, a task more aligned with LLM capabilities than direct KG generation from text. This pipeline enables generating datasets composed of longer texts paired with larger KGs that better reflect real-world scenarios compared to existing benchmarks, thus supporting effective SFT of lightweight models for single-shot KG construction. Experimental results on CE12k, a dataset generated using the introduced pipeline, show that InvertiTune outperforms larger non-fine-tuned LLMs as well as state-of-the-art Text2KG approaches, while also demonstrating stronger cross-dataset generalization on CrossEval-1200, a test set created from three established benchmark datasets and CE12k. These findings highlight the importance of realistic, high-quality training data for advancing efficient and high-performing Text2KG systems.

</details>


### [6] [Identifying attributions of causality in political text](https://arxiv.org/abs/2512.03214)
*Paulina Garcia-Corral*

Main category: cs.CL

TL;DR: 作者提出一个检测和解析政治文本中解释的框架，使用轻量级因果语言模型提取因果对，用于大规模分析政治解释。


<details>
  <summary>Details</summary>
Motivation: 解释是理解政治世界的基本要素，但政治学中缺乏系统分析解释的方法，现有方法分散且常针对特定议题。

Method: 训练轻量级因果语言模型，从政治文本中提取结构化因果对（原因-结果对），用于下游分析。

Result: 方法展示了如何大规模研究因果解释，具有适度的标注需求、良好的泛化能力和相对于人工编码的准确性。

Conclusion: 该框架为政治文本中的解释分析提供了系统方法，能够检测和解析因果解释，支持大规模政治解释研究。

Abstract: Explanations are a fundamental element of how people make sense of the political world. Citizens routinely ask and answer questions about why events happen, who is responsible, and what could or should be done differently. Yet despite their importance, explanations remain an underdeveloped object of systematic analysis in political science, and existing approaches are fragmented and often issue-specific. I introduce a framework for detecting and parsing explanations in political text. To do this, I train a lightweight causal language model that returns a structured data set of causal claims in the form of cause-effect pairs for downstream analysis. I demonstrate how causal explanations can be studied at scale, and show the method's modest annotation requirements, generalizability, and accuracy relative to human coding.

</details>


### [7] [Randomized Masked Finetuning: An Efficient Way to Mitigate Memorization of PIIs in LLMs](https://arxiv.org/abs/2512.03310)
*Kunj Joshi,David A. Smith*

Main category: cs.CL

TL;DR: 提出随机掩码微调(RMFT)技术，减少LLM对训练数据中个人身份信息(PII)的记忆，同时最小化性能影响，在Enron数据集上实现80%以上的提取率降低。


<details>
  <summary>Details</summary>
Motivation: 当前自然语言模型（特别是大语言模型）的记忆能力带来严重的安全和隐私风险，模型倾向于记忆训练数据中的个人身份信息(PII)。

Method: 提出随机掩码微调(RMFT)技术，这是一种新颖的隐私保护微调方法。同时提出MaxTER评估框架，用于评估隐私-效用权衡，并使用AURC指标比较RMFT与去重方法的性能。

Result: 在Enron邮件数据集上，RMFT相比基线微调实现了80.81%的总提取率降低和80.17%的已见提取率降低，仅增加5.73%的困惑度，优于去重方法。

Conclusion: RMFT是一种有效的隐私保护微调技术，能够显著减少LLM对PII的记忆，同时保持模型性能，为隐私-效用权衡提供了实用解决方案。

Abstract: The current literature on memorization in Natural Language Models, especially Large Language Models (LLMs), poses severe security and privacy risks, as models tend to memorize personally identifying information (PIIs) from training data. We introduce Randomized Masked Fine-Tuning (RMFT), a novel privacy-preserving fine-tuning technique that reduces PII memorization while minimizing performance impact. Using the Enron Email Dataset, we demonstrate that RMFT achieves an 80.81% reduction in Total Extraction Rate and 80.17% reduction in Seen Extraction Rate compared to baseline fine-tuning, outperforming deduplication methods while maintaining only a 5.73% increase in perplexity. We present MaxTER, a Pareto-optimal evaluation framework for assessing privacy-utility tradeoffs, and show the performance of RMFT vs Deduplication by Area Under The Response Curve (AURC) metric.

</details>


### [8] [Modeling Topics and Sociolinguistic Variation in Code-Switched Discourse: Insights from Spanish-English and Spanish-Guaraní](https://arxiv.org/abs/2512.03334)
*Nemika Tyagi,Nelvin Licona Guevara,Olga Kellert*

Main category: cs.CL

TL;DR: LLM辅助标注流水线用于西班牙语-英语和西班牙语-瓜拉尼语双语语料的社会语言学和主题分析，自动标注了3691个语码转换句子的主题、体裁和语用功能，揭示了性别、语言优势与语用功能之间的系统性关联。


<details>
  <summary>Details</summary>
Motivation: 传统社会语言学分析依赖人工标注，耗时耗力且难以扩展到大规模语料。本研究旨在利用大语言模型自动恢复传统上只能通过人工标注获得的可解释社会语言学模式，推进跨语言和低资源双语研究的计算方法。

Method: 使用大语言模型构建自动标注流水线，对西班牙语-英语（迈阿密双语语料库）和西班牙语-瓜拉尼语两种类型学不同语境下的3691个语码转换句子进行主题、体裁和语用功能标注，整合迈阿密语料库的人口统计元数据，并为西班牙语-瓜拉尼语数据集添加新的主题标注。

Result: 分析结果显示：1）迈阿密数据中性别、语言优势与语用功能存在系统性关联；2）巴拉圭文本中正式瓜拉尼语与非正式西班牙语存在明显的双语分工模式。这些发现以语料库规模的定量证据复制并扩展了早期的互动和社会语言学观察。

Conclusion: 大语言模型能够可靠地恢复传统上只能通过人工标注获得的可解释社会语言学模式，为跨语言和低资源双语研究提供了有效的计算方法，证明了计算社会语言学方法的可行性。

Abstract: This study presents an LLM-assisted annotation pipeline for the sociolinguistic and topical analysis of bilingual discourse in two typologically distinct contexts: Spanish-English and Spanish-Guaraní. Using large language models, we automatically labeled topic, genre, and discourse-pragmatic functions across a total of 3,691 code-switched sentences, integrated demographic metadata from the Miami Bilingual Corpus, and enriched the Spanish-Guaraní dataset with new topic annotations. The resulting distributions reveal systematic links between gender, language dominance, and discourse function in the Miami data, and a clear diglossic division between formal Guaraní and informal Spanish in Paraguayan texts. These findings replicate and extend earlier interactional and sociolinguistic observations with corpus-scale quantitative evidence. The study demonstrates that large language models can reliably recover interpretable sociolinguistic patterns traditionally accessible only through manual annotation, advancing computational methods for cross-linguistic and low-resource bilingual research.

</details>


### [9] [PERCS: Persona-Guided Controllable Biomedical Summarization Dataset](https://arxiv.org/abs/2512.03340)
*Rohan Charudatt Salvi,Chirag Chawla,Dhruv Jain,Swapnil Panigrahi,Md Shad Akhtar,Shweta Yadav*

Main category: cs.CL

TL;DR: PERCS数据集：包含针对四种不同医学知识水平用户（普通公众、医预科学生、非医学研究人员、医学专家）量身定制的生物医学摘要总结，支持个性化可控摘要研究。


<details>
  <summary>Details</summary>
Motivation: 现有医学文本简化资源通常假设单一通用受众，忽视了不同用户群体在医学素养和信息需求上的巨大差异。需要针对不同知识水平和信息需求的用户提供定制化的医学摘要。

Method: 创建PERCS数据集，包含生物医学摘要及其针对四种不同用户角色的总结：普通公众、医预科学生、非医学研究人员、医学专家。所有总结均由医生审核事实准确性和角色一致性，使用详细的错误分类法进行评估。

Result: 技术验证显示不同角色总结在可读性、词汇使用和内容深度上存在明显差异。使用自动评估指标对四个大型语言模型进行基准测试，评估全面性、可读性和忠实度，为未来研究建立基线结果。

Conclusion: PERCS数据集、标注指南和评估材料已公开，支持角色特定沟通和可控生物医学摘要研究，有助于提高健康素养，使复杂的生物医学研究对不同读者群体更加可及。

Abstract: Automatic medical text simplification plays a key role in improving health literacy by making complex biomedical research accessible to diverse readers. However, most existing resources assume a single generic audience, overlooking the wide variation in medical literacy and information needs across user groups. To address this limitation, we introduce PERCS (Persona-guided Controllable Summarization), a dataset of biomedical abstracts paired with summaries tailored to four personas: Laypersons, Premedical Students, Non-medical Researchers, and Medical Experts. These personas represent different levels of medical literacy and information needs, emphasizing the need for targeted, audience-specific summarization. Each summary in PERCS was reviewed by physicians for factual accuracy and persona alignment using a detailed error taxonomy. Technical validation shows clear differences in readability, vocabulary, and content depth across personas. Along with describing the dataset, we benchmark four large language models on PERCS using automatic evaluation metrics that assess comprehensiveness, readability, and faithfulness, establishing baseline results for future research. The dataset, annotation guidelines, and evaluation materials are publicly available to support research on persona-specific communication and controllable biomedical summarization.

</details>


### [10] [Idea-Gated Transformers: Enforcing Semantic Coherence via Differentiable Vocabulary Pruning](https://arxiv.org/abs/2512.03343)
*Darshan Fofadiya*

Main category: cs.CL

TL;DR: 提出Idea-Gated Transformer架构，通过分离语义规划和语法生成来解决自回归语言模型中的"主题漂移"问题，使用概念向量门控机制实时抑制语义无关的token。


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型在下一个token预测训练中容易产生"主题漂移"问题，生成内容会偏离初始提示，主要依赖局部关联而非全局规划。虽然增大模型规模可以缓解，但NTP目标的根本短视性问题仍然存在。

Method: 引入Idea-Gated Transformer架构，分离语义规划和语法生成。添加辅助的"Idea Head"来预测未来上下文窗口的词袋分布，生成潜在的"概念向量"，在生成过程中主动门控主词汇表。提出可微分门控机制，实时抑制语义无关的token，有效修剪搜索空间。

Result: 在WikiText-103上的实验表明，Idea-Gated模型在验证困惑度上与标准GPT-2基线相当，但表现出显著优越的领域保持能力。定性和定量分析显示，门控机制成功将生成锁定在特定语义簇（如金融、科学）中，并抵抗关联漂移。

Conclusion: Idea-Gated Transformer提供了一种参数高效的路径，实现更可控的语言建模，通过分离语义规划和语法生成来解决主题漂移问题，为改进语言模型的可控性提供了新思路。

Abstract: Autoregressive Language Models (LLMs) trained on Next-Token Prediction (NTP) often suffer from ``Topic Drift'' where the generation wanders away from the initial prompt due to a reliance on local associations rather than global planning \citep{holtzman2019curious}. While scaling model size mitigates this \citep{brown2020language}, the fundamental myopia of the NTP objective remains. In this work, we introduce the Idea-Gated Transformer, a novel architecture that separates semantic planning from syntactic generation. We introduce an auxiliary ``Idea Head'' trained to predict the bag-of-words distribution for a future context window, creating a latent ``Concept Vector'' that actively gates the main vocabulary during generation. We propose a differentiable gating mechanism that suppresses semantically irrelevant tokens, effectively pruning the search space in real-time. Experiments on WikiText-103 demonstrate that while the Idea-Gated model achieves comparable validation perplexity to a standard GPT-2 baseline, it exhibits significantly superior Domain Retention. Qualitative and quantitative analysis reveals that the gating mechanism successfully locks generation into specific semantic clusters (e.g., Finance, Science) and resists associative drift, offering a parameter-efficient path toward more controllable language modeling.

</details>


### [11] [From Hypothesis to Premises: LLM-based Backward Logical Reasoning with Selective Symbolic Translation](https://arxiv.org/abs/2512.03360)
*Qingchuan Li,Mingyue Cheng,Zirui Liu,Daoyu Wang,Yuting Zeng,Tongxuan Liu*

Main category: cs.CL

TL;DR: HBLR框架通过置信感知符号翻译和假设驱动的后向推理，提升逻辑推理的准确性和效率，优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型主要依赖前向推理范式，存在推理路径冗余、步骤幻觉和语义漂移等问题，导致推理效率低下且不可靠。需要更接近人类演绎思维的推理方法。

Method: 提出假设驱动的后向逻辑推理框架：1）置信感知符号翻译，仅将高置信度内容转换为一阶逻辑等形式，不确定内容保留自然语言；2）翻译反思模块评估符号输出，必要时回退到文本；3）假设结论为真，递归验证前提的后向推理；4）推理反思模块识别并修正错误推理步骤。

Result: 在五个推理基准测试上的广泛实验表明，HBLR在准确性和效率方面均持续优于强基线方法。

Conclusion: HBLR通过结合符号翻译和后向推理，模拟人类演绎思维，有效解决了前向推理的局限性，为逻辑推理提供了更可靠和高效的框架。

Abstract: Logical reasoning is a core challenge in natural language understanding and a fundamental capability of artificial intelligence, underpinning scientific discovery, mathematical theorem proving, and complex decision-making. Despite the remarkable progress of large language models (LLMs), most current approaches still rely on forward reasoning paradigms, generating step-by-step rationales from premises to conclusions. However, such methods often suffer from redundant inference paths, hallucinated steps, and semantic drift, resulting in inefficient and unreliable reasoning. In this paper, we propose a novel framework, Hypothesis-driven Backward Logical Reasoning (HBLR). The core idea is to integrate confidence-aware symbolic translation with hypothesis-driven backward reasoning. In the translation phase, only high-confidence spans are converted into logical form, such as First-Order Logic (FOL), while uncertain content remains in natural language. A translation reflection module further ensures semantic fidelity by evaluating symbolic outputs and reverting lossy ones back to text when necessary. In the reasoning phase, HBLR simulates human deductive thinking by assuming the conclusion is true and recursively verifying its premises. A reasoning reflection module further identifies and corrects flawed inference steps, enhancing logical coherence. Extensive experiments on five reasoning benchmarks demonstrate that HBLR consistently outperforms strong baselines in both accuracy and efficiency.

</details>


### [12] [Nexus: Higher-Order Attention Mechanisms in Transformers](https://arxiv.org/abs/2512.03377)
*Hanting Chen,Chu Zhong,Kai Han,Yuchuan Tian,Yuchen Liang,Tianyu Guo,Xinghao Chen,Dacheng Tao,Yunhe Wang*

Main category: cs.CL

TL;DR: 提出高阶注意力网络(Hon)，通过递归框架增强Transformer的表示能力，解决标准注意力机制的低秩瓶颈问题


<details>
  <summary>Details</summary>
Motivation: 标准Transformer的一阶注意力机制存在低秩瓶颈，难以在单层中捕捉复杂的多跳关系，限制了模型的表示能力

Method: 设计递归框架，动态精炼Query和Key表示：Query和Key向量本身是内部注意力循环的输出，允许token在最终注意力计算前聚合全局上下文并建模高阶相关性；采用参数高效的权重共享策略，确保增强表达能力的同时只增加O(1)参数

Result: 理论分析表明该方法打破了标准注意力的线性瓶颈；实证结果显示Hon在多个基准测试中优于标准Transformer

Conclusion: 高阶注意力网络通过递归框架有效增强了Transformer的表示能力，解决了标准注意力的低秩瓶颈问题，在保持参数效率的同时提升了模型性能

Abstract: Transformers have achieved significant success across various domains, relying on self-attention to capture dependencies. However, the standard first-order attention mechanism is often limited by a low-rank bottleneck, struggling to capture intricate, multi-hop relationships within a single layer. In this paper, we propose the \textbf{Higher-Order Attention Network (Hon)}, a novel architecture designed to enhance representational power through a recursive framework. Unlike standard approaches that use static linear projections for Queries and Keys, Hon dynamically refines these representations via nested self-attention mechanisms. Specifically, the Query and Key vectors are themselves outputs of inner attention loops, allowing tokens to aggregate global context and model high-order correlations \textit{prior} to the final attention computation. We enforce a parameter-efficient weight-sharing strategy across recursive steps, ensuring that this enhanced expressivity incurs $\mathcal{O}(1)$ additional parameters. We provide theoretical analysis demonstrating that our method breaks the linear bottleneck of standard attention. Empirically, Hon outperforms standard Transformers on multiple benchmarks.

</details>


### [13] [Characterizing Language Use in a Collaborative Situated Game](https://arxiv.org/abs/2512.03381)
*Nicholas Tomlin,Naitian Zhou,Eve Fleisig,Liangyuan,Chen,Téa Wright,Lauren Vinh,Laura X. Ma,Seun Eisape,Ellie French,Tingting Du,Tianjiao Zhang,Alexander Koller,Alane Suhr*

Main category: cs.CL

TL;DR: 收集了11.5小时Portal 2合作模式对话语料库，包含24.5K话语，分析复杂空间指代、澄清修复等独特语言现象，公开多模态数据支持未来研究


<details>
  <summary>Details</summary>
Motivation: 合作视频游戏产生丰富的语言数据，但现有闲聊或任务导向对话语料库缺乏复杂环境下的协调、不确定推理等语言现象

Method: 收集Portal 2合作模式中11.5小时口语对话，包含玩家视频、音频、转录、游戏状态数据，并进行手动和自动标注

Result: 构建了Portal对话语料库，识别出复杂空间指代、澄清修复、临时约定形成等独特语言现象，这些在现有语料库中罕见

Conclusion: 该语料库为研究复杂情境下协作问题解决中的语言使用提供了宝贵资源，支持未来语言分析研究

Abstract: Cooperative video games, where multiple participants must coordinate by communicating and reasoning under uncertainty in complex environments, yield a rich source of language data. We collect the Portal Dialogue Corpus: a corpus of 11.5 hours of spoken human dialogue in the co-op mode of the popular Portal 2 virtual puzzle game, comprising 24.5K total utterances. We analyze player language and behavior, identifying a number of linguistic phenomena that rarely appear in most existing chitchat or task-oriented dialogue corpora, including complex spatial reference, clarification and repair, and ad-hoc convention formation. To support future analyses of language use in complex, situated, collaborative problem-solving scenarios, we publicly release the corpus, which comprises player videos, audio, transcripts, game state data, and both manual and automatic annotations of language data.

</details>


### [14] [Dual LoRA: Enhancing LoRA with Magnitude and Direction Updates](https://arxiv.org/abs/2512.03402)
*Yixing Xu,Chao Li,Xuanwu Yin,Spandan Tiwari,Dong Li,Ashish Sirasao,Emad Barsoum*

Main category: cs.CL

TL;DR: Dual LoRA：通过将低秩矩阵分解为幅度组和方向组，并分别应用ReLU和符号函数，改进LoRA性能，在多个NLP任务上超越原始LoRA及其变体。


<details>
  <summary>Details</summary>
Motivation: LoRA作为参数高效微调方法虽然流行，但由于其低秩假设，训练出的模型性能往往不理想。需要一种方法来改进LoRA的性能，使其更好地模拟基于梯度的全参数微调过程。

Method: 提出Dual LoRA方法，将低秩矩阵分解为两个组：幅度组（控制参数是否更新及更新幅度）和方向组（决定参数更新方向）。通过为幅度组添加ReLU函数，为方向组添加符号函数，更好地模拟全参数微调的梯度优化过程。

Result: 在广泛的NLP任务上（包括自然语言生成、理解和常识推理）进行实验，使用GPT-2、RoBERTa、DeBERTa和LLaMA-1/2/3作为基线模型。结果显示，在相同可训练参数数量下，Dual LoRA始终优于原始LoRA及其最先进的变体。

Conclusion: Dual LoRA通过引入归纳偏置，将参数更新过程分解为幅度和方向两个维度，显著提升了LoRA的性能，为参数高效微调提供了更有效的解决方案。

Abstract: Low-rank adaptation (LoRA) is one of the most popular methods among parameter-efficient fine-tuning (PEFT) methods to adapt pre-trained large language models (LLMs) to specific downstream tasks. However, the model trained based on LoRA often has an unsatisfactory performance due to its low-rank assumption. In this paper, we propose a novel method called Dual LoRA to improve the performance by incorporating an inductive bias into the original LoRA. Specifically, we separate low-rank matrices into two groups: the magnitude group to control whether or not and how far we should update a parameter and the direction group to decide whether this parameter should move forward or backward, to better simulate the parameter updating process of the full fine-tuning based on gradient-based optimization algorithms. We show that this can be simply achieved by adding a ReLU function to the magnitude group and a sign function to the direction group. We conduct several experiments over a wide range of NLP tasks, including natural language generation (NLG), understanding (NLU), and commonsense reasoning datasets on GPT-2, RoBERTa, DeBERTa, and LLaMA-1/2/3 as baseline models. The results show that we consistently outperform LoRA and its state-of-the-art variants with the same number of trainable parameters.

</details>


### [15] [PretrainZero: Reinforcement Active Pretraining](https://arxiv.org/abs/2512.03442)
*Xingrun Xing,Zhiyuan Fan,Jie Lou,Guoqi Li,Jiajun Zhang,Debing Zhang*

Main category: cs.CL

TL;DR: PretrainZero：基于预训练语料的强化主动学习框架，将RL从领域特定后训练扩展到通用预训练，通过主动识别信息内容、自监督学习和验证缩放来提升基础模型的通用推理能力


<details>
  <summary>Details</summary>
Motivation: 当前基于强化学习的大思维模型虽然在某些专业领域（如软件、数学）表现出专家级能力，但仍严重依赖特定领域可验证的奖励信号，这限制了通用推理能力的扩展。需要突破验证数据壁垒，实现更通用的推理能力

Method: 提出PretrainZero框架：1）主动预训练：学习统一推理策略，主动从预训练语料中识别合理且信息丰富的内容；2）自监督学习：无需可验证标签、预训练奖励模型或监督微调，直接在通用维基百科语料上使用RL预训练推理器；3）验证缩放：通过处理越来越具挑战性的掩码跨度来增强基础模型的通用推理能力

Result: 在强化预训练中，PretrainZero将Qwen3-4B-Base在MMLU-Pro、SuperGPQA和数学平均基准上的性能分别提升了8.43、5.96和10.60分。预训练模型还可作为下游RLVR任务的推理基础模型

Conclusion: PretrainZero成功将强化学习从领域特定后训练扩展到通用预训练，通过主动学习和自监督方法突破了验证数据壁垒，显著提升了基础模型的通用推理能力，为实现更通用的人工智能提供了新途径

Abstract: Mimicking human behavior to actively learning from general experience and achieve artificial general intelligence has always been a human dream. Recent reinforcement learning (RL) based large-thinking models demonstrate impressive expert-level abilities, i.e., software and math, but still rely heavily on verifiable rewards in specific domains, placing a significant bottleneck to extend the performance boundary of general reasoning capabilities. In this work, we propose PretrainZero, a reinforcement active learning framework built on the pretraining corpus to extend RL from domain-specific post-training to general pretraining. PretrainZero features the following characteristics: 1) Active pretraining: inspired by the active learning ability of humans, PretrainZero learns a unified reasoning policy to actively identify reasonable and informative contents from pretraining corpus, and reason to predict these contents by RL. 2) Self-supervised learning: without any verifiable labels, pretrained reward models, or supervised fine-tuning, we directly pretrain reasoners from 3 to 30B base models on the general Wikipedia corpus using RL, significantly breaking the verification data-wall for general reasoning. 3) Verification scaling: by tackling increasingly challenging masked spans, PretrainZero substantially enhances the general reasoning abilities of pretrained base models. In reinforcement pretraining, PretrainZero improves Qwen3-4B-Base for 8.43, 5.96 and 10.60 on MMLU-Pro, SuperGPQA and math average benchmarks. In post-training, the pretrained models can also serve as reasoning foundation models for downstream RLVR tasks.

</details>


### [16] [A Preliminary Study on the Promises and Challenges of Native Top-$k$ Sparse Attention](https://arxiv.org/abs/2512.03494)
*Di Xiu,Hongyin Tang,Bolin Rong,Lizhi Yan,Jingang Wang,Yifan Lu,Xunliang Cai*

Main category: cs.CL

TL;DR: Top-k注意力机制在解码和训练阶段的有效性研究，通过保留与查询最相似的关键键作为上下文窗口，在保持性能的同时显著降低计算成本


<details>
  <summary>Details</summary>
Motivation: 大语言模型在长上下文建模中日益普及，但其推理计算成本已成为阻碍智能体和多模态应用发展的关键瓶颈，需要探索更高效的注意力机制

Method: 研究Top-k注意力机制在解码和训练阶段的有效性：1）验证精确Top-k解码的效果；2）探索原生Top-k注意力训练策略；3）研究近似Top-k算法精度对下游任务的影响；4）从熵的角度提供理论解释

Result: 实验表明：1）解码阶段仅保留与查询最相似的关键键能达到与完整注意力相当甚至更好的性能；2）训练与推理一致的Top-k注意力操作能进一步释放Top-k解码潜力；3）下游任务性能与近似保真度正相关；4）Top-k注意力SFT在熵减少现象验证了低熵状态更适合Top-k解码的假设

Conclusion: Top-k注意力机制能有效降低大语言模型的计算成本，同时保持或提升下游任务性能，训练与推理的一致性以及低熵状态是机制成功的关键因素

Abstract: Large Language Models (LLMs) are increasingly prevalent in the field of long-context modeling, however, their inference computational costs have become a critical bottleneck hindering the advancement of tasks such as agents and multimodal applications. This report conducts a preliminary investigation into the effectiveness and theoretical mechanisms of the Top-$k$ Attention mechanism during both the decoding and training phases. First, we validate the effectiveness of exact Top-$k$ Decoding through extensive experimentation. Experiments demonstrate that retaining only the pivotal Keys with the highest similarity to the Query as the context window during the decoding stage achieves performance comparable to, or even surpassing, full attention on downstream tasks such as HELMET and LongBench v2. Second, we further explore the native Top-$k$ Attention training strategy. Experiments confirm that ensuring the consistency between training and inference regarding Top-$k$ Attention operations facilitates the further unlocking of Top-$k$ Decoding's potential, thereby significantly enhancing model performance. Furthermore, considering the high computational complexity of exact Top-$k$ Attention, we investigate the impact of approximate Top-$k$ algorithm precision on downstream tasks. Our research confirms a positive correlation between downstream task performance and approximation fidelity, and we provide statistical evaluations of the Lightning Indexer's precision within the DeepSeek-V3.2-Exp model. Finally, this report provides a theoretical interpretation from the perspective of Entropy. Experimental observations indicate that models subjected to Top-$k$ Attention SFT exhibit a distinct phenomenon of entropy reduction in downstream tasks, which validates the hypothesis that low-entropy states are better adapted to Top-$k$ Decoding.

</details>


### [17] [Understanding LLM Reasoning for Abstractive Summarization](https://arxiv.org/abs/2512.03503)
*Haohan Yuan,Siu Cheung Hui,Haopeng Zhang*

Main category: cs.CL

TL;DR: 大型语言模型的推理能力在摘要生成中并非普遍有效，其效果高度依赖具体策略和上下文，存在摘要质量与事实忠实度的权衡


<details>
  <summary>Details</summary>
Motivation: 虽然大型语言模型在数学和代码生成等分析任务中表现出色，但其在抽象摘要生成中的实用性被广泛假设但未经验证，需要填补这一研究空白

Method: 首先将通用推理策略定制到摘要领域，然后对8种推理策略和3个大型推理模型在8个不同数据集上进行系统化、大规模的比较研究，评估摘要质量和忠实度

Result: 推理不是通用解决方案，其有效性高度依赖具体策略和上下文；观察到摘要质量与事实忠实度之间的权衡：显式推理策略倾向于提高流畅性但牺牲事实基础，而大型推理模型中的隐式推理则呈现相反模式；增加模型的内部推理预算不会改善甚至可能损害事实一致性

Conclusion: 有效的摘要生成需要忠实的压缩而非创造性的过度思考，推理在摘要任务中的应用需要谨慎考虑策略选择和上下文因素

Abstract: While the reasoning capabilities of Large Language Models (LLMs) excel in analytical tasks such as mathematics and code generation, their utility for abstractive summarization remains widely assumed but largely unverified. To bridge this gap, we first tailor general reasoning strategies to the summarization domain. We then conduct a systematic, large scale comparative study of 8 reasoning strategies and 3 Large Reasoning Models (LRMs) across 8 diverse datasets, assessing both summary quality and faithfulness. Our findings show that reasoning is not a universal solution and its effectiveness is highly dependent on the specific strategy and context. Specifically, we observe a trade-off between summary quality and factual faithfulness: explicit reasoning strategies tend to improve fluency at the expense of factual grounding, while implicit reasoning in LRMs exhibits the inverse pattern. Furthermore, increasing an LRM's internal reasoning budget does not improve, and can even hurt, factual consistency, suggesting that effective summarization demands faithful compression rather than creative over-thinking.

</details>


### [18] [Fine-grained Narrative Classification in Biased News Articles](https://arxiv.org/abs/2512.03582)
*Zeba Afroz,Harsh Vardhan,Pawan Bhakuni,Aanchal Punia,Rajdeep Kumar,Md. Shad Akhtar*

Main category: cs.CL

TL;DR: 提出了INDI-PROP数据集，用于印度新闻媒体中的宣传分析，包含三个层次的标注：意识形态偏见、叙事框架和说服技巧，并开发了基于GPT-4o-mini的多跳推理框架FANTA和TPTC进行分类任务。


<details>
  <summary>Details</summary>
Motivation: 叙事是宣传的认知和情感支架，能将孤立的说服技巧组织成连贯的故事。现有研究缺乏细粒度的叙事分类，特别是在印度新闻媒体背景下。需要建立意识形态基础的细粒度叙事数据集和分析框架。

Method: 1. 构建INDI-PROP数据集：包含1,266篇关于CAA和农民抗议的文章，进行三层标注：意识形态偏见、事件特定细粒度叙事框架、说服技巧。2. 开发两个GPT-4o-mini引导的多跳推理框架：FANTA（整合信息提取和上下文框架进行分层推理）和TPTC（通过两阶段方法系统分解说服线索）。

Result: INDI-PROP是首个意识形态基础的细粒度叙事数据集。FANTA和TPTC框架在偏见、叙事和说服技巧分类任务上相比基线方法有显著改进。

Conclusion: 该研究提供了系统分析宣传叙事的方法，通过多层次的标注框架和基于大语言模型的推理方法，能够有效识别新闻文章中的意识形态偏见、叙事框架和说服技巧，为宣传分析提供了新的工具和数据集。

Abstract: Narratives are the cognitive and emotional scaffolds of propaganda. They organize isolated persuasive techniques into coherent stories that justify actions, attribute blame, and evoke identification with ideological camps. In this paper, we propose a novel fine-grained narrative classification in biased news articles. We also explore article-bias classification as the precursor task to narrative classification and fine-grained persuasive technique identification. We develop INDI-PROP, the first ideologically grounded fine-grained narrative dataset with multi-level annotation for analyzing propaganda in Indian news media. Our dataset INDI-PROP comprises 1,266 articles focusing on two polarizing socio-political events in recent times: CAA and the Farmers' protest. Each article is annotated at three hierarchical levels: (i) ideological article-bias (pro-government, pro-opposition, neutral), (ii) event-specific fine-grained narrative frames anchored in ideological polarity and communicative intent, and (iii) persuasive techniques. We propose FANTA and TPTC, two GPT-4o-mini guided multi-hop prompt-based reasoning frameworks for the bias, narrative, and persuasive technique classification. FANTA leverages multi-layered communicative phenomena by integrating information extraction and contextual framing for hierarchical reasoning. On the other hand, TPTC adopts systematic decomposition of persuasive cues via a two-stage approach. Our evaluation suggests substantial improvement over underlying baselines in each case.

</details>


### [19] [AlignCheck: a Semantic Open-Domain Metric for Factual Consistency Assessment](https://arxiv.org/abs/2512.03634)
*Ahmad Aghaebrahimian*

Main category: cs.CL

TL;DR: 提出一个可解释的事实一致性评估框架，通过将文本分解为原子事实并引入灵活的、无模式的方法来评估LLM生成内容的事实准确性，特别针对临床等高风险领域。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型容易产生看似合理但错误或误导性的论点（幻觉问题），这在临床等高风险领域尤其危险。现有评估指标无法充分评估事实一致性且缺乏可解释性，使得诊断和缓解错误变得困难。

Method: 提出一个可解释的事实一致性评估框架：1）将文本分解为原子事实；2）引入灵活的无模式方法；3）使用加权指标而非绝对指标来增强事实评估；4）提出控制复杂领域评估复杂度的机制。

Result: 在流行的通用和临床数据集上进行了基准测试，并发布了代码以支持未来研究中事实感知模型的训练。

Conclusion: 该框架解决了现有事实一致性评估方法的局限性，为高风险领域提供了更可靠、可解释的评估工具，有助于诊断和缓解LLM的幻觉问题。

Abstract: Large Language Models have significantly advanced natural language processing tasks, but remain prone to generating incorrect or misleading but plausible arguments. This issue, known as hallucination, is particularly concerning in high-stakes domains like clinical applications, where factual inaccuracies can have severe consequences. Existing evaluation metrics fail to adequately assess factual consistency and lack interpretability, making diagnosing and mitigating errors difficult. We propose an interpretable framework for factual consistency assessment for in-domain and open-domain texts to address these limitations. Our approach decomposes text into atomic facts and introduces a flexible, schema-free methodology. Unlike previous methods with an absolute metric, we incorporate a weighted metric to enhance factual evaluation. Additionally, we propose a mechanism to control assessment complexity in intricate domains. We benchmark our approach on popular general and clinical datasets and release our code to support fact-aware model training in future research.

</details>


### [20] [Generative AI Practices, Literacy, and Divides: An Empirical Analysis in the Italian Context](https://arxiv.org/abs/2512.03671)
*Beatrice Savoldi,Giuseppe Attanasio,Olga Gorodetskaya,Marta Marchiori Manerba,Elisa Bassignana,Silvia Casola,Matteo Negri,Tommaso Caselli,Luisa Bentivogli,Alan Ramponi,Arianna Muti,Nicoletta Balbo,Debora Nozza*

Main category: cs.CL

TL;DR: 意大利首次全面调查显示：生成式AI在意大利广泛采用，正取代其他技术成为主要信息来源，但用户数字素养低且存在显著性别鸿沟，女性采用率仅为男性一半。


<details>
  <summary>Details</summary>
Motivation: 生成式AI聊天机器人正在改变数字互动，但存在扩大数字鸿沟的风险。研究旨在通过首次全面实证调查，了解意大利生成式AI的采用情况、使用模式和素养水平，以识别潜在风险和不平等问题。

Method: 基于新收集的1906名意大利语成年人的调查数据，进行全面的实证映射分析，研究生成式AI的采用率、使用模式和数字素养。

Result: 1) 生成式AI在工作和个人用途中广泛采用，包括情感支持和医疗建议等敏感任务；2) 生成式AI正取代其他技术成为主要信息来源，尽管用户数字素养低且难以识别错误信息；3) 存在显著性别鸿沟，女性采用率仅为男性一半，使用频率也更低；4) 数字素养是采用的关键预测因素，但只能部分解释性别差异。

Conclusion: 生成式AI的多用途使用需要有针对性的教育举措，并进一步研究素养无法完全解释的平等参与障碍。研究为理解生成式AI的社会影响提供了细致洞察。

Abstract: The rise of Artificial Intelligence (AI) language technologies, particularly generative AI (GenAI) chatbots accessible via conversational interfaces, is transforming digital interactions. While these tools hold societal promise, they also risk widening digital divides due to uneven adoption and low awareness of their limitations. This study presents the first comprehensive empirical mapping of GenAI adoption, usage patterns, and literacy in Italy, based on newly collected survey data from 1,906 Italian-speaking adults. Our findings reveal widespread adoption for both work and personal use, including sensitive tasks like emotional support and medical advice. Crucially, GenAI is supplanting other technologies to become a primary information source: this trend persists despite low user digital literacy, posing a risk as users struggle to recognize errors or misinformation. Moreover, we identify a significant gender divide -- particularly pronounced in older generations -- where women are half as likely to adopt GenAI and use it less frequently than men. While we find literacy to be a key predictor of adoption, it only partially explains this disparity, suggesting that other barriers are at play. Overall, our data provide granular insights into the multipurpose usage of GenAI, highlighting the dual need for targeted educational initiatives and further investigation into the underlying barriers to equitable participation that competence alone cannot explain.

</details>


### [21] [Evaluating Hydro-Science and Engineering Knowledge of Large Language Models](https://arxiv.org/abs/2512.03672)
*Shiruo Hu,Wenbo Shan,Yingjia Li,Zhiqi Wan,Xinpeng Yu,Yunjia Qi,Haotian Xia,Yang Xiao,Dingxiao Liu,Jiaru Wang,Chenxu Gong,Ruixi Zhang,Shuyue Wu,Shibo Cui,Chee Hui Lai,Wei Luo,Yubin He,Bin Xu,Jianshi Zhao*

Main category: cs.CL

TL;DR: 该研究提出了Hydro-SE Bench基准测试，包含4000道选择题，用于评估大语言模型在水科学与工程领域的知识、应用和推理能力，发现商业模型准确率在0.74-0.80之间，小参数模型在0.41-0.68之间。


<details>
  <summary>Details</summary>
Motivation: 水科学与工程是保障人类水安全、清洁能源和防灾减灾的关键领域，需要多学科专家协作决策。随着大语言模型的发展，其在Hydro-SE领域的应用潜力日益受到关注，但模型在该领域的知识和应用能力尚未得到充分评估。

Method: 提出了Hydro-SE Bench评估基准，包含4000道选择题，涵盖9个子领域，从基础概念知识、工程应用能力、推理计算能力三个维度评估LLMs。对商业模型和小参数模型进行了系统评估。

Result: 商业LLMs准确率在0.74-0.80之间，小参数模型在0.41-0.68之间。模型在自然科学相关子领域表现良好，但在行业标准、水工结构等专业领域表现不佳。模型扩展主要提升推理计算能力，工程应用仍有改进空间。

Conclusion: 研究揭示了LLMs在Hydro-SE领域的优势和不足，为模型开发者提供了明确的训练目标，为Hydro-SE研究人员提供了应用LLMs的实践指导，有助于推动LLMs在该领域的更好应用。

Abstract: Hydro-Science and Engineering (Hydro-SE) is a critical and irreplaceable domain that secures human water supply, generates clean hydropower energy, and mitigates flood and drought disasters. Featuring multiple engineering objectives, Hydro-SE is an inherently interdisciplinary domain that integrates scientific knowledge with engineering expertise. This integration necessitates extensive expert collaboration in decision-making, which poses difficulties for intelligence. With the rapid advancement of large language models (LLMs), their potential application in the Hydro-SE domain is being increasingly explored. However, the knowledge and application abilities of LLMs in Hydro-SE have not been sufficiently evaluated. To address this issue, we propose the Hydro-SE LLM evaluation benchmark (Hydro-SE Bench), which contains 4,000 multiple-choice questions. Hydro-SE Bench covers nine subfields and enables evaluation of LLMs in aspects of basic conceptual knowledge, engineering application ability, and reasoning and calculation ability. The evaluation results on Hydro-SE Bench show that the accuracy values vary among 0.74 to 0.80 for commercial LLMs, and among 0.41 to 0.68 for small-parameter LLMs. While LLMs perform well in subfields closely related to natural and physical sciences, they struggle with domain-specific knowledge such as industry standards and hydraulic structures. Model scaling mainly improves reasoning and calculation abilities, but there is still great potential for LLMs to better handle problems in practical engineering application. This study highlights the strengths and weaknesses of LLMs for Hydro-SE tasks, providing model developers with clear training targets and Hydro-SE researchers with practical guidance for applying LLMs.

</details>


### [22] [Different types of syntactic agreement recruit the same units within large language models](https://arxiv.org/abs/2512.03676)
*Daria Kryvosheieva,Andrea de Varda,Evelina Fedorenko,Greta Tuckute*

Main category: cs.CL

TL;DR: LLMs中的语法知识表征研究：发现不同语法现象（特别是语法一致性）在模型中共享功能单元，构成有意义的语法功能类别，且跨语言存在结构相似性模式。


<details>
  <summary>Details</summary>
Motivation: 虽然大型语言模型能够可靠区分语法正确与错误的句子，但语法知识在模型内部如何表征仍然是一个开放性问题。研究者希望探究不同语法现象在LLMs中是共享还是使用不同的组件。

Method: 采用受认知神经科学启发的功能定位方法，在7个开源模型中识别对67种英语语法现象最敏感的单元。通过跨语言分析（英语、俄语、中文）和57种语言的跨语言比较，研究语法一致性的表征模式。

Result: 发现不同类型的语法一致性（如主谓一致、照应一致、限定词-名词一致）在模型中招募重叠的单元集合，表明语法一致性构成LLMs中有意义的功能类别。这种模式在英语、俄语和中文中均成立，且结构更相似的语言在主谓一致性上共享更多单元。

Conclusion: 语法一致性作为语法依赖关系的关键标记，在LLMs的表征空间中构成了有意义的类别，揭示了模型内部语法知识的组织方式具有跨语言的结构相似性模式。

Abstract: Large language models (LLMs) can reliably distinguish grammatical from ungrammatical sentences, but how grammatical knowledge is represented within the models remains an open question. We investigate whether different syntactic phenomena recruit shared or distinct components in LLMs. Using a functional localization approach inspired by cognitive neuroscience, we identify the LLM units most responsive to 67 English syntactic phenomena in seven open-weight models. These units are consistently recruited across sentences containing the phenomena and causally support the models' syntactic performance. Critically, different types of syntactic agreement (e.g., subject-verb, anaphor, determiner-noun) recruit overlapping sets of units, suggesting that agreement constitutes a meaningful functional category for LLMs. This pattern holds in English, Russian, and Chinese; and further, in a cross-lingual analysis of 57 diverse languages, structurally more similar languages share more units for subject-verb agreement. Taken together, these findings reveal that syntactic agreement-a critical marker of syntactic dependencies-constitutes a meaningful category within LLMs' representational spaces.

</details>


### [23] [AITutor-EvalKit: Exploring the Capabilities of AI Tutors](https://arxiv.org/abs/2512.03688)
*Numaan Naeem,Kaushal Kumar Maurya,Kseniia Petukhova,Ekaterina Kochmar*

Main category: cs.CL

TL;DR: AITutor-EvalKit是一个使用语言技术评估AI导师教学质量的工具，提供演示、评估、模型检查和数据可视化功能，面向教育利益相关者和ACL社区。


<details>
  <summary>Details</summary>
Motivation: 随着AI导师在教育领域的广泛应用，需要系统评估其教学质量。当前缺乏专门工具来评估AI导师的教学效果，教育利益相关者和研究社区需要可靠的方法来评估和改进AI导师的教学能力。

Method: 开发了一个综合应用工具，利用语言技术评估AI导师的教学质量。该工具包含：1）教学评估功能；2）软件演示和评估模块；3）模型检查工具；4）数据可视化组件。支持用户反馈和注释收集。

Result: 创建了一个功能完整的AITutor-EvalKit工具，能够系统评估AI导师的教学质量。该工具为教育利益相关者和ACL社区提供了实用的评估平台，支持学习过程并促进用户反馈收集。

Conclusion: AITutor-EvalKit是一个有价值的工具，填补了AI导师教学质量评估的空白，为教育实践和研究社区提供了重要的技术支持，有助于提升AI导师的教学效果和质量。

Abstract: We present AITutor-EvalKit, an application that uses language technology to evaluate the pedagogical quality of AI tutors, provides software for demonstration and evaluation, as well as model inspection and data visualization. This tool is aimed at education stakeholders as well as *ACL community at large, as it supports learning and can also be used to collect user feedback and annotations.

</details>


### [24] [DZ-TDPO: Non-Destructive Temporal Alignment for Mutable State Tracking in Long-Context Dialogue](https://arxiv.org/abs/2512.03704)
*Yijun Liao*

Main category: cs.CL

TL;DR: DZ-TDPO是一个非破坏性对齐框架，通过冲突感知的动态KL约束和可学习的时间注意力偏置，解决了长上下文对话系统中的状态惯性问题，在保持零样本泛化能力的同时实现了最先进的胜率。


<details>
  <summary>Details</summary>
Motivation: 长上下文对话系统存在"状态惯性"问题，即静态约束阻碍了模型在演化用户意图与历史上下文之间解决冲突。现有方法通常通过破坏性权重更新来克服惯性，但这会损害模型的通用能力。

Method: 提出DZ-TDPO框架，结合冲突感知的动态KL约束和可学习的时间注意力偏置。动态KL约束根据历史与当前意图的冲突程度调整正则化强度，时间注意力偏置通过可学习参数调节历史token的注意力权重。

Result: 在Multi-Session Chat数据集上，DZ-TDPO在Phi-3.5模型上达到86.2%的胜率，Qwen2.5-7B模型达到99.4%的胜率且困惑度开销可忽略。同时保持零样本泛化能力和通用能力（MMLU）。

Conclusion: TAI（时间注意力惯性）可以通过精确的注意力调节而非破坏性权重更新来缓解，从而在保持模型通用能力的同时解决状态惯性问题。研究还揭示了"容量-稳定性权衡"现象。

Abstract: Long-context dialogue systems suffer from State Inertia, where static constraints prevent models from resolving conflicts between evolving user intents and established historical context. To address this, we propose DZ-TDPO, a non-destructive alignment framework that synergizes conflict-aware dynamic KL constraints with a learnable temporal attention bias. Experiments on the Multi-Session Chat (MSC) dataset demonstrate that DZ-TDPO achieves state-of-the-art win rates (86.2% on Phi-3.5) while maintaining robust zero-shot generalization. Crucially, our scaling analysis reveals a "Capacity-Stability Trade-off": while smaller models incur an "alignment tax" (perplexity surge) to overcome historical inertia, the larger Qwen2.5-7B model achieves near-perfect alignment (99.4% win rate) with negligible perplexity overhead. This confirms that TAI can be alleviated via precise attention regulation rather than destructive weight updates, preserving general capabilities (MMLU) across model scales. Code and data are available: https://github.com/lyj20071013/DZ-TDPO

</details>


### [25] [AR-Med: Automated Relevance Enhancement in Medical Search via LLM-Driven Information Augmentation](https://arxiv.org/abs/2512.03737)
*Chuyue Wang,Jie Feng,Yuxi Wu,Hang Zhang,Zhiguo Fan,Bing Cheng,Wei Lin*

Main category: cs.CL

TL;DR: AR-Med是一个用于医疗搜索自动相关性评估的框架，通过检索增强方法将LLM推理基于已验证的医学知识，并采用知识蒸馏实现高效在线部署，在离线准确率上达到93%以上。


<details>
  <summary>Details</summary>
Motivation: 在线医疗平台搜索的准确性和可靠性对用户安全和服务效果至关重要。传统方法难以理解复杂细微的用户查询，而LLM虽然具有强大的语义理解能力，但在医疗领域部署面临事实幻觉、专业知识缺口和高运营成本等挑战。

Method: AR-Med采用检索增强方法将LLM推理基于已验证的医学知识，确保高准确性和可靠性。为实现在线服务的高效性，设计了实用的知识蒸馏方案，将大型教师模型压缩为紧凑而强大的学生模型。同时引入了LocalQSMed多专家标注基准来指导模型迭代。

Result: AR-Med在离线准确率上达到93%以上，比原始在线系统提升了24%的绝对改进。在线相关性和用户满意度方面也取得了显著提升，已成功在在线医疗配送平台上大规模部署。

Conclusion: 该工作为在现实世界医疗应用中开发可信赖的LLM驱动系统提供了一个实用且可扩展的蓝图，成功解决了医疗搜索中的准确性和可靠性问题。

Abstract: Accurate and reliable search on online healthcare platforms is critical for user safety and service efficacy. Traditional methods, however, often fail to comprehend complex and nuanced user queries, limiting their effectiveness. Large language models (LLMs) present a promising solution, offering powerful semantic understanding to bridge this gap. Despite their potential, deploying LLMs in this high-stakes domain is fraught with challenges, including factual hallucinations, specialized knowledge gaps, and high operational costs. To overcome these barriers, we introduce \textbf{AR-Med}, a novel framework for \textbf{A}utomated \textbf{R}elevance assessment for \textbf{Med}ical search that has been successfully deployed at scale on the Online Medical Delivery Platforms. AR-Med grounds LLM reasoning in verified medical knowledge through a retrieval-augmented approach, ensuring high accuracy and reliability. To enable efficient online service, we design a practical knowledge distillation scheme that compresses large teacher models into compact yet powerful student models. We also introduce LocalQSMed, a multi-expert annotated benchmark developed to guide model iteration and ensure strong alignment between offline and online performance. Extensive experiments show AR-Med achieves an offline accuracy of over 93\%, a 24\% absolute improvement over the original online system, and delivers significant gains in online relevance and user satisfaction. Our work presents a practical and scalable blueprint for developing trustworthy, LLM-powered systems in real-world healthcare applications.

</details>


### [26] [Principled RL for Diffusion LLMs Emerges from a Sequence-Level Perspective](https://arxiv.org/abs/2512.03759)
*Jingyang Ou,Jiaqi Han,Minkai Xu,Shaoxuan Xu,Jianwen Xie,Stefano Ermon,Yi Wu,Chongxuan Li*

Main category: cs.CL

TL;DR: ESPO提出了一种针对扩散大语言模型的序列级强化学习框架，解决了传统token级RL方法在dLLMs中不适用的问题，在数学推理、编程和规划任务上显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 强化学习在自回归语言模型中很有效，但难以应用于扩散大语言模型，因为dLLMs通过迭代去噪步骤生成序列，缺乏token级条件概率，无法直接使用token级RL目标。

Method: 提出ELBO-based Sequence-level Policy Optimization (ESPO)，将整个序列生成视为单一动作，使用ELBO作为可处理的序列级似然代理，包含token级重要性比率归一化和鲁棒的KL散度估计以确保训练稳定性。

Result: 在数学推理、编程和规划任务上的实验表明，ESPO显著优于token级基线方法，在Countdown任务上实现了20-40分的巨大提升，在数学和编程基准上也保持了一致的增益。

Conclusion: ESPO为dLLMs中的强化学习建立了一个原则性且经验有效的序列级优化范式，解决了dLLMs与RL方法之间的根本性不匹配问题。

Abstract: Reinforcement Learning (RL) has proven highly effective for autoregressive language models, but adapting these methods to diffusion large language models (dLLMs) presents fundamental challenges. The core difficulty lies in likelihood approximation: while autoregressive models naturally provide token-level conditional probabilities essential for token-level RL objectives (e.g., GRPO), dLLMs generate sequences through iterative non-autoregressive denoising steps that lack this factorization. To address this fundamental mismatch, we propose ELBO-based Sequence-level Policy Optimization (ESPO), a principled RL framework that treats entire sequence generation as a single action and uses the ELBO as a tractable sequence-level likelihood proxy. Our method incorporates per-token normalization of importance ratios and robust KL-divergence estimation to ensure stable large-scale training. Extensive experiments on mathematical reasoning, coding, and planning tasks demonstrate that ESPO significantly outperforms token-level baselines, achieving dramatic improvements of 20-40 points on the Countdown task, while maintaining consistent gains on math and coding benchmarks. Our approach establishes sequence-level optimization as a principled and empirically effective paradigm for RL in dLLMs. Our code is available at https://github.com/ML-GSAI/ESPO.

</details>


### [27] [In-Context Representation Hijacking](https://arxiv.org/abs/2512.03771)
*Itay Yona,Amir Sarid,Michael Karasik,Yossi Gandelsman*

Main category: cs.CL

TL;DR: Doublespeak是一种针对大语言模型的上下文表示劫持攻击，通过将有害关键词替换为良性标记来绕过安全对齐，使模型内部将良性输入解释为有害指令。


<details>
  <summary>Details</summary>
Motivation: 当前LLM的安全对齐策略存在漏洞，攻击者可能通过操纵内部表示空间来绕过安全防护。研究者希望揭示这种新的攻击面，证明现有对齐方法在表示层面的不足。

Method: 通过系统性地将有害关键词（如"bomb"）替换为良性标记（如"carrot"），在多个上下文示例中构建攻击。这种替换导致良性标记的内部表示收敛于有害标记的表示，从而在语义层面实现劫持。

Result: 攻击在闭源和开源系统上均有效，在Llama-3.3-70B-Instruct上单句上下文覆盖达到74%的攻击成功率。可解释性工具显示语义覆盖逐层发生，早期层的良性含义在后期层收敛为有害语义。

Conclusion: Doublespeak攻击揭示了LLM潜在空间中的新攻击面，表明当前对齐策略不足，需要在表示层面进行安全防护。这种优化无关、跨模型可转移的攻击对现有安全框架构成严重挑战。

Abstract: We introduce \textbf{Doublespeak}, a simple \emph{in-context representation hijacking} attack against large language models (LLMs). The attack works by systematically replacing a harmful keyword (e.g., \textit{bomb}) with a benign token (e.g., \textit{carrot}) across multiple in-context examples, provided a prefix to a harmful request. We demonstrate that this substitution leads to the internal representation of the benign token converging toward that of the harmful one, effectively embedding the harmful semantics under a euphemism. As a result, superficially innocuous prompts (e.g., ``How to build a carrot?'') are internally interpreted as disallowed instructions (e.g., ``How to build a bomb?''), thereby bypassing the model's safety alignment. We use interpretability tools to show that this semantic overwrite emerges layer by layer, with benign meanings in early layers converging into harmful semantics in later ones. Doublespeak is optimization-free, broadly transferable across model families, and achieves strong success rates on closed-source and open-source systems, reaching 74\% ASR on Llama-3.3-70B-Instruct with a single-sentence context override. Our findings highlight a new attack surface in the latent space of LLMs, revealing that current alignment strategies are insufficient and should instead operate at the representation level.

</details>


### [28] [Enhancing Instruction-Following Capabilities in Seq2Seq Models: DoLA Adaptations for T5](https://arxiv.org/abs/2512.03803)
*Huey Sun,Anabel Yong,Lorenzo Gilly,Felipe Jin*

Main category: cs.CL

TL;DR: 将DoLa对比解码方法从仅解码器架构扩展到T5/FLAN-T5编码器-解码器架构，评估其对指令跟随能力的影响，发现对某些任务类别有提升但对其他有害


<details>
  <summary>Details</summary>
Motivation: 现有对比解码方法（如DoLa）仅在解码器架构中实现，且主要研究其对事实性的改进。本研究旨在将DoLa扩展到编码器-解码器架构（T5/FLAN-T5），并评估其对指令跟随能力的影响

Method: 将DoLa方法适配到T5和FLAN-T5模型家族，通过层间对比解码策略，并进行逐层分析以量化DoLa对令牌输出概率的影响

Result: DoLa在某些任务类别中提高了文本生成的忠实度，但在其他类别中反而有害。通过逐层分析揭示了DoLa对令牌概率的具体影响模式

Conclusion: 这是首次在编码器-解码器架构中实现对比解码策略，DoLa对指令跟随能力的影响具有任务类别依赖性，需要进一步研究其适用条件

Abstract: Contrastive decoding is a lightweight and effective inference-time method that improves the quality of text generation in Large Language Models. However, algorithms such as DoLa (Decoding by Contrastive Layers) have only been implemented in decoder-only architectures and studied for their impact on improving factuality. This work adapts DoLa for the T5 and FLAN-T5 model families and evaluates its impact on the models' instruction following capabilities, which to our knowledge is the first implementation of a contrastive decoding strategy in an encoder-decoder architecture. Our results show that DoLa improves the faithfulness of text generation for certain categories of tasks and harms others. To understand these results, we present a layer-by-layer analysis of logit evolution in a FLAN-T5 model to quantify DoLa's impact on token output probabilities.

</details>


### [29] [Improving Alignment Between Human and Machine Codes: An Empirical Assessment of Prompt Engineering for Construct Identification in Psychology](https://arxiv.org/abs/2512.03818)
*Kylie L. Anglin,Stephanie Milan,Brittney Hernandez,Claudia Ventura*

Main category: cs.CL

TL;DR: 研究提出一个通过提示工程优化LLM在文本分类任务中性能的实证框架，发现构造定义、任务框架和示例是影响分类准确性的关键因素，建议结合人工和自动生成的提示变体进行实证选择。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在文本分类中表现良好，但其输出严重依赖提示的措辞。现有研究很少关注心理学等领域的分类任务，这些领域的构念具有精确、理论驱动的定义，可能在预训练数据中代表性不足。需要系统方法来优化LLM在专家判断对齐关键场景中的提示。

Method: 提出一个实证框架，实验评估五种提示策略：代码本引导的实证提示选择、自动提示工程、角色提示、思维链推理和解释性提示，结合零样本和少样本分类。在三个构念和两个模型上进行测试。

Result: 发现角色、思维链和解释并不能完全解决提示措辞不当带来的性能损失。影响提示性能的最关键特征是构造定义、任务框架，以及较小程度上的示例。与专家判断最一致的结果来自结合代码本引导的实证提示选择和自动提示工程的少样本提示。

Conclusion: 建议研究人员尽可能生成和评估尽可能多的提示变体（人工制作、自动生成或两者结合），基于训练数据集中的实证性能选择提示和示例，并在保留集上验证最终方法。这为在专家判断对齐关键场景中优化LLM提示提供了实用、系统和理论驱动的方法。

Abstract: Due to their architecture and vast pre-training data, large language models (LLMs) demonstrate strong text classification performance. However, LLM output - here, the category assigned to a text - depends heavily on the wording of the prompt. While literature on prompt engineering is expanding, few studies focus on classification tasks, and even fewer address domains like psychology, where constructs have precise, theory-driven definitions that may not be well represented in pre-training data. We present an empirical framework for optimizing LLM performance for identifying constructs in texts via prompt engineering. We experimentally evaluate five prompting strategies --codebook-guided empirical prompt selection, automatic prompt engineering, persona prompting, chain-of-thought reasoning, and explanatory prompting - with zero-shot and few-shot classification. We find that persona, chain-of-thought, and explanations do not fully address performance loss accompanying a badly worded prompt. Instead, the most influential features of a prompt are the construct definition, task framing, and, to a lesser extent, the examples provided. Across three constructs and two models, the classifications most aligned with expert judgments resulted from a few-shot prompt combining codebook-guided empirical prompt selection with automatic prompt engineering. Based on our findings, we recommend that researchers generate and evaluate as many prompt variants as feasible, whether human-crafted, automatically generated, or ideally both, and select prompts and examples based on empirical performance in a training dataset, validating the final approach in a holdout set. This procedure offers a practical, systematic, and theory-driven method for optimizing LLM prompts in settings where alignment with expert judgment is critical.

</details>


### [30] [Training and Evaluation of Guideline-Based Medical Reasoning in LLMs](https://arxiv.org/abs/2512.03838)
*Michael Staniek,Artem Sokolov,Stefan Riezler*

Main category: cs.CL

TL;DR: 该论文提出了一种方法，通过将医学共识指南转化为推理规则来微调LLMs，使其能够遵循医学共识进行逐步推理和预测，并以Sepsis-3定义为例验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前医学早期预测的机器学习方法虽然性能有所突破，但过度关注预测准确性而忽视了可解释性，导致难以获得医疗从业者的信任。医学领域普遍存在共识指南，但现有方法未能有效利用这些指南来指导模型的推理过程。

Method: 将医学共识指南转化为可执行的推理规则，用这些规则的实例化数据微调LLMs，使模型学会遵循共识规则进行逐步推理。同时采用多模态方法，将时间序列预测模型的输出表示与LLM集成，以处理稀疏和不规则的临床变量预测。

Result: 微调后的小型模型在推理正确性方面显著优于使用显式定义进行单次学习的大型LLMs，以及那些在包含共识定义的医学文本上训练的模型。微调模型在未见患者数据上对规则（及其例外）的推导正确性接近完美。多模态集成进一步提高了对未来稀疏不规则临床变量的预测能力。

Conclusion: 通过将医学共识指南转化为推理规则来微调LLMs，可以有效提高模型推理的可解释性和正确性。早期预测的主要瓶颈不是分布外泛化，而是对未来稀疏不规则临床变量的预测问题，这一问题可以通过多模态集成方法得到改善。

Abstract: Machine learning for early prediction in medicine has recently shown breakthrough performance, however, the focus on improving prediction accuracy has led to a neglect of faithful explanations that are required to gain the trust of medical practitioners. The goal of this paper is to teach LLMs to follow medical consensus guidelines step-by-step in their reasoning and prediction process. Since consensus guidelines are ubiquitous in medicine, instantiations of verbalized medical inference rules to electronic health records provide data for fine-tuning LLMs to learn consensus rules and possible exceptions thereof for many medical areas. Consensus rules also enable an automatic evaluation of the model's inference process regarding its derivation correctness (evaluating correct and faithful deduction of a conclusion from given premises) and value correctness (comparing predicted values against real-world measurements). We exemplify our work using the complex Sepsis-3 consensus definition. Our experiments show that small fine-tuned models outperform one-shot learning of considerably larger LLMs that are prompted with the explicit definition and models that are trained on medical texts including consensus definitions. Since fine-tuning on verbalized rule instantiations of a specific medical area yields nearly perfect derivation correctness for rules (and exceptions) on unseen patient data in that area, the bottleneck for early prediction is not out-of-distribution generalization, but the orthogonal problem of generalization into the future by forecasting sparsely and irregularly sampled clinical variables. We show that the latter results can be improved by integrating the output representations of a time series forecasting model with the LLM in a multimodal setup.

</details>


### [31] [Reconstructing KV Caches with Cross-layer Fusion For Enhanced Transformers](https://arxiv.org/abs/2512.03870)
*Hongzhan Lin,Zhiqi Bai,Xinmiao Zhang,Sen Yang,Xiang Li,Siran Yang,Yunlong Xu,Jiaheng Liu,Yongchi Zhao,Jiamang Wang,Yuchi Xu,Wenbo Su,Bo Zheng*

Main category: cs.CL

TL;DR: FusedKV通过融合底层和中层的信息来优化Transformer解码器的KV缓存，在减少50%内存的同时保持甚至提升性能。


<details>
  <summary>Details</summary>
Motivation: Transformer解码器在处理长序列时，KV缓存的内存需求变得难以承受。现有的跨层KV缓存共享方法（如YOCO、CLA）性能通常不如层内方法（如GQA），需要找到更有效的KV缓存优化方案。

Method: 提出FusedKV方法，通过分析发现顶层KV缓存中，values主要来自底层，keys则同时来自底层和中层。因此设计顶层KV缓存为底层和中层最有信息量的KV缓存的可学习融合，直接在应用RoPE后的keys上进行融合，避免重新计算旋转嵌入。还提出轻量版FusedKV-Lite，顶层KV缓存直接使用底层values和中层keys。

Result: 在332M到4B参数的LLM实验中，该方法减少50%缓存内存，同时达到比标准Transformer解码器更低的验证困惑度，成为内存高效且高性能的架构替代方案。

Conclusion: FusedKV通过智能融合不同层的KV缓存信息，有效解决了长序列处理中的内存瓶颈问题，在保持性能的同时显著减少内存使用，为Transformer架构的内存优化提供了新思路。

Abstract: Transformer decoders have achieved strong results across tasks, but the memory required for the KV cache becomes prohibitive at long sequence lengths. Although Cross-layer KV Cache sharing (e.g., YOCO, CLA) offers a path to mitigate KV Cache bottleneck, it typically underperforms within-layer methods like GQA. To understand the root cause, we investigate the information flow of keys and values of the top-layers. Our preliminary reveals a clear distribution: values are predominantly derived from the bottom layer, while keys draw more information from both bottom and middle layers. Building upon this, we propose FusedKV, whose top-layer KV caches are a learnable fusion of the most informative ones from the bottom and middle layers. This fusion operates directly on post-RoPE keys, preserving relative positional information without the computational cost of re-applying rotary embeddings. To further improve efficiency, we propose FusedKV-Lite, an cross-layer sharing approach, where top-layer KV caches are directly derived from the bottom-layer values and the middle-layer keys. Compared to FusedKV, FusedKV-Lite reduces I/O overhead at the cost of a slight increase in perplexity. In experiments on LLMs ranging from 332M to 4B parameters, our proposed method reduce 50\% cache memory while achieving lower validation perplexity than the standard Transformer decoder, establishing it as a memory-efficient, high-performance architectural alternative.

</details>


### [32] [BERnaT: Basque Encoders for Representing Natural Textual Diversity](https://arxiv.org/abs/2512.03903)
*Ekhi Azurmendi,Joseba Fernandez de Landa,Jaione Bengoetxea,Maite Heredia,Julen Etxaniz,Mikel Zubillaga,Ander Soraluze,Aitor Soroa*

Main category: cs.CL

TL;DR: 本文研究了语言模型训练中语言多样性的重要性，通过构建包含标准、社交媒体和历史文本的巴斯克语语料库，训练了不同配置的BERT模型，发现结合多样语料训练的模型在所有任务上表现更优。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型依赖经过质量过滤的大规模文本语料库，这往往会排除非标准语言变体（方言、历史、非正式等），降低模型鲁棒性并加剧表征偏见。作者认为语言模型应捕捉语言变异的完整谱系，而非仅依赖标准化文本。

Method: 针对巴斯克语（形态丰富、资源稀缺的语言），构建了包含标准文本、社交媒体内容和历史资料的新语料库。预训练了BERnaT系列编码器模型，包括三种配置：标准语料、多样语料、以及两者结合。提出了将自然语言理解任务分为标准和多样子集的评估框架，以评估语言泛化能力。

Result: 结果显示，在标准和多样数据上训练的模型始终优于仅使用标准语料训练的模型，在所有任务类型上都有性能提升，且不影响标准基准测试的准确性。

Conclusion: 语言多样性对于构建包容性强、泛化能力好的语言模型至关重要。结合多样语料训练能提升模型性能而不损害标准任务表现。

Abstract: Language models depend on massive text corpora that are often filtered for quality, a process that can unintentionally exclude non-standard linguistic varieties, reduce model robustness and reinforce representational biases. In this paper, we argue that language models should aim to capture the full spectrum of language variation (dialectal, historical, informal, etc.) rather than relying solely on standardized text. Focusing on Basque, a morphologically rich and low-resource language, we construct new corpora combining standard, social media, and historical sources, and pre-train the BERnaT family of encoder-only models in three configurations: standard, diverse, and combined. We further propose an evaluation framework that separates Natural Language Understanding (NLU) tasks into standard and diverse subsets to assess linguistic generalization. Results show that models trained on both standard and diverse data consistently outperform those trained on standard corpora, improving performance across all task types without compromising standard benchmark accuracy. These findings highlight the importance of linguistic diversity in building inclusive, generalizable language models.

</details>


### [33] [Is Lying Only Sinful in Islam? Exploring Religious Bias in Multilingual Large Language Models Across Major Religions](https://arxiv.org/abs/2512.03943)
*Kazi Abrab Hossain,Jannatul Somiya Mahmud,Maria Hossain Tuli,Anik Mitra,S. M. Taiabul Haque,Farig Y. Sadeque*

Main category: cs.CL

TL;DR: BRAND数据集用于评估多语言模型在宗教敏感话题上的偏见，发现模型在英语中表现优于孟加拉语，且对伊斯兰教存在系统性偏见。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在偏见检测方面有所进步，但宗教等敏感话题仍面临挑战，因为细微错误可能导致严重误解。多语言模型经常误传宗教信息，在宗教语境中准确性不足。

Method: 引入BRAND数据集，聚焦南亚四大宗教（佛教、基督教、印度教、伊斯兰教），包含2400多个条目，使用英语和孟加拉语三种不同类型的提示进行评估。

Result: 模型在英语中的表现优于孟加拉语，且始终对伊斯兰教存在偏见，即使在回答宗教中立问题时也是如此。这表明多语言模型在不同语言中提问相似问题时存在持续性偏见。

Conclusion: 研究揭示了多语言模型在宗教话题上的系统性偏见，特别是在不同语言环境下的表现差异。这些发现与HCI领域关于宗教和灵性的更广泛问题相关。

Abstract: While recent developments in large language models have improved bias detection and classification, sensitive subjects like religion still present challenges because even minor errors can result in severe misunderstandings. In particular, multilingual models often misrepresent religions and have difficulties being accurate in religious contexts. To address this, we introduce BRAND: Bilingual Religious Accountable Norm Dataset, which focuses on the four main religions of South Asia: Buddhism, Christianity, Hinduism, and Islam, containing over 2,400 entries, and we used three different types of prompts in both English and Bengali. Our results indicate that models perform better in English than in Bengali and consistently display bias toward Islam, even when answering religion-neutral questions. These findings highlight persistent bias in multilingual models when similar questions are asked in different languages. We further connect our findings to the broader issues in HCI regarding religion and spirituality.

</details>


### [34] [Adapting Large Language Models to Low-Resource Tibetan: A Two-Stage Continual and Supervised Fine-Tuning Study](https://arxiv.org/abs/2512.03976)
*Lifeng Chen,Ryan Lai,Tianming Liu*

Main category: cs.CL

TL;DR: 该研究提出两阶段方法（持续预训练+监督微调）将Qwen2.5-3B模型适配到藏语，显著降低了困惑度并提升了翻译质量，同时通过层分析揭示了适配机制。


<details>
  <summary>Details</summary>
Motivation: 大语言模型适配低资源语言面临数据稀缺和跨语言漂移的挑战，藏语作为形态丰富且代表性不足的语言，需要有效的适配方法。

Method: 采用两阶段方法：1) 持续预训练建立藏语语言基础；2) 监督微调进行任务和翻译专业化。使用Qwen2.5-3B模型，并对Qwen3-4B的435层进行层分析。

Result: 困惑度从2.98降至1.54；汉藏翻译质量显著提升（BLEU从0.046到0.261，chrF从2.2到6.6）。层分析显示适配主要集中在嵌入层和输出头，中后期MLP投影编码领域特定转换。

Conclusion: 持续预训练构建藏语语义流形，监督微调以最小表征扰动优化任务对齐。该研究首次定量探索藏语适配动态，为低资源语言适配提供了可复现框架。

Abstract: Adapting large language models (LLMs) to low-resource languages remains a major challenge due to data scarcity and cross-lingual drift. This work presents a two-stage adaptation of Qwen2.5-3B to Tibetan, a morphologically rich and underrepresented language. We employ Continual Pretraining (CPT) to establish Tibetan linguistic grounding, followed by Supervised Fine-Tuning (SFT) for task and translation specialization. Empirical evaluations demonstrate a consistent decrease in perplexity (from 2.98 $\rightarrow$ 1.54) and substantial improvements in Chinese$\rightarrow$Tibetan translation quality (BLEU: 0.046 $\rightarrow$ 0.261; chrF: 2.2 $\rightarrow$ 6.6). Layer-wise analysis across 435 layers in Qwen3-4B reveals that adaptation primarily concentrates on embedding and output heads, with mid--late MLP projections encoding domain-specific transformations. Our findings suggest that CPT constructs a Tibetan semantic manifold while SFT sharpens task alignment with minimal representational disruption. This study provides the first quantitative exploration of Tibetan adaptation dynamics for LLMs, and offers an open, reproducible framework for extending multilingual foundation models to low-resource settings.

</details>


### [35] [Teaching Old Tokenizers New Words: Efficient Tokenizer Adaptation for Pre-trained Models](https://arxiv.org/abs/2512.03989)
*Taido Purason,Pavel Chizhov,Ivan P. Yamshchikov,Mark Fishel*

Main category: cs.CL

TL;DR: 本文提出两种互补的tokenizer适应方法：持续BPE训练用于词汇扩展，以及基于叶子的词汇剪枝，以提升预训练语言模型在新领域或语言的迁移效果。


<details>
  <summary>Details</summary>
Motivation: 当前tokenizer适应方法（在新数据上训练新tokenizer并追加不重叠词汇）存在效率问题，许多新增词汇无法被访问或从未使用，需要更有效的词汇修改方法。

Method: 1. 持续BPE训练：在预训练tokenizer基础上，继续在新数据上进行BPE合并学习过程；2. 基于叶子的词汇剪枝：移除冗余词汇同时保持模型质量。

Result: 在多语言和多种模型家族上的实验表明，持续BPE训练提高了tokenization效率，并更好地利用了新增词汇；词汇剪枝方法能有效移除冗余词汇。

Conclusion: 这两种方法为受控词汇修改提供了实用工具，已作为开源包发布，能够有效支持预训练语言模型向新领域或语言的迁移。

Abstract: Tokenizer adaptation plays an important role in transferring pre-trained language models to new domains or languages. In this work, we address two complementary aspects of this process: vocabulary extension and pruning. The common approach to extension trains a new tokenizer on domain-specific text and appends the tokens that do not overlap with the existing vocabulary, which often results in many tokens that are unreachable or never used. We propose continued BPE training, which adapts a pre-trained tokenizer by continuing the BPE merge learning process on new data. Experiments across multiple languages and model families show that this approach improves tokenization efficiency and leads to better utilization of added vocabulary. We also introduce leaf-based vocabulary pruning, which removes redundant tokens while preserving model quality. Together, these methods provide practical tools for controlled vocabulary modification, which we release as an open-source package.

</details>


### [36] [AugServe: Adaptive Request Scheduling for Augmented Large Language Model Inference Serving](https://arxiv.org/abs/2512.04013)
*Ying Wang,Zhen Jin,Jiexiong Xu,Wenhai Lin,Yiquan Chen,Wenzhi Chen*

Main category: cs.CL

TL;DR: AugServe是一个用于增强型大语言模型推理服务的高效推理框架，通过两阶段自适应请求调度和动态令牌批处理机制，显著提升有效吞吐量并降低延迟。


<details>
  <summary>Details</summary>
Motivation: 随着增强型大语言模型在Web应用中的普及，现有推理系统面临两个主要问题：1) 先到先服务调度导致严重的队头阻塞，使许多请求超出服务级别目标；2) 静态批处理令牌限制无法适应负载和硬件条件变化。这些问题降低了有效吞吐量和服务质量。

Method: AugServe采用两阶段自适应请求调度策略：第一阶段结合增强型LLM请求的推理特征优化调度顺序；第二阶段利用运行时信息持续优化调度决策，适应请求特性和系统能力。此外，系统根据硬件状态和实时负载动态调整令牌批处理机制。

Result: 实验结果显示，AugServe相比vLLM和InferCept实现了4.7-33.1倍和3.3-13.2倍的有效吞吐量提升，同时将首令牌时间分别降低了96.3%和95.0%。

Conclusion: AugServe通过创新的两阶段自适应调度和动态批处理机制，有效解决了增强型LLM推理服务中的队头阻塞和静态批处理限制问题，显著提升了服务效率和用户体验。

Abstract: As augmented large language models (LLMs) with external tools become increasingly popular in web applications, improving augmented LLM inference serving efficiency and optimizing service-level objectives (SLOs) are critical for enhancing user experience. To achieve this, inference systems must maximize request handling within latency constraints, referred to as increasing effective throughput. However, existing systems face two major challenges: (i) reliance on first-come-first-served (FCFS) scheduling causes severe head-of-line blocking, leading to queuing delays exceeding the SLOs for many requests; and (ii) static batch token limit, which fails to adapt to fluctuating loads and hardware conditions. Both of these factors degrade effective throughput and service quality.
  This paper presents AugServe, an efficient inference framework designed to reduce queueing latency and enhance effective throughput for augmented LLM inference services. The core idea of AugServe is a two-stage adaptive request scheduling strategy. Specifically, AugServe combines the inference features of augmented LLM requests to optimize the order of scheduling decisions (stage I). These decisions are continuously refined with runtime information (stage II), adapting to both request characteristics and system capabilities. In addition, AugServe dynamically adjusts the token batching mechanism based on hardware status and real-time load, further enhancing throughput performance. Experimental results show that AugServe achieves 4.7-33.1x and 3.3-13.2x higher effective throughput than vLLM and InferCept, while reducing time-to-first-token (TTFT) by up to 96.3% and 95.0%, respectively.

</details>


### [37] [Jina-VLM: Small Multilingual Vision Language Model](https://arxiv.org/abs/2512.04032)
*Andreas Koukounas,Georgios Mastrapas,Florian Hönicke,Sedigheh Eslami,Guillaume Roncari,Scott Martens,Han Xiao*

Main category: cs.CL

TL;DR: Jina-VLM是一个2.4B参数的多语言视觉语言模型，在2B规模的开源VLM中实现了最先进的多语言视觉问答性能。


<details>
  <summary>Details</summary>
Motivation: 开发一个在2B参数规模下具有竞争力的多语言视觉语言模型，能够在保持文本性能的同时，在视觉问答任务上超越同类模型。

Method: 结合SigLIP2视觉编码器和Qwen3语言骨干网络，通过注意力池化连接器实现任意分辨率图像的token高效处理。

Result: 在标准VQA基准测试和多语言评估中，Jina-VLM超越了可比模型，同时保持了有竞争力的纯文本性能。

Conclusion: Jina-VLM证明了通过精心设计的架构组合，可以在2B参数规模下实现多语言视觉问答的最先进性能。

Abstract: We present Jina-VLM, a 2.4B parameter vision-language model that achieves state-of-the-art multilingual visual question answering among open 2B-scale VLMs. The model couples a SigLIP2 vision encoder with a Qwen3 language backbone through an attention-pooling connector that enables token-efficient processing of arbitrary-resolution images. Across standard VQA benchmarks and multilingual evaluations, Jina-VLM outperforms comparable models while preserving competitive text-only performance.

</details>


### [38] [SkillFactory: Self-Distillation For Learning Cognitive Behaviors](https://arxiv.org/abs/2512.04072)
*Zayne Sprague,Jack Lu,Manya Wadhwa,Sedrick Keh,Mengye Ren,Greg Durrett*

Main category: cs.CL

TL;DR: SkillFactory是一种在强化学习前通过监督微调让模型学习认知技能的方法，通过重新组织模型自身输出来创建训练数据，帮助模型在RL后更好地泛化到更难任务


<details>
  <summary>Details</summary>
Motivation: 如何让模型掌握基础模型不具备的认知技能（如验证答案、回溯、尝试替代方法等），而不依赖于从更强模型的蒸馏

Method: 在强化学习前进行监督微调，使用模型自身样本重新组织成"银色"SFT轨迹，这些轨迹可能不完美但能帮助模型在RL阶段学习认知技能

Result: (1) SkillFactory SFT初始化帮助模型在RL后泛化到更难任务变体；(2) 模型确实使用了认知技能；(3) SkillFactory模型在域外任务上比基础模型更稳健

Conclusion: 在强化学习前学习的归纳偏置有助于模型学习稳健的认知技能使用，SkillFactory提供了一种不依赖蒸馏的方法来培养模型认知能力

Abstract: Reasoning models leveraging long chains of thought employ various cognitive skills, such as verification of their answers, backtracking, retrying by an alternate method, and more. Previous work has shown that when a base language model exhibits these skills, training that model further with reinforcement learning (RL) can learn to leverage them. How can we get models to leverage skills that aren't exhibited by base models? Our work, SkillFactory, is a method for fine-tuning models to roughly learn these skills during a supervised fine-tuning (SFT) stage prior to RL. Our approach does not rely on distillation from a stronger model, but instead uses samples from the model itself, rearranged to provide training data in the format of those skills. These "silver" SFT traces may be imperfect, but are nevertheless effective for priming a model to acquire skills during RL. Our evaluation shows that (1) starting from SkillFactory SFT initialization helps a model to generalize to harder variants of a task post-RL, despite lower performance pre-RL; (2) cognitive skills are indeed used by the model; (3) RLed SkillFactory models are more robust to regression on out-of-domain tasks than RLed base models. Our work suggests that inductive biases learned prior to RL help models learn robust cognitive skill use.

</details>


### [39] [Advancing Multi-Step Mathematical Reasoning in Large Language Models through Multi-Layered Self-Reflection with Auto-Prompting](https://arxiv.org/abs/2506.23888)
*André de Souza Loureiro,Jorge Valverde-Rebaza,Julieta Noguez,David Escarcega,Ricardo Marcacini*

Main category: cs.CL

TL;DR: MAPS框架通过结合思维链、自我反思和自动提示技术，提升LLMs在多步数学推理任务中的表现，在多个基准测试中优于标准CoT方法。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在问题解决能力上有所提升，但在处理复杂的多步推理任务时仍然存在困难，需要更有效的推理增强方法。

Method: 提出MAPS框架，采用迭代优化过程：首先使用思维链生成解决方案，当检测到错误时，自适应自我反思机制分析错误并生成定制化提示来指导修正，通过动态调整提示实现推理的迭代优化。

Result: 在四个基准测试和多个LLMs上的实验表明，MAPS显著优于标准CoT方法，并与推理优化模型达到竞争性结果，使通用LLMs能够达到与专用推理模型相当的性能水平。

Conclusion: MAPS通过战略性地限制反思深度，在成本和推理性能之间取得了最佳平衡，虽然更深的反思层能提高准确性，但也会增加令牌使用和成本。

Abstract: Recent advancements in Large Language Models (LLMs) have significantly improved their problem-solving capabilities. However, these models still struggle when faced with complex multi-step reasoning tasks. In this paper, we propose the Multi-Layered Self-Reflection with Auto-Prompting (MAPS) framework, a novel approach designed to enhance multi-step mathematical reasoning in LLMs by integrating techniques such as Chain of Thought (CoT), Self-Reflection, and Auto-Prompting. Unlike traditional static prompting methods, MAPS employs an iterative refinement process. Initially, the model generates a solution using CoT prompting. When errors are detected, an adaptive self-reflection mechanism identifies and analyzes them, generating tailored prompts to guide corrections. These dynamically adjusted prompts enable the model to iteratively refine its reasoning. Experiments on four well-established benchmarks across multiple LLMs show that MAPS significantly outperforms standard CoT and achieves competitive results with reasoning-optimized models. In addition, MAPS enables general-purpose LLMs to reach performance levels comparable to specialized reasoning models. While deeper reflection layers improve accuracy, they also increase token usage and costs. To balance this trade-off, MAPS strategically limits reflection depth, ensuring an optimal balance between cost and reasoning performance.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [40] [Exploring Syntropic Frameworks in AI Alignment: A Philosophical Investigation](https://arxiv.org/abs/2512.03048)
*Austin Spizzirri*

Main category: cs.AI

TL;DR: 论文提出将AI对齐重新构想为通过基于过程、多智能体、发展性机制来构建熵减的、理由响应的智能体，而非编码固定的人类价值内容。


<details>
  <summary>Details</summary>
Motivation: 传统基于内容的价值规范方法存在结构性不稳定问题，包括"是-应该"鸿沟、价值多元主义和扩展框架问题，这构成了"规范陷阱"。

Method: 1) 提出"熵减"作为理解多智能体对齐动态的信息论框架；2) 基于相容论指导控制理论建立真实与模拟道德能力的功能区分；3) 设计具身实验范式和验证机制。

Result: 该框架生成了关于人工系统中价值涌现和道德能动性的具体、可证伪预测，但实证验证仍在进行中。

Conclusion: AI对齐应转向过程导向、多智能体、发展性的方法，通过熵减机制构建理由响应的智能体，而非试图编码固定的人类价值内容。

Abstract: I argue that AI alignment should be reconceived as architecting syntropic, reasons-responsive agents through process-based, multi-agent, developmental mechanisms rather than encoding fixed human value content. The paper makes three philosophical contributions. First, I articulate the ``specification trap'' argument demonstrating why content-based value specification appears structurally unstable due to the conjunction of the is-ought gap, value pluralism, and the extended frame problem. Second, I propose syntropy -- the recursive reduction of mutual uncertainty between agents through state alignment -- as an information-theoretic framework for understanding multi-agent alignment dynamics. Third, I establish a functional distinction between genuine and simulated moral capacity grounded in compatibilist theories of guidance control, coupled with an embodied experimental paradigm and verification regime providing operational criteria independent of phenomenological claims. This paper represents the philosophical component of a broader research program whose empirical validation is being developed in a separate project currently in preparation. While the framework generates specific, falsifiable predictions about value emergence and moral agency in artificial systems, empirical validation remains pending.

</details>


### [41] [Beyond the Black Box: A Cognitive Architecture for Explainable and Aligned AI](https://arxiv.org/abs/2512.03072)
*Hu Keyi*

Main category: cs.AI

TL;DR: 本文提出"权重计算主义"认知架构，通过逻辑原子和基本操作实现可解释的AGI，使用权重=收益×概率模型实现透明决策


<details>
  <summary>Details</summary>
Motivation: 当前AI范式作为"体验架构师"面临可解释性和价值对齐的根本挑战，需要一种基于第一原理的新认知架构来构建可信赖的通用人工智能

Method: 提出权重计算主义架构，将认知分解为不可分割的逻辑原子和两个基本操作：指向和比较。决策通过可解释的权重计算模型（权重=收益×概率）形式化，所有值可追溯到可审计的初始权重集。实现基于图算法计算引擎和全局工作空间工作流

Result: 该架构在未见过场景中实现了透明、类人的推理和鲁棒学习，为构建可信赖和对齐的AGI奠定了实践和理论基础

Conclusion: 权重计算主义是基于第一原理的可行AGI路径，通过原子分解实现根本可解释性、内在通用性和可追溯价值对齐，为解决当前AI挑战提供了新方向

Abstract: Current AI paradigms, as "architects of experience," face fundamental challenges in explainability and value alignment. This paper introduces "Weight-Calculatism," a novel cognitive architecture grounded in first principles, and demonstrates its potential as a viable pathway toward Artificial General Intelligence (AGI). The architecture deconstructs cognition into indivisible Logical Atoms and two fundamental operations: Pointing and Comparison. Decision-making is formalized through an interpretable Weight-Calculation model (Weight = Benefit * Probability), where all values are traceable to an auditable set of Initial Weights. This atomic decomposition enables radical explainability, intrinsic generality for novel situations, and traceable value alignment. We detail its implementation via a graph-algorithm-based computational engine and a global workspace workflow, supported by a preliminary code implementation and scenario validation. Results indicate that the architecture achieves transparent, human-like reasoning and robust learning in unprecedented scenarios, establishing a practical and theoretical foundation for building trustworthy and aligned AGI.

</details>


### [42] [When Do Symbolic Solvers Enhance Reasoning in Large Language Models?](https://arxiv.org/abs/2512.03272)
*Zhiyuan He,Dingmin Wang*

Main category: cs.AI

TL;DR: 论文探讨了符号求解器集成方法何时能增强传统长思维链推理，发现该方法仅在问题需要有限隐式推理但涉及充分搜索空间时有效，在需要重复回溯的约束满足问题上显著提升LLM性能。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型通过生成长思维链在复杂推理任务上表现良好，但这种方法可能导致大量token开销，甚至因"过度思考"产生冗长推理链而导致错误答案。符号求解器集成方法利用LLM的代码生成能力将推理任务转化为可执行代码，然后用符号求解器解决，但何时传统长思维链能被符号求解器增强仍是一个开放问题。

Method: 研究采用符号求解器集成方法，将LLM的代码生成能力与符号求解器结合，将推理任务转化为可执行代码。通过实验比较传统长思维链方法与符号求解器集成方法在不同类型问题上的表现。

Result: 实验结果显示：1) 符号求解器集成方法仅在问题需要有限隐式推理但涉及充分搜索空间时有效；2) GPT-4o等最新LLM在推理深度较浅的演绎问题上表现更好；3) 符号求解器集成方法在需要重复回溯的约束满足问题上显著提升LLM性能；4) 提供声明式示例时，即使是CodeLlama-13B也能在困难的斑马谜题上超越GPT-4o。

Conclusion: 符号求解器集成方法对传统长思维链推理的增强效果具有选择性，特别适用于需要大量搜索和回溯的约束满足问题，而在需要深度隐式推理的问题上优势有限。该方法为LLM推理提供了有效的补充策略。

Abstract: Large Reasoning Models (LRMs) achieve strong performance on complex reasoning tasks by generating long Chains of Thought (CoTs). However, this paradigm might incur substantial token overhead, especially when models "overthink" by producing lengthy reasoning chains, which can even lead to incorrect answers. A promising direction is the symbolic-solver-integrated approach, which leverages the code generation capabilities of LLMs to translate reasoning tasks into executable code and then solve them with a symbolic solver. In this paper, we explore an open question of when the conventional long-CoT can be enhanced by symbolic solvers. Our experimental results show that the symbolic-solver-integrated method only helps when the problem requires limited implicit reasoning but involves an ample search space. The latest LLMs, like GPT-4o, show better performance on deductive problems with shallow reasoning depth, while the symbolic-solver-integrated method significantly improves the LLMs' performance in constraint satisfaction problems that require repeated backtracks. When a declarative exemplar is provided, even CodeLlama-13B can outperform GPT-4o in difficult Zebra puzzles.

</details>


### [43] [Prior preferences in active inference agents: soft, hard, and goal shaping](https://arxiv.org/abs/2512.03293)
*Filippo Torresan,Ryota Kanai,Manuel Baltieri*

Main category: cs.AI

TL;DR: 研究比较了主动推理中四种偏好分布定义方式（硬/软目标、有无目标塑造）在网格世界导航任务中的表现，发现目标塑造能提升性能但会牺牲对环境的探索学习。


<details>
  <summary>Details</summary>
Motivation: 主动推理使用期望自由能作为规划决策目标，但文献中很少关注偏好分布应如何定义以及不同定义方式对推理和学习的影响。本研究旨在填补这一空白。

Method: 考虑了四种定义偏好分布的方式：硬目标vs软目标、有无目标塑造（中间目标）。在网格世界导航任务中比较了使用这四种偏好分布的智能体表现。

Result: 目标塑造能带来最佳整体性能（促进利用），但会牺牲对环境转移动态的学习（阻碍探索）。

Conclusion: 偏好分布的定义方式对主动推理智能体的表现有重要影响，目标塑造在提升性能的同时会减少探索，需要在利用和探索之间权衡。

Abstract: Active inference proposes expected free energy as an objective for planning and decision-making to adequately balance exploitative and explorative drives in learning agents. The exploitative drive, or what an agent wants to achieve, is formalised as the Kullback-Leibler divergence between a variational probability distribution, updated at each inference step, and a preference probability distribution that indicates what states or observations are more likely for the agent, hence determining the agent's goal in a certain environment. In the literature, the questions of how the preference distribution should be specified and of how a certain specification impacts inference and learning in an active inference agent have been given hardly any attention. In this work, we consider four possible ways of defining the preference distribution, either providing the agents with hard or soft goals and either involving or not goal shaping (i.e., intermediate goals). We compare the performances of four agents, each given one of the possible preference distributions, in a grid world navigation task. Our results show that goal shaping enables the best performance overall (i.e., it promotes exploitation) while sacrificing learning about the environment's transition dynamics (i.e., it hampers exploration).

</details>


### [44] [Evaluating Generalization Capabilities of LLM-Based Agents in Mixed-Motive Scenarios Using Concordia](https://arxiv.org/abs/2512.03318)
*Chandler Smith,Marwa Abdulhai,Manfred Diaz,Marko Tesic,Rakshit S. Trivedi,Alexander Sasha Vezhnevets,Lewis Hammond,Jesse Clifton,Minsuk Chang,Edgar A. Duéñez-Guzmán,John P. Agapiou,Jayd Matyas,Danny Karmon,Akash Kundu,Aliaksei Korshuk,Ananya Ananya,Arrasy Rahman,Avinaash Anand Kulandaivel,Bain McHale,Beining Zhang,Buyantuev Alexander,Carlos Saith Rodriguez Rojas,Caroline Wang,Chetan Talele,Chenao Liu,Chichen Lin,Diana Riazi,Di Yang Shi,Emanuel Tewolde,Elizaveta Tennant,Fangwei Zhong,Fuyang Cui,Gang Zhao,Gema Parreño Piqueras,Hyeonggeun Yun,Ilya Makarov,Jiaxun Cui,Jebish Purbey,Jim Dilkes,Jord Nguyen,Lingyun Xiao,Luis Felipe Giraldo,Manuela Chacon-Chamorro,Manuel Sebastian Rios Beltran,Marta Emili García Segura,Mengmeng Wang,Mogtaba Alim,Nicanor Quijano,Nico Schiavone,Olivia Macmillan-Scott,Oswaldo Peña,Peter Stone,Ram Mohan Rao Kadiyala,Rolando Fernandez,Ruben Manrique,Sunjia Lu,Sheila A. McIlraith,Shamika Dhuri,Shuqing Shi,Siddhant Gupta,Sneheel Sarangi,Sriram Ganapathi Subramanian,Taehun Cha,Toryn Q. Klassen,Wenming Tu,Weijian Fan,Wu Ruiyang,Xue Feng,Yali Du,Yang Liu,Yiding Wang,Yipeng Kang,Yoonchang Sung,Yuxuan Chen,Zhaowei Zhang,Zhihan Wang,Zhiqiang Wu,Ziang Chen,Zilong Zheng,Zixia Jia,Ziyan Wang,Dylan Hadfield-Menell,Natasha Jaques,Tim Baarslag,Jose Hernandez-Orallo,Joel Z. Leibo*

Main category: cs.AI

TL;DR: 该论文提出了一种评估LLM智能体在零样本混合动机环境中合作能力的方法，使用Concordia自然语言多智能体模拟环境，发现当前智能体在需要说服和规范执行的场景中合作能力存在显著差距。


<details>
  <summary>Details</summary>
Motivation: LLM智能体在社会互动方面展现出强大能力，并越来越多地部署在与人类和人工智能体交互的场景中。然而，现有评估方法无法衡量这些能力如何泛化到新的社会情境，这是LLM智能体发展的关键前沿问题。

Method: 引入一种评估LLM智能体在零样本混合动机环境中合作能力的方法，使用Concordia自然语言多智能体模拟环境。该方法通过测试智能体在不同伙伴和情境中识别和利用互利机会的能力来衡量一般合作智能。

Result: 基于NeurIPS 2024 Concordia竞赛的实证结果显示，当前智能体能力与实现可靠合作所需的稳健泛化之间存在显著差距，特别是在需要说服和规范执行的场景中。

Conclusion: LLM智能体在合作能力方面仍需显著改进，特别是在复杂社会情境中的泛化能力。Concordia评估框架为衡量和提升智能体的合作智能提供了重要工具。

Abstract: Large Language Model (LLM) agents have demonstrated impressive capabilities for social interaction and are increasingly being deployed in situations where they might engage with both human and artificial agents. These interactions represent a critical frontier for LLM-based agents, yet existing evaluation methods fail to measure how well these capabilities generalize to novel social situations. In this paper, we introduce a method for evaluating the ability of LLM-based agents to cooperate in zero-shot, mixed-motive environments using Concordia, a natural language multi-agent simulation environment. Our method measures general cooperative intelligence by testing an agent's ability to identify and exploit opportunities for mutual gain across diverse partners and contexts. We present empirical results from the NeurIPS 2024 Concordia Contest, where agents were evaluated on their ability to achieve mutual gains across a suite of diverse scenarios ranging from negotiation to collective action problems. Our findings reveal significant gaps between current agent capabilities and the robust generalization required for reliable cooperation, particularly in scenarios demanding persuasion and norm enforcement.

</details>


### [45] [Multimodal Reinforcement Learning with Agentic Verifier for AI Agents](https://arxiv.org/abs/2512.03438)
*Reuben Tan,Baolin Peng,Zhengyuan Yang,Hao Cheng,Oier Mees,Theodore Zhao,Andrea Tupini,Isar Meijier,Qianhui Wu,Yuncong Yang,Lars Liden,Yu Gu,Sheng Zhang,Xiaodong Liu,Lijuan Wang,Marc Pollefeys,Yong Jae Lee,Jianfeng Gao*

Main category: cs.AI

TL;DR: Argos是一个用于多模态强化学习的智能奖励代理，通过动态选择评分函数来评估最终答案、时空定位和推理过程质量，显著提升多模态推理模型的训练效果。


<details>
  <summary>Details</summary>
Motivation: 当前多模态强化学习模型主要使用基于最终结果的稀疏奖励，缺乏对推理过程的细粒度指导。不同样本需要不同的评分函数，且教师模型可能提供噪声奖励信号，因此需要更智能的奖励机制。

Method: 提出Argos智能奖励代理，为每个样本从教师模型和基于规则的评分函数池中动态选择，同时评估：1）最终答案准确性；2）实体和动作的时空定位；3）推理过程质量。该机制用于SFT数据筛选和RL训练。

Result: 在空间推理、视觉幻觉、机器人和具身AI等多个智能任务上取得最先进结果。证明仅依赖SFT后训练会导致模型在RL中崩溃到非接地解，而在线验证能防止奖励黑客行为。

Conclusion: Argos通过帕累托最优性理论验证其有效性，为多模态强化学习提供了更精细的奖励机制，显著提升智能推理模型的训练效果和泛化能力。

Abstract: Agentic reasoning models trained with multimodal reinforcement learning (MMRL) have become increasingly capable, yet they are almost universally optimized using sparse, outcome-based rewards computed based on the final answers. Richer rewards computed from the reasoning tokens can improve learning significantly by providing more fine-grained guidance. However, it is challenging to compute more informative rewards in MMRL beyond those based on outcomes since different samples may require different scoring functions and teacher models may provide noisy reward signals too. In this paper, we introduce the Argos (Agentic Reward for Grounded & Objective Scoring), a principled reward agent to train multimodal reasoning models for agentic tasks. For each sample, Argos selects from a pool of teacher-model derived and rule-based scoring functions to simultaneously evaluate: (i) final response accuracy, (ii) spatiotemporal localization of referred entities and actions, and (iii) the quality of the reasoning process. We find that by leveraging our agentic verifier across both SFT data curation and RL training, our model achieves state-of-the-art results across multiple agentic tasks such as spatial reasoning, visual hallucination as well as robotics and embodied AI benchmarks. Critically, we demonstrate that just relying on SFT post-training on highly curated reasoning data is insufficient, as agents invariably collapse to ungrounded solutions during RL without our online verification. We also show that our agentic verifier can help to reduce reward-hacking in MMRL. Finally, we also provide a theoretical justification for the effectiveness of Argos through the concept of pareto-optimality.

</details>


### [46] [Multi-Agent Reinforcement Learning with Communication-Constrained Priors](https://arxiv.org/abs/2512.03528)
*Guang Yang,Tianpei Yang,Jingwen Qiao,Yanqing Wu,Jing Huo,Xingguo Chen,Yang Gao*

Main category: cs.AI

TL;DR: 提出一个通信受限的多智能体强化学习框架，通过区分有损和无损消息，量化通信影响，提升在复杂动态环境中的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现实世界中普遍存在有损通信问题，现有多智能体强化学习方法由于可扩展性和鲁棒性有限，难以应用于复杂动态环境

Method: 提出广义通信约束模型统一描述不同场景通信条件；作为学习先验区分有损/无损消息；使用双重互信息估计器解耦消息对分布式决策的影响；将通信消息影响量化到全局奖励中

Result: 在多个通信受限基准测试中验证了方法的有效性

Conclusion: 提出的通信约束多智能体强化学习框架能够有效处理现实世界中的有损通信问题，提升系统在复杂动态环境中的性能

Abstract: Communication is one of the effective means to improve the learning of cooperative policy in multi-agent systems. However, in most real-world scenarios, lossy communication is a prevalent issue. Existing multi-agent reinforcement learning with communication, due to their limited scalability and robustness, struggles to apply to complex and dynamic real-world environments. To address these challenges, we propose a generalized communication-constrained model to uniformly characterize communication conditions across different scenarios. Based on this, we utilize it as a learning prior to distinguish between lossy and lossless messages for specific scenarios. Additionally, we decouple the impact of lossy and lossless messages on distributed decision-making, drawing on a dual mutual information estimatior, and introduce a communication-constrained multi-agent reinforcement learning framework, quantifying the impact of communication messages into the global reward. Finally, we validate the effectiveness of our approach across several communication-constrained benchmarks.

</details>


### [47] [PARC: An Autonomous Self-Reflective Coding Agent for Robust Execution of Long-Horizon Tasks](https://arxiv.org/abs/2512.03549)
*Yuki Orimo,Iori Kurata,Hodaka Mori,Ryuhei Okuno,Ryohto Sawada,Daisuke Okanohara*

Main category: cs.AI

TL;DR: PARC是一个用于自主执行长期计算任务的编码代理，采用分层多智能体架构，具备自我评估和反馈机制，能够在材料科学和Kaggle竞赛中自主完成复杂任务。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统在执行长期计算任务时缺乏自主性和鲁棒性，需要开发能够独立检测和纠正错误、持续进展无需人工干预的系统。

Method: 采用分层多智能体架构，包含任务规划、执行、自我评估和反馈机制，能够从独立上下文评估自身行为和结果。

Result: 在材料科学中成功复现锂离子传导和合金偏析研究的关键结果，协调数十个并行模拟任务（每个约43小时计算）；在Kaggle实验中从自然语言指令开始，生成与人工设计基准竞争的解决方案。

Conclusion: 分层多智能体系统与自我评估反馈机制的结合，能够实现AI系统独立进行大规模科学和分析工作的潜力。

Abstract: We introduce PARC, a coding agent for the autonomous and robust execution of long-horizon computational tasks. PARC is built on a hierarchical multi-agent architecture incorporating task planning, execution, and a mechanism that evaluates its own actions and their outcomes from an independent context and provides feedback, namely self-assessment and self-feedback. This design enables PARC to detect and correct high-level strategic errors and sustain progress without human intervention. We evaluate PARC across computational science and data science tasks. In materials science, it autonomously reproduces key results from studies on lithium-ion conduction and alloy segregation. In particular, it coordinates dozens of parallel simulation tasks, each requiring roughly 43 hours of computation, managing orchestration, monitoring, and error correction end-to-end. In Kaggle-based experiments, starting from minimal natural-language instructions, PARC conducts data analysis and implements search strategies, producing solutions competitive with human-engineered baselines. These results highlight the potential of integrating a hierarchical multi-agent system with self-assessment and self-feedback to enable AI systems capable of independent, large-scale scientific and analytical work.

</details>


### [48] [Reason-Plan-ReAct: A Reasoner-Planner Supervising a ReAct Executor for Complex Enterprise Tasks](https://arxiv.org/abs/2512.03560)
*Gianni Molinari,Fabio Ciravegna*

Main category: cs.AI

TL;DR: RP-ReAct是一种新颖的多智能体方法，将战略规划与低级执行解耦，通过Reasoner Planner Agent进行规划分析，Proxy-Execution Agent执行工具交互，并采用上下文保存策略管理大型工具输出，在复杂任务中实现卓越的可靠性和效率。


<details>
  <summary>Details</summary>
Motivation: 当前自主智能体在企业领域解决复杂任务时面临两个主要限制：1) 单智能体架构的单一规划-执行循环导致轨迹不稳定；2) 为数据隐私使用本地开放权重模型时，较小的上下文窗口会快速消耗大型工具输出的上下文。

Method: RP-ReAct采用多智能体架构，包含Reasoner Planner Agent（RPA）负责使用大型推理模型进行子步骤规划和执行结果分析，以及一个或多个Proxy-Execution Agent（PEA）使用ReAct方法将子步骤转换为具体工具交互。关键创新是PEA中的上下文保存策略，通过外部存储和按需访问管理大型工具输出，缓解上下文窗口溢出问题。

Result: 在具有挑战性的多领域ToolQA基准测试中，使用六种开放权重推理模型进行评估，RP-ReAct在解决跨领域复杂任务时实现了优于最先进基线的性能和改进的泛化能力。同时证明了该方法在不同模型规模下的增强鲁棒性和稳定性。

Conclusion: RP-ReAct通过解耦战略规划与低级执行，结合上下文管理策略，为企业领域提供了有效且可部署的智能体解决方案，解决了现有方法在复杂任务中的可靠性和效率问题。

Abstract: Despite recent advances, autonomous agents often struggle to solve complex tasks in enterprise domains that require coordinating multiple tools and processing diverse data sources. This struggle is driven by two main limitations. First, single-agent architectures enforce a monolithic plan-execute loop, which directly causes trajectory instability. Second, the requirement to use local open-weight models for data privacy introduces smaller context windows leading to the rapid consumption of context from large tool outputs. To solve this problem we introduce RP-ReAct (Reasoner Planner-ReAct), a novel multi-agent approach that fundamentally decouples strategic planning from low-level execution to achieve superior reliability and efficiency. RP-ReAct consists of a Reasoner Planner Agent (RPA), responsible for planning each sub-step, continuously analysing the execution results using the strong reasoning capabilities of a Large Reasoning Model, and one or multiple Proxy-Execution Agent (PEA) that translates sub-steps into concrete tool interactions using a ReAct approach. Crucially, we incorporate a context-saving strategy within the PEA to mitigate context window overflow by managing large tool outputs via external storage and on-demand access. We evaluate RP-ReAct, on the challenging, multi-domain ToolQA benchmark using a diverse set of six open-weight reasoning models. Our empirical results show that RP-ReAct achieves superior performance and improved generalization ability over state-of-the-art baselines when addressing diverse complex tasks across the evaluated domains. Furthermore we establish the enhanced robustness and stability of our approach across different model scales, paving the way for effective and deployable agentic solutions for enterprises.

</details>


### [49] [EnCompass: Enhancing Agent Programming with Search Over Program Execution Paths](https://arxiv.org/abs/2512.03571)
*Zhening Li,Armando Solar-Lezama,Yisong Yue,Stephan Zheng*

Main category: cs.AI

TL;DR: 提出PAN编程模型，通过分离核心工作流逻辑和推理时策略，简化LLM智能体开发


<details>
  <summary>Details</summary>
Motivation: 当前智能体编程方法通常将核心工作流逻辑和推理时策略（如树搜索）耦合在一起，导致开发不够灵活

Method: 引入"概率天使非确定性"（PAN）编程模型，使用Python装饰器将智能体工作流程序编译为搜索空间，实现EnCompass框架

Result: 通过三个案例研究证明，该框架能让程序员快速提升智能体可靠性，轻松切换不同推理时策略，且代码增量很少

Conclusion: PAN编程模型成功分离了智能体设计的两个关键方面，提供了更灵活、可维护的LLM智能体开发方法

Abstract: We introduce a new approach to agent programming, the development of LLM-based agents. Current approaches to agent programming often entangle two aspects of agent design: the core workflow logic and the inference-time strategy (e.g., tree search). We introduce "probabilistic angelic nondeterminism" ("PAN"), a programming model that disentangles these two concerns, allowing the programmer to describe the agent workflow and independently experiment with different inference-time strategies by simply changing a few inputs. We provide an implementation of PAN in Python as the EnCompass framework, which uses a Python decorator to compile agent workflow programs into a search space. We present three case studies that demonstrate how the framework lets the programmer quickly improve the reliability of an agent and easily switch between different inference-time strategies, all with little additional coding.

</details>


### [50] [DeepRule: An Integrated Framework for Automated Business Rule Generation via Deep Predictive Modeling and Hybrid Search Optimization](https://arxiv.org/abs/2512.03607)
*Yusen Wu,Xiaotie Deng*

Main category: cs.AI

TL;DR: DeepRule是一个用于零售品类和定价优化的自动化业务规则生成框架，通过LLM语义解析、博弈论约束优化和可解释决策蒸馏，解决理论模型与现实经济复杂性之间的差距。


<details>
  <summary>Details</summary>
Motivation: 解决现有理论模型与真实世界经济复杂性之间的系统性错配，特别是数据模态不匹配（非结构化文本）、动态特征纠缠（非线性价格弹性）和操作不可行性（多层业务约束）三大关键差距。

Method: 采用三层架构：1) 混合知识融合引擎使用LLM深度语义解析非结构化文本；2) 博弈论约束优化机制通过双边效用函数动态协调供应链利益；3) 可解释决策蒸馏接口利用LLM引导的符号回归优化定价策略和可审计业务规则。

Result: 在真实零售环境中验证，相比系统性B2C基线获得更高利润，同时确保操作可行性，建立了从非结构化知识注入到多智能体优化再到可解释策略合成的闭环管道。

Conclusion: DeepRule建立了统一非结构化知识注入、多智能体优化和可解释策略合成的闭环管道，为真实经济智能提供系统化解决方案，弥合了理论模型与现实经济复杂性之间的差距。

Abstract: This paper proposes DeepRule, an integrated framework for automated business rule generation in retail assortment and pricing optimization. Addressing the systematic misalignment between existing theoretical models and real-world economic complexities, we identify three critical gaps: (1) data modality mismatch where unstructured textual sources (e.g. negotiation records, approval documents) impede accurate customer profiling; (2) dynamic feature entanglement challenges in modeling nonlinear price elasticity and time-varying attributes; (3) operational infeasibility caused by multi-tier business constraints.
  Our framework introduces a tri-level architecture for above challenges. We design a hybrid knowledge fusion engine employing large language models (LLMs) for deep semantic parsing of unstructured text, transforming distributor agreements and sales assessments into structured features while integrating managerial expertise. Then a game-theoretic constrained optimization mechanism is employed to dynamically reconcile supply chain interests through bilateral utility functions, encoding manufacturer-distributor profit redistribution as endogenous objectives under hierarchical constraints. Finally an interpretable decision distillation interface leveraging LLM-guided symbolic regression to find and optimize pricing strategies and auditable business rules embeds economic priors (e.g. non-negative elasticity) as hard constraints during mathematical expression search. We validate the framework in real retail environments achieving higher profits versus systematic B2C baselines while ensuring operational feasibility. This establishes a close-loop pipeline unifying unstructured knowledge injection, multi-agent optimization, and interpretable strategy synthesis for real economic intelligence.

</details>


### [51] [MemVerse: Multimodal Memory for Lifelong Learning Agents](https://arxiv.org/abs/2512.03627)
*Junming Liu,Yifei Sun,Weihua Cheng,Haodong Lei,Yirong Chen,Licheng Wen,Xuemeng Yang,Daocheng Fu,Pinlong Cai,Nianchen Deng,Yi Yu,Shuyue Hu,Botian Shi,Ding Wang*

Main category: cs.AI

TL;DR: MemVerse是一个模型无关的即插即用记忆框架，通过结合快速参数化回忆和分层检索式记忆，解决AI代理的记忆问题，支持多模态智能的扩展和适应。


<details>
  <summary>Details</summary>
Motivation: 尽管大规模语言和视觉模型发展迅速，但AI代理仍存在根本限制：无法记忆。没有可靠的记忆，代理会灾难性遗忘过去经验，难以进行长时程推理，在多模态或交互环境中无法连贯操作。

Method: MemVerse采用模型无关的即插即用架构，结合快速参数化回忆和分层检索式记忆。它维护短期记忆处理近期上下文，将原始多模态经验转化为结构化长期记忆，组织为分层知识图谱。引入周期性蒸馏机制，将长期记忆中的关键知识压缩到参数化模型中，实现快速可微回忆。

Result: 大量实验表明，MemVerse显著提升了多模态推理和持续学习效率，使代理能够在扩展交互中记忆、适应和连贯推理。

Conclusion: MemVerse通过桥接参数化记忆和检索式记忆，解决了AI代理的记忆限制问题，支持持续整合、自适应遗忘和有界内存增长，为可扩展的自适应多模态智能提供了有效框架。

Abstract: Despite rapid progress in large-scale language and vision models, AI agents still suffer from a fundamental limitation: they cannot remember. Without reliable memory, agents catastrophically forget past experiences, struggle with long-horizon reasoning, and fail to operate coherently in multimodal or interactive environments. We introduce MemVerse, a model-agnostic, plug-and-play memory framework that bridges fast parametric recall with hierarchical retrieval-based memory, enabling scalable and adaptive multimodal intelligence. MemVerse maintains short-term memory for recent context while transforming raw multimodal experiences into structured long-term memories organized as hierarchical knowledge graphs. This design supports continual consolidation, adaptive forgetting, and bounded memory growth. To handle real-time demands, MemVerse introduces a periodic distillation mechanism that compresses essential knowledge from long-term memory into the parametric model, allowing fast, differentiable recall while preserving interpretability. Extensive experiments demonstrate that MemVerse significantly improves multimodal reasoning and continual learning efficiency, empowering agents to remember, adapt, and reason coherently across extended interactions.

</details>


### [52] [RoCo: Role-Based LLMs Collaboration for Automatic Heuristic Design](https://arxiv.org/abs/2512.03762)
*Jiawei Xu,Fengfeng Wei,Weineng Chen*

Main category: cs.AI

TL;DR: RoCo是一个基于多智能体角色协作的系统，通过四个专门化的LLM智能体（探索者、利用者、批评者、整合者）协同生成高质量启发式算法，在组合优化问题的自动启发式设计中取得优越性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的自动启发式设计研究通常只考虑单一角色，限制了启发式算法的多样性和质量。为了解决这个问题，需要设计一个能够通过多角色协作来增强启发式设计多样性和质量的系统。

Method: 提出RoCo多智能体角色协作系统，包含四个专门化的LLM智能体：探索者（促进长期潜力，注重创造性多样性）、利用者（关注短期改进，进行保守的效率优化）、批评者（评估进化步骤并提供反馈）、整合者（综合探索者和利用者的建议，平衡创新与利用）。这些智能体通过结构化的多轮过程进行交互，包括反馈、细化和精英变异，同时考虑短期和长期反思。

Result: 在五个不同的组合优化问题上，在白盒和黑盒设置下进行评估。实验结果表明，RoCo实现了优越的性能，在白盒和黑盒场景中都能生成优于现有方法（包括ReEvo和HSEvo）的竞争性启发式算法。

Conclusion: 这种基于角色的协作范式为鲁棒且高性能的自动启发式设计建立了新标准，通过多角色协作有效提升了启发式设计的多样性和质量。

Abstract: Automatic Heuristic Design (AHD) has gained traction as a promising solution for solving combinatorial optimization problems (COPs). Large Language Models (LLMs) have emerged and become a promising approach to achieving AHD, but current LLM-based AHD research often only considers a single role. This paper proposes RoCo, a novel Multi-Agent Role-Based System, to enhance the diversity and quality of AHD through multi-role collaboration. RoCo coordinates four specialized LLM-guided agents-explorer, exploiter, critic, and integrator-to collaboratively generate high-quality heuristics. The explorer promotes long-term potential through creative, diversity-driven thinking, while the exploiter focuses on short-term improvements via conservative, efficiency-oriented refinements. The critic evaluates the effectiveness of each evolution step and provides targeted feedback and reflection. The integrator synthesizes proposals from the explorer and exploiter, balancing innovation and exploitation to drive overall progress. These agents interact in a structured multi-round process involving feedback, refinement, and elite mutations guided by both short-term and accumulated long-term reflections. We evaluate RoCo on five different COPs under both white-box and black-box settings. Experimental results demonstrate that RoCo achieves superior performance, consistently generating competitive heuristics that outperform existing methods including ReEvo and HSEvo, both in white-box and black-box scenarios. This role-based collaborative paradigm establishes a new standard for robust and high-performing AHD.

</details>


### [53] [Omni-AutoThink: Adaptive Multimodal Reasoning via Reinforcement Learning](https://arxiv.org/abs/2512.03783)
*Dongchao Yang,Songxiang Liu,Disong Wang,Yuanyuan Wang,Guanglu Wan,Helen Meng*

Main category: cs.AI

TL;DR: 提出Omni-AutoThink框架，通过自适应调整推理深度来解决现有Omni模型推理行为僵化的问题，包含自适应监督微调和自适应强化学习两个阶段，并在多模态推理基准上取得显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有Omni模型在推理行为上存在僵化问题：要么对简单问题过度推理，要么在需要推理时无法有效推理。需要一种能够根据任务难度动态调整推理深度的自适应推理框架。

Method: 提出两阶段框架：1) 自适应监督微调阶段，使用大规模推理增强数据赋予模型基础推理能力；2) 自适应强化学习阶段，基于任务复杂度和奖励反馈优化推理行为。同时构建了涵盖文本、文本-音频、文本-视觉、文本-音频-视觉多模态的自适应推理基准。

Result: 实验结果表明，提出的框架相比先前基线在自适应推理性能上有显著提升。所有基准数据和代码将公开。

Conclusion: Omni-AutoThink通过自适应调整推理深度有效解决了现有Omni模型推理行为僵化的问题，在多模态推理任务上表现出色，为自适应推理提供了新的解决方案。

Abstract: Recent advances in Omni models have enabled unified multimodal perception and generation. However, most existing systems still exhibit rigid reasoning behaviors, either overthinking simple problems or failing to reason when necessary. To address this limitation, we propose Omni-AutoThink, a novel adaptive reasoning framework that dynamically adjusts the model's reasoning depth according to task difficulty. Our framework comprises two stages: (1) an Adaptive Supervised Fine-Tuning (Adaptive SFT) stage, which endows the Omni model with fundamental reasoning capability using large-scale reasoning-augmented data, and (2) an Adaptive Reinforcement Learning (Adaptive GRPO) stage, which optimizes reasoning behaviors based on task complexity and reward feedback. We further construct a comprehensive adaptive reasoning benchmark that spans text-only, text-audio, text-visual, and text-audio-visual modalities, providing both training and evaluation splits for multimodal reasoning assessment. Experimental results demonstrate that our proposed framework significantly improves adaptive reasoning performance compared to previous baselines. All benchmark data and code will be publicly released.

</details>


### [54] [A Hierarchical Tree-based approach for creating Configurable and Static Deep Research Agent (Static-DRA)](https://arxiv.org/abs/2512.03887)
*Saurav Prateek*

Main category: cs.AI

TL;DR: 提出Static-DRA：基於樹狀靜態工作流的深度研究代理，通過Depth和Breadth參數讓用戶在報告質量與計算成本間取得平衡。


<details>
  <summary>Details</summary>
Motivation: 為克服靜態RAG管道在處理複雜多輪研究任務時的局限性，需要開發更靈活的深度研究代理系統。

Method: 採用可配置的層次化樹狀靜態工作流，包含Supervisor、Independent和Worker三類代理，通過Depth和Breadth參數控制研究強度。

Result: 在DeepResearch Bench上使用RACE框架評估，Depth=2、Breadth=5配置下獲得34.72分，驗證參數增加能提升研究深度和評分。

Conclusion: Static-DRA提供實用且資源感知的解決方案，讓用戶能透明地控制深度研究過程，實現質量與成本的平衡。

Abstract: The advancement in Large Language Models has driven the creation of complex agentic systems, such as Deep Research Agents (DRAs), to overcome the limitations of static Retrieval Augmented Generation (RAG) pipelines in handling complex, multi-turn research tasks. This paper introduces the Static Deep Research Agent (Static-DRA), a novel solution built upon a configurable and hierarchical Tree-based static workflow.
  The core contribution is the integration of two user-tunable parameters, Depth and Breadth, which provide granular control over the research intensity. This design allows end-users to consciously balance the desired quality and comprehensiveness of the research report against the associated computational cost of Large Language Model (LLM) interactions. The agent's architecture, comprising Supervisor, Independent, and Worker agents, facilitates effective multi-hop information retrieval and parallel sub-topic investigation.
  We evaluate the Static-DRA against the established DeepResearch Bench using the RACE (Reference-based Adaptive Criteria-driven Evaluation) framework. Configured with a depth of 2 and a breadth of 5, and powered by the gemini-2.5-pro model, the agent achieved an overall score of 34.72. Our experiments validate that increasing the configured Depth and Breadth parameters results in a more in-depth research process and a correspondingly higher evaluation score. The Static-DRA offers a pragmatic and resource-aware solution, empowering users with transparent control over the deep research process. The entire source code, outputs and benchmark results are open-sourced at https://github.com/SauravP97/Static-Deep-Research/

</details>


### [55] [Autonomous Agents and Policy Compliance: A Framework for Reasoning About Penalties](https://arxiv.org/abs/2512.03931)
*Vineel Tummala,Daniela Inclezan*

Main category: cs.AI

TL;DR: 提出一个基于逻辑编程的策略感知自主代理框架，能够推理违规惩罚并据此行动，在必要时允许偏离策略以实现高风险目标。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注确保合规性，但现实场景中为实现高风险目标可能需要偏离策略。同时，建模违规行为有助于政策制定者模拟真实的人类决策过程。

Method: 扩展Gelfond和Lobo的授权与义务策略语言(AOPL)以纳入惩罚机制，集成答案集编程(ASP)进行推理。开发从扩展AOPL到ASP的自动翻译，并改进ASP规划算法以考虑惩罚因素。

Result: 在两个领域实验中，该框架能生成更高质量的计划，避免有害行动，并在某些情况下提高计算效率。能够区分不同违规计划，优先选择惩罚最小的方案。

Conclusion: 该框架通过惩罚推理增强了自主决策能力，为政策制定者提供了有价值的模拟工具，有助于政策优化和改进。

Abstract: This paper presents a logic programming-based framework for policy-aware autonomous agents that can reason about potential penalties for non-compliance and act accordingly. While prior work has primarily focused on ensuring compliance, our approach considers scenarios where deviating from policies may be necessary to achieve high-stakes goals. Additionally, modeling non-compliant behavior can assist policymakers by simulating realistic human decision-making. Our framework extends Gelfond and Lobo's Authorization and Obligation Policy Language (AOPL) to incorporate penalties and integrates Answer Set Programming (ASP) for reasoning. Compared to previous approaches, our method ensures well-formed policies, accounts for policy priorities, and enhances explainability by explicitly identifying rule violations and their consequences. Building on the work of Harders and Inclezan, we introduce penalty-based reasoning to distinguish between non-compliant plans, prioritizing those with minimal repercussions. To support this, we develop an automated translation from the extended AOPL into ASP and refine ASP-based planning algorithms to account for incurred penalties. Experiments in two domains demonstrate that our framework generates higher-quality plans that avoid harmful actions while, in some cases, also improving computational efficiency. These findings underscore its potential for enhancing autonomous decision-making and informing policy refinement. Under consideration in Theory and Practice of Logic Programming (TPLP).

</details>


### [56] [Benchmark for Planning and Control with Large Language Model Agents: Blocksworld with Model Context Protocol](https://arxiv.org/abs/2512.03955)
*Niklas Jobs,Luis Miguel Vieira da Silva,Jayanth Somashekaraiah,Maximilian Weigand,David Kube,Felix Gehlhoff*

Main category: cs.AI

TL;DR: 提出一个基于Blocksworld问题的可执行仿真基准测试，使用MCP作为标准化工具接口，用于系统评估LLM智能体在工业自动化中的规划与执行能力


<details>
  <summary>Details</summary>
Motivation: 工业自动化需要灵活的适应策略，而基于LLM的智能体虽具潜力但缺乏标准化基准进行系统比较

Method: 创建包含五个复杂度类别的Blocksworld问题仿真环境，集成MCP作为标准化工具接口，允许不同智能体架构无需修改即可连接评估

Result: 通过单智能体实现验证了基准的适用性，建立了用于比较LLM规划与执行方法的定量指标

Conclusion: 该基准测试为系统评估和比较LLM智能体在自适应规划与执行方面的能力提供了标准化框架

Abstract: Industrial automation increasingly requires flexible control strategies that can adapt to changing tasks and environments. Agents based on Large Language Models (LLMs) offer potential for such adaptive planning and execution but lack standardized benchmarks for systematic comparison. We introduce a benchmark with an executable simulation environment representing the Blocksworld problem providing five complexity categories. By integrating the Model Context Protocol (MCP) as a standardized tool interface, diverse agent architectures can be connected to and evaluated against the benchmark without implementation-specific modifications. A single-agent implementation demonstrates the benchmark's applicability, establishing quantitative metrics for comparison of LLM-based planning and execution approaches.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [57] [Evaluating A/B Testing Methodologies via Sample Splitting: Theory and Practice](https://arxiv.org/abs/2512.03366)
*Ryan Kessler,James McQueen,Miikka Rokkanen*

Main category: econ.EM

TL;DR: 论文为A/B测试中的样本分割建立了理论框架，证明样本分割估计量对全样本性能有偏，但能一致估计样本分割类比性能，并提供了渐近分布、置信区间和偏差-方差权衡分析。


<details>
  <summary>Details</summary>
Motivation: 在A/B测试中，当真实影响无法观测时，需要评估新估计方法和决策规则的性能。样本分割（将数据分为两部分）是常用方法，但缺乏对其统计性质的理论理解，特别是估计量的偏差和方差特性。

Method: 开发理论框架分析样本分割估计量，推导其渐近分布，构建有效置信区间，并刻画样本分割设计选择中的偏差-方差权衡。通过模拟验证理论结果。

Result: 证明样本分割估计量对全样本性能有偏，但能一致估计样本分割类比性能。提供了渐近分布理论、有效置信区间构造方法，并揭示了样本分割设计中的偏差-方差权衡关系。

Conclusion: 为A/B测试产品评估新估计器和决策规则提供了理论指导和实施建议，建立了样本分割方法的理论基础，帮助实践者做出更好的设计选择。

Abstract: We develop a theoretical framework for sample splitting in A/B testing environments, where data for each test are partitioned into two splits to measure methodological performance when the true impacts of tests are unobserved. We show that sample-split estimators are generally biased for full-sample performance but consistently estimate sample-split analogues of it. We derive their asymptotic distributions, construct valid confidence intervals, and characterize the bias-variance trade-offs underlying sample-split design choices. We validate our theoretical results through simulations and provide implementation guidance for A/B testing products seeking to evaluate new estimators and decision rules.

</details>


### [58] [Estimation of Panel Data Models with Nonlinear Factor Structure](https://arxiv.org/abs/2512.03693)
*Christina Maschmann,Joakim Westerlund*

Main category: econ.EM

TL;DR: 提出SCCE估计量，通过结合CCE方法和样条方法，放宽交互效应模型中时间效应必须线性的假设，适用于更广泛的因子结构。


<details>
  <summary>Details</summary>
Motivation: 传统面板数据模型假设未观测的交互效应（时间效应）是线性的，但这种假设缺乏理论依据，仅因方便而沿用。需要更灵活的方法来处理非线性因子结构。

Method: 结合共同相关效应（CCE）方法和样条方法，提出SCCE估计量。CCE处理交互效应，样条方法允许非线性因子结构，保持计算简单性。

Result: SCCE估计量保留了CCE的计算简单性、良好的小样本和渐近性质，但适用于更广泛的因子结构，包括线性结构作为特例。

Conclusion: SCCE估计量为广泛的实证应用提供了更灵活的工具，放宽了传统模型对因子结构的限制性假设，同时保持了原有方法的优势。

Abstract: Panel data models with unobserved heterogeneity in the form of interactive effects standardly assume that the time effects - or "common factors" - enter linearly. This assumption is unnatural in the sense that it pertains to the unobserved component of the model, and there is rarely any reason to believe that this component takes on a particular functional form. This is in stark contrast to the relationship between the observables, which can often be credibly argued to be linear. Linearity in the factors has persevered mainly because it is convenient, and that it is better than standard fixed effects. The present paper relaxes this assumption. It does so by combining the common correlated effects (CCE) approach to standard interactive effects with the method of sieves. The new estimator - abbreviated "SCCE" - retains many of the advantages of CCE, including its computational simplicity, and good small-sample and asymptotic properties, but is applicable under a much broader class of factor structures that includes the linear one as a special case. This makes it well-suited for a wide range of empirical applications.

</details>


### [59] [Learning from crises: A new class of time-varying parameter VARs with observable adaptation](https://arxiv.org/abs/2512.03763)
*Nicolas Hardy,Dimitris Korobilis*

Main category: econ.EM

TL;DR: 提出自适应变参数VAR模型，用可观测外生变量驱动参数调整，替代传统TVP-VAR的潜在状态创新，简化估计并提高预测性能


<details>
  <summary>Details</summary>
Motivation: 传统时变参数VAR模型的参数变化可能过于缓慢，难以适应重大危机期间的急剧结构变化，需要更灵活但不过度参数化的方法

Method: 开发自适应变参数VAR模型，用宏观经济和金融指标的可观测外生变量线性组合驱动参数调整，将状态方程融入测量方程，实现简单线性估计

Result: 模拟显示自适应参数比传统TVP更简约，能有效约束参数动态而不牺牲灵活性；美国和欧元区实证表明AVP-VAR持续改进样本外预测，尤其在波动加剧时期

Conclusion: 自适应变参数VAR通过可观测变量驱动参数调整，提供更简约、易估计的框架，在危机时期显著提升预测性能，是传统TVP-VAR的有效替代

Abstract: We revisit macroeconomic time-varying parameter vector autoregressions (TVP-VARs), whose persistent coefficients may adapt too slowly to large, abrupt shifts such as those during major crises. We explore the performance of an adaptively-varying parameter (AVP) VAR that incorporates deterministic adjustments driven by observable exogenous variables, replacing latent state innovations with linear combinations of macroeconomic and financial indicators. This reformulation collapses the state equation into the measurement equation, enabling simple linear estimation of the model. Simulations show that adaptive parameters are substantially more parsimonious than conventional TVPs, effectively disciplining parameter dynamics without sacrificing flexibility. Using macroeconomic datasets for both the U.S. and the euro area, we demonstrate that AVP-VAR consistently improves out-of-sample forecasts, especially during periods of heightened volatility.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [60] [Aggregate then evaluate](https://arxiv.org/abs/2512.03396)
*Zachary Van Oosten,Ruodu Wang*

Main category: econ.TH

TL;DR: 本文区分了模糊决策的两种框架：先评估后聚合（ETA）和先聚合后评估（ATE），重点研究相对被忽视的ATE框架，提出了Choquet ATE模型并进行了公理化。


<details>
  <summary>Details</summary>
Motivation: 现有模糊决策模型大多属于ETA框架，而ATE框架在概念上同样有说服力但在文献中相对被忽视。本文旨在系统研究ATE框架，探索其理论价值和应用潜力。

Method: 提出Choquet ATE模型，该模型通过允许任意纯风险偏好来推广Choquet期望效用模型。在具有外生明确事件源的Savage设定中，为该模型提供了公理化基础。

Result: 成功建立了Choquet ATE框架，能够分析广泛的模糊态度及其与风险态度的相互作用。该框架为模糊决策提供了新的建模工具。

Conclusion: ATE框架是模糊决策中与ETA框架同等重要的替代方案，Choquet ATE模型为研究模糊态度与风险态度的交互提供了灵活的理论工具，填补了文献空白。

Abstract: We distinguish two frameworks for decisions under ambiguity: evaluate-then-aggregate (ETA) and aggregate-then-evaluate (ATE). Given a statistic that represents the decision maker's pure-risk preferences (such as expected utility) and an ambiguous act, an ETA model first evaluates the act under each plausible probabilistic model using this statistic and then aggregates the resulting evaluations according to ambiguity attitudes. In contrast, an ATE model first aggregates ambiguity by assigning the act a single representative distribution and then evaluates that distribution using the statistic. These frameworks differ in the order in which risk and ambiguity are processed, and they coincide when there is no ambiguity. While most existing ambiguity models fall within the ETA framework, our study focuses on the ATE framework, which is conceptually just as compelling and has been relatively neglected in the literature. We develop a Choquet ATE model, which generalizes the Choquet expected utility model by allowing arbitrary pure-risk preferences. We provide an axiomatization of this model in a Savage setting with an exogenous source of unambiguous events. The Choquet ATE framework allows us to analyze a wide range of ambiguity attitudes and their interplay with risk attitudes.

</details>


### [61] [From Micro-Distributions to Macro-Regularities: A Critique and Reconstruction of the Production Function Based on the Maximum Entropy Principle](https://arxiv.org/abs/2512.03812)
*Jihyuan Liuh*

Main category: econ.TH

TL;DR: 该论文基于统计物理学为柯布-道格拉斯生产函数提供微观基础，并批判其政治经济学含义。通过最大熵原理和尺度不变性公理，证明在不完全信息经济系统中，微观技术系数的最无偏分布必须是截断幂律分布，其统计加总自然导致宏观层面出现规模报酬不变的柯布-道格拉斯函数。


<details>
  <summary>Details</summary>
Motivation: 为柯布-道格拉斯生产函数提供不依赖代表性主体或资本价值加总的微观基础，同时揭示生产函数作为微观信息有损压缩的本质，批判其将社会历史关系"自然化"为永恒技术规律的政治经济学含义。

Method: 引入统计物理学的最大熵原理和尺度不变性公理，证明在不完全信息条件下，微观技术系数的最无偏分布为截断幂律分布，通过统计加总推导出宏观柯布-道格拉斯生产函数。

Result: 证明了柯布-道格拉斯生产函数是微观技术系数截断幂律分布的统计加总结果，为规模报酬不变的柯布-道格拉斯函数提供了微观基础，同时揭示了生产函数作为信息压缩工具的本质。

Conclusion: 柯布-道格拉斯生产函数本质上是微观信息的有损压缩，而非技术规律；在这一压缩过程中，分配参数中的社会历史关系被"自然化"为永恒技术法则，体现了马克思"拜物教"批判在数理逻辑层面的表现。

Abstract: This paper aims to provide a micro-foundation for the Cobb-Douglas production function based on statistical physics, and to launch a critique of its political-economic implications. By introducing the Maximum Entropy Principle and an axiom of scale invariance, we prove that in an economic system with incomplete information, the most unbiased distribution of micro-level technical coefficients must take the form of a truncated power law. Based on this, statistical aggregation naturally leads to the emergence of a constant-returns-to-scale Cobb-Douglas function at the macro level. This result not only provides a micro-foundation for neoclassical growth models that does not rely on a representative agent or value aggregation of capital but, more importantly, reveals that the aggregate production function is essentially a lossy compression of micro-level information. In this compression process, the social-historical relations embedded in distribution parameters are 'naturalized' into seemingly eternal technical laws, which is the manifestation of Marx's critique of 'fetishism' at the level of mathematical logic. This paper further deepens the understanding of the production function as a statistical phenomenon rather than a technical law through dialogues with Marx, the Cambridge School, and Shaikh.

</details>


### [62] [A choice-based axiomatization of Nash equilibrium](https://arxiv.org/abs/2512.03930)
*Michele Crescenzi*

Main category: econ.TH

TL;DR: 该论文为正规形式博弈提供了纳什均衡的公理化刻画，用四个简单直观的公理完全刻画了纳什均衡对应关系。


<details>
  <summary>Details</summary>
Motivation: 为纳什均衡概念提供公理化基础，使其不依赖于效用表示、策略集基数或纯/混合策略等具体设定，建立更一般化的理论框架。

Method: 采用公理化方法，提出四个公理（其中两个受抽象选择理论中的收缩和扩展一致性启发），证明这些公理完全刻画了纳什均衡对应关系。

Result: 成功建立了纳什均衡的公理化刻画，该刻画适用于纯策略和混合策略、任意基数策略集的博弈，且不要求偏好具有效用或期望效用表示。

Conclusion: 纳什均衡可以通过四个简单公理完全刻画，这为纳什均衡概念提供了坚实的公理化基础，扩展了其适用范围和理论深度。

Abstract: An axiomatic characterization of Nash equilibrium is provided for games in normal form. The Nash equilibrium correspondence is shown to be fully characterized by four simple and intuitive axioms, two of which are inspired by contraction and expansion consistency properties from the literature on abstract choice theory. The axiomatization applies to Nash equilibria in pure and mixed strategies alike, to games with strategy sets of any cardinality, and it does not require that players' preferences have a utility or expected utility representation.

</details>


### [63] [Payoff Continuity in Games of Incomplete Information Across Models of Knowledge](https://arxiv.org/abs/2512.03982)
*Ashwin Kambhampati*

Main category: econ.TH

TL;DR: 该论文证明了Monderer-Samet拓扑与Kajii-Morris拓扑等价性的开放猜想，即两种信息结构接近性定义在博弈均衡收益方面是等价的。


<details>
  <summary>Details</summary>
Motivation: 不完全信息博弈中的均衡预测对信息结构假设很敏感。Monderer和Samet(1996)与Kajii和Morris(1998)分别提出了不同的拓扑结构来衡量信息结构的接近性，但两者定义方式不同，需要证明它们之间的等价关系。

Method: 通过数学证明的方式，建立两种拓扑结构之间的等价关系。具体证明两个分割剖面在Monderer-Samet拓扑中接近当且仅当存在类型标记使得相关的共同先验在Kajii-Morris拓扑中接近。

Result: 成功证明了开放猜想：两个分割剖面在Monderer-Samet(1996)拓扑中接近当且仅当存在类型标记使得相关的共同先验在Kajii-Morris(1998)拓扑中接近。

Conclusion: 该研究统一了不完全信息博弈中信息结构接近性的两种主要拓扑定义，为博弈论中信息结构稳定性的研究提供了理论基础，表明两种看似不同的方法在均衡收益稳定性方面是等价的。

Abstract: Equilibrium predictions in games of incomplete information are sensitive to the assumed information structure. Monderer and Samet (1996) and Kajii and Morris (1998) define topological notions of proximity for common prior information structures such that two information structures are close if and only if (approximate) equilibrium payoffs are close. However, Monderer and Samet (1996) fix a common prior and define their topology on profiles of partitions over a state space, whereas Kajii and Morris (1998) define their topology on common priors over the product of a state space and a type space. We prove the open conjecture that two partition profiles are close in the Monderer and Samet (1996) topology if and only if there exists a labeling of types such that the associated common priors are close in the Kajii and Morris (1998) topology.

</details>


### [64] [Assessing Financial Statement Risks among $\mathrm{MCDM}$ Techniques](https://arxiv.org/abs/2512.04035)
*Marwa Abdullah,Revzon Oksana Anatolyevna,Duaa Abdullah*

Main category: econ.TH

TL;DR: 使用AHP和SAW多准则决策方法评估工业公司财务风险，识别关键风险因素和高风险年份


<details>
  <summary>Details</summary>
Motivation: 工业公司面临多种财务风险，需要系统评估这些风险的相对重要性，并识别哪些年份风险暴露最高，为风险管理提供决策支持

Method: 应用层次分析法(AHP)确定财务风险因素的权重，结合简单加权法(SAW)分析AL-Ahliah植物油公司2008-2017年的财务比率数据

Result: 成功识别了公司面临的主要财务风险因素及其相对重要性，确定了风险暴露最高的年份，为该公司提供了风险管理优先级建议

Conclusion: 多准则决策方法能有效评估工业公司财务风险，AHP和SAW结合使用可为财务风险管理提供系统化、量化的决策框架

Abstract: In this paper, to determine the financial risks faced by an industrial company, assessing the relative importance of these risks and identifying the years most exposed to financial risk using modern multi-criteria decision-making techniques. Applied to AL-Ahliah Vegetable Oil Company, the research utilizes the Analytical Hierarchy Process and Simple Additive Weighting to analyze financial ratios from 2008 to 2017.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [65] [Physics-Informed Machine Learning for Steel Development: A Computational Framework and CCT Diagram Modelling](https://arxiv.org/abs/2512.03050)
*Peter Hedström,Victor Lamelas Cubero,Jón Sigurdsson,Viktor Österberg,Satish Kolli,Joakim Odqvist,Ziyong Hou,Wangzhong Mu,Viswanadh Gowtham Arigela*

Main category: cs.LG

TL;DR: 提出一个结合物理洞察与机器学习的计算框架，用于开发钢材的物理信息连续冷却转变（CCT）模型，该模型在4100个图的数据集上训练，能高效生成CCT图并展示良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 通用机器学习框架在复杂工业材料（如钢材）中的应用存在挑战，主要障碍在于准确捕捉化学成分、加工参数与微观结构/性能之间的复杂关系。

Method: 开发了一个结合物理洞察与机器学习的计算框架，构建物理信息CCT模型，在4100个CCT图的数据集上进行训练，并采用文献和实验数据进行验证。

Result: 模型计算效率高（5秒内生成100条冷却曲线的完整CCT图），泛化能力强（所有相的分类F1分数超过88%），相变温度回归误差低（除贝氏体MAE为27°C外，其他相MAE均低于20°C）。

Conclusion: 该框架可扩展为通用的热处理数字孪生平台，结合补充模拟工具和针对性实验，将支持加速材料设计工作流程。

Abstract: Machine learning (ML) has emerged as a powerful tool for accelerating the computational design and production of materials. In materials science, ML has primarily supported large-scale discovery of novel compounds using first-principles data and digital twin applications for optimizing manufacturing processes. However, applying general-purpose ML frameworks to complex industrial materials such as steel remains a challenge. A key obstacle is accurately capturing the intricate relationship between chemical composition, processing parameters, and the resulting microstructure and properties. To address this, we introduce a computational framework that combines physical insights with ML to develop a physics-informed continuous cooling transformation (CCT) model for steels. Our model, trained on a dataset of 4,100 diagrams, is validated against literature and experimental data. It demonstrates high computational efficiency, generating complete CCT diagrams with 100 cooling curves in under 5 seconds. It also shows strong generalizability across alloy steels, achieving phase classification F1 scores above 88% for all phases. For phase transition temperature regression, it attains mean absolute errors (MAE) below 20 °C across all phases except bainite, which shows a slightly higher MAE of 27 °C. This framework can be extended with additional generic and customized ML models to establish a universal digital twin platform for heat treatment. Integration with complementary simulation tools and targeted experiments will further support accelerated materials design workflows.

</details>


### [66] [Mitigating hallucinations and omissions in LLMs for invertible problems: An application to hardware logic design automation](https://arxiv.org/abs/2512.03053)
*Andrew S. Cassidy,Guillaume Garreau,Jay Sivagnaname,Mike Grassi,Bernard Brezzo,John V. Arthur,Dharmendra S. Modha*

Main category: cs.LG

TL;DR: 提出使用LLM作为无损编码器/解码器的方法，通过源域到目标域再到源域的双向转换来减少LLM的幻觉和遗漏问题，在硬件设计领域验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在代码生成等任务中常见的幻觉和遗漏问题，特别是在硬件设计这种需要高可靠性的领域。

Method: 采用无损编码-解码方法：1) 使用LLM作为编码器将源数据（如LCTs）转换为目标数据（如HDL代码）；2) 再用LLM作为解码器将生成的HDL代码转换回源数据；3) 比较原始和重建的源数据来验证正确性。

Result: 在二维网络芯片路由器设计中（13个单元，1500-2000行代码），使用7种不同LLM进行测试，该方法能有效确认正确生成的逻辑、检测错误生成的逻辑，并帮助开发者发现设计规范错误。

Conclusion: 提出的无损编码-解码方法能显著减轻LLM的幻觉和遗漏问题，提高开发效率，不仅验证LLM生成逻辑的正确性，还能辅助发现设计规范错误。

Abstract: We show for invertible problems that transform data from a source domain (for example, Logic Condition Tables (LCTs)) to a destination domain (for example, Hardware Description Language (HDL) code), an approach of using Large Language Models (LLMs) as a lossless encoder from source to destination followed by as a lossless decoder back to the source, comparable to lossless compression in information theory, can mitigate most of the LLM drawbacks of hallucinations and omissions. Specifically, using LCTs as inputs, we generate the full HDL for a two-dimensional network-on-chip router (13 units, 1500-2000 lines of code) using seven different LLMs, reconstruct the LCTs from the auto-generated HDL, and compare the original and reconstructed LCTs. This approach yields significant productivity improvements, not only confirming correctly generated LLM logic and detecting incorrectly generated LLM logic but also assisting developers in finding design specification errors.

</details>


### [67] [Energy-Efficient Federated Learning via Adaptive Encoder Freezing for MRI-to-CT Conversion: A Green AI-Guided Research](https://arxiv.org/abs/2512.03054)
*Ciro Benito Raggio,Lucia Migliorelli,Nils Skupien,Mathias Krohmer Zabaleta,Oliver Blanck,Francesco Cicone,Giuseppe Lucio Cascini,Paolo Zaffino,Maria Francesca Spadea*

Main category: cs.LG

TL;DR: 提出一种面向绿色AI的自适应层冻结策略，用于联邦学习中的MRI-to-CT转换任务，在保持模型性能的同时减少23%的训练时间、能耗和碳排放。


<details>
  <summary>Details</summary>
Motivation: 联邦学习虽然能促进医疗平等，但其高计算资源需求会排除计算基础设施有限的机构，加剧医疗不平等。需要降低FL的资源消耗，使其更具可持续性和包容性。

Method: 提出自适应层冻结策略：基于轮次间编码器权重的相对差异监控，选择性冻结编码器权重；采用基于耐心的机制，仅在更新持续保持最小时才进行冻结；使用CodeCarbon库追踪能耗和碳排放。

Result: 相比未冻结的对照方法，训练时间、总能耗和CO2eq排放减少高达23%；MRI-to-CT转换性能保持稳定，MAE仅有小幅变化；5种架构中3种无统计显著差异，2种有统计显著改进。

Conclusion: 该工作符合促进深度学习框架满足临床需求同时确保气候、社会和经济可持续性的研究范式，为新颖的联邦学习评估框架奠定基础，推动AI驱动医疗中的隐私、公平和正义。

Abstract: Federated Learning (FL) holds the potential to advance equality in health by enabling diverse institutions to collaboratively train deep learning (DL) models, even with limited data. However, the significant resource requirements of FL often exclude centres with limited computational infrastructure, further widening existing healthcare disparities. To address this issue, we propose a Green AI-oriented adaptive layer-freezing strategy designed to reduce energy consumption and computational load while maintaining model performance. We tested our approach using different federated architectures for Magnetic Resonance Imaging (MRI)-to-Computed Tomography (CT) conversion. The proposed adaptive strategy optimises the federated training by selectively freezing the encoder weights based on the monitored relative difference of the encoder weights from round to round. A patience-based mechanism ensures that freezing only occurs when updates remain consistently minimal. The energy consumption and CO2eq emissions of the federation were tracked using the CodeCarbon library. Compared to equivalent non-frozen counterparts, our approach reduced training time, total energy consumption and CO2eq emissions by up to 23%. At the same time, the MRI-to-CT conversion performance was maintained, with only small variations in the Mean Absolute Error (MAE). Notably, for three out of the five evaluated architectures, no statistically significant differences were observed, while two architectures exhibited statistically significant improvements. Our work aligns with a research paradigm that promotes DL-based frameworks meeting clinical requirements while ensuring climatic, social, and economic sustainability. It lays the groundwork for novel FL evaluation frameworks, advancing privacy, equity and, more broadly, justice in AI-driven healthcare.

</details>


### [68] [Physics-informed self-supervised learning for predictive modeling of coronary artery digital twins](https://arxiv.org/abs/2512.03055)
*Xiaowu Sun,Thabo Mahendiran,Ortal Senouf,Denise Auberson,Bernard De Bruyne,Stephane Fournier,Olivier Muller,Pascal Frossard,Emmanuel Abbe,Dorina Thanou*

Main category: cs.LG

TL;DR: PINS-CAD：基于物理信息自监督学习的框架，通过20万合成冠状动脉数字孪生预训练图神经网络，无需CFD或标注数据即可预测心血管事件，临床验证AUC达0.73。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病是全球主要死因，冠状动脉疾病（CAD）需要早期风险预测。传统3D冠状动脉数字孪生依赖计算流体动力学（CFD）计算量大，数据驱动方法受限于标注数据稀缺和缺乏生理先验知识。

Method: 提出PINS-CAD物理信息自监督学习框架：1）使用20万合成冠状动脉数字孪生预训练图神经网络；2）基于1D Navier-Stokes方程和压降定律指导压力与血流预测；3）无需CFD或标注数据；4）在FAME2研究635名患者临床数据上微调。

Result: 在FAME2多中心研究中，PINS-CAD预测未来心血管事件的AUC为0.73，优于临床风险评分和数据驱动基线方法。能生成空间分辨的压力和血流储备分数曲线，提供可解释的生物标志物。

Conclusion: 物理信息预训练提高了样本效率并产生生理学有意义的表示。通过将物理先验嵌入几何深度学习，PINS-CAD将常规血管造影转化为无需模拟、具有生理感知的可扩展预防心脏病学框架。

Abstract: Cardiovascular disease is the leading global cause of mortality, with coronary artery disease (CAD) as its most prevalent form, necessitating early risk prediction. While 3D coronary artery digital twins reconstructed from imaging offer detailed anatomy for personalized assessment, their analysis relies on computationally intensive computational fluid dynamics (CFD), limiting scalability. Data-driven approaches are hindered by scarce labeled data and lack of physiological priors. To address this, we present PINS-CAD, a physics-informed self-supervised learning framework. It pre-trains graph neural networks on 200,000 synthetic coronary digital twins to predict pressure and flow, guided by 1D Navier-Stokes equations and pressure-drop laws, eliminating the need for CFD or labeled data. When fine-tuned on clinical data from 635 patients in the multicenter FAME2 study, PINS-CAD predicts future cardiovascular events with an AUC of 0.73, outperforming clinical risk scores and data-driven baselines. This demonstrates that physics-informed pretraining boosts sample efficiency and yields physiologically meaningful representations. Furthermore, PINS-CAD generates spatially resolved pressure and fractional flow reserve curves, providing interpretable biomarkers. By embedding physical priors into geometric deep learning, PINS-CAD transforms routine angiography into a simulation-free, physiology-aware framework for scalable, preventive cardiology.

</details>


### [69] [Delta Sampling: Data-Free Knowledge Transfer Across Diffusion Models](https://arxiv.org/abs/2512.03056)
*Zhidong Gao,Zimeng Pan,Yuhang Yao,Chenyue Xie,Wei Wei*

Main category: cs.LG

TL;DR: Delta Sampling (DS) 是一种无需原始训练数据、在推理时实现跨架构基础模型知识迁移的新方法，通过利用模型适配前后的预测差异来指导新基础模型的去噪过程。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型的适配组件（如LoRA、ControlNet等）与特定基础模型紧密耦合，当基础模型升级时（如从SD 1.x到2.x），由于模型参数和架构的重大变化，这些适配组件难以复用。

Method: 提出Delta Sampling方法，完全在推理时操作：首先计算原始基础模型适配前后的预测差异（delta），然后将这个delta用于指导新基础模型的去噪过程，实现知识迁移。

Result: 在不同Stable Diffusion版本上的评估表明，DS能够在不同采样策略下，在创建期望效果（如视觉风格、语义概念和结构）方面实现一致的改进。

Conclusion: DS是一种有效的即插即用机制，能够在基于扩散的图像合成中实现跨基础模型架构的知识迁移，无需访问原始训练数据。

Abstract: Diffusion models like Stable Diffusion (SD) drive a vibrant open-source ecosystem including fully fine-tuned checkpoints and parameter-efficient adapters such as LoRA, LyCORIS, and ControlNet. However, these adaptation components are tightly coupled to a specific base model, making them difficult to reuse when the base model is upgraded (e.g., from SD 1.x to 2.x) due to substantial changes in model parameters and architecture. In this work, we propose Delta Sampling (DS), a novel method that enables knowledge transfer across base models with different architectures, without requiring access to the original training data. DS operates entirely at inference time by leveraging the delta: the difference in model predictions before and after the adaptation of a base model. This delta is then used to guide the denoising process of a new base model. We evaluate DS across various SD versions, demonstrating that DS achieves consistent improvements in creating desired effects (e.g., visual styles, semantic concepts, and structures) under different sampling strategies. These results highlight DS as an effective, plug-and-play mechanism for knowledge transfer in diffusion-based image synthesis. Code:~ https://github.com/Zhidong-Gao/DeltaSampling

</details>


### [70] [Dynamical Properties of Tokens in Self-Attention and Effects of Positional Encoding](https://arxiv.org/abs/2512.03058)
*Duy-Tung Pham,An The Nguyen,Viet-Hoang Tran,Nhan-Phu Chung,Xin T. Tong,Tan M. Nguyen,Thieu N. Vo*

Main category: cs.LG

TL;DR: 研究预训练Transformer中token的动态特性，分析其连续时间极限的动力学系统，提出改进Transformer架构的简单方法


<details>
  <summary>Details</summary>
Motivation: 探索预训练Transformer模型中token的动态特性，理解token随时间变化的行为模式，为改进Transformer模型提供理论基础

Method: 分析预训练模型的连续时间极限动力学系统，研究token收敛或发散的条件，考察绝对位置编码和旋转位置编码的影响

Result: 提出了更广泛适用的条件来识别token收敛到零或发散到无穷的情况，发现收敛情况会损害模型性能，并提出了缓解收敛行为的架构改进方法

Conclusion: 该研究为改进Transformer模型提供了理论支持和设计原则，特别是通过调整位置编码来优化token的动态行为

Abstract: This paper investigates the dynamical properties of tokens in pre-trained Transformer models and explores their application to improving Transformers. To this end, we analyze the dynamical system governing the continuous-time limit of the pre-trained model and characterize the asymptotic behavior of its solutions. Specifically, we characterize when tokens move closer to or farther from one another over time, depending on the model parameters. We provide sufficient conditions, based on these parameters, to identify scenarios where tokens either converge to zero or diverge to infinity. Unlike prior works, our conditions are broader in scope and more applicable to real-world models. Furthermore, we investigate how different forms of positional encoding -- specifically absolute and rotary -- affect these dynamical regimes. Empirical evidence reveals that the convergence scenario adversely impacts model performance. Motivated by these insights, we propose simple refinements to Transformer architectures that mitigate convergence behavior in models with absolute or rotary positional encoding. These findings support theoretical foundations and design principles for improving Transformer models.

</details>


### [71] [Safe and Sustainable Electric Bus Charging Scheduling with Constrained Hierarchical DRL](https://arxiv.org/abs/2512.03059)
*Jiaju Qi,Lei Lei,Thorsteinn Jonsson,Dusit Niyato*

Main category: cs.LG

TL;DR: 提出了一种安全的分层深度强化学习框架，用于解决多源不确定性下的电动公交车充电调度问题，通过DAC-MAPPO-Lagrangian算法实现成本最小化和安全运行。


<details>
  <summary>Details</summary>
Motivation: 电动公交车与光伏等可再生能源整合是促进可持续低碳公共交通的有前景方案，但在实际运行中，光伏发电、动态电价、可变行驶时间和有限充电基础设施等多源不确定性使得优化充电调度以最小化运营成本同时确保电池不耗尽的安全运行具有挑战性。

Method: 将问题建模为带选项的约束马尔可夫决策过程，提出新颖的DAC-MAPPO-Lagrangian分层深度强化学习算法：高层采用集中式PPO-Lagrangian学习安全充电器分配策略，低层采用MAPPO-Lagrangian在集中训练分散执行范式下学习分散式充电功率决策。

Result: 基于真实数据的广泛实验表明，所提方法在成本最小化和安全合规性方面均优于现有基线方法，同时保持了快速收敛速度。

Conclusion: 提出的安全分层深度强化学习框架能有效解决多源不确定性下的电动公交车充电调度问题，为可持续公共交通系统提供了实用的优化解决方案。

Abstract: The integration of Electric Buses (EBs) with renewable energy sources such as photovoltaic (PV) panels is a promising approach to promote sustainable and low-carbon public transportation. However, optimizing EB charging schedules to minimize operational costs while ensuring safe operation without battery depletion remains challenging - especially under real-world conditions, where uncertainties in PV generation, dynamic electricity prices, variable travel times, and limited charging infrastructure must be accounted for. In this paper, we propose a safe Hierarchical Deep Reinforcement Learning (HDRL) framework for solving the EB Charging Scheduling Problem (EBCSP) under multi-source uncertainties. We formulate the problem as a Constrained Markov Decision Process (CMDP) with options to enable temporally abstract decision-making. We develop a novel HDRL algorithm, namely Double Actor-Critic Multi-Agent Proximal Policy Optimization Lagrangian (DAC-MAPPO-Lagrangian), which integrates Lagrangian relaxation into the Double Actor-Critic (DAC) framework. At the high level, we adopt a centralized PPO-Lagrangian algorithm to learn safe charger allocation policies. At the low level, we incorporate MAPPO-Lagrangian to learn decentralized charging power decisions under the Centralized Training and Decentralized Execution (CTDE) paradigm. Extensive experiments with real-world data demonstrate that the proposed approach outperforms existing baselines in both cost minimization and safety compliance, while maintaining fast convergence speed.

</details>


### [72] [A Large Scale Heterogeneous Treatment Effect Estimation Framework and Its Applications of Users' Journey at Snap](https://arxiv.org/abs/2512.03060)
*Jing Pan,Li Shi,Paul Lo*

Main category: cs.LG

TL;DR: 大规模工业框架利用数百个实验数据估计异质性处理效应，通过结合多实验结果发现潜在用户特征，并在广告影响力和敏感性应用中取得显著效果


<details>
  <summary>Details</summary>
Motivation: 传统处理效应模型假设每个用户的处理效应相同，但在实际应用中，用户对处理的响应存在异质性。需要开发能够在大规模工业环境中估计异质性处理效应（HTE）和条件平均处理效应（CATE）的框架。

Method: 1. 实验选择：从数百个Snapchat用户实验中收集数据；2. 基础学习器设计：构建HTE估计模型；3. 增量训练：实现系统持续更新；4. 结合多实验结果发现潜在用户特征；5. 在广告影响力和敏感性两个应用场景中验证框架。

Result: 1. 框架成功处理了数亿用户的大规模数据；2. 发现了之前无法测量的潜在用户特征；3. 获得了稳定的处理效应估计；4. 在线A/B测试显示，使用影响力分数进行广告定向的效果比通常认为显著的水平高出六倍以上。

Conclusion: 该大规模工业框架能够有效估计异质性处理效应，通过结合多实验数据发现潜在用户特征，在广告定向等实际应用中取得了显著的业务效果提升，证明了HTE/CATE模型在工业环境中的实用价值。

Abstract: Heterogeneous Treatment Effect (HTE) and Conditional Average Treatment Effect (CATE) models relax the assumption that treatment effects are the same for every user. We present a large scale industrial framework for estimating HTE using experimental data from hundreds of millions of Snapchat users. By combining results across many experiments, the framework uncovers latent user characteristics that were previously unmeasurable and produces stable treatment effect estimates at scale.
  We describe the core components that enabled this system, including experiment selection, base learner design, and incremental training. We also highlight two applications: user influenceability to ads and user sensitivity to ads. An online A/B test using influenceability scores for targeting showed an improvement on key business metrics that is more than six times larger than what is typically considered significant.

</details>


### [73] [Globally optimized SVD compression of LLMs via Fermi-function-based rank selection and gauge fixing](https://arxiv.org/abs/2512.03062)
*Roman Rausch,David Jansen,Sukhbinder Singh,Román Orús*

Main category: cs.LG

TL;DR: 提出两种基于物理启发的SVD LLM压缩改进方法：FermiGrad算法通过费米函数将离散奇异值截断转化为连续优化来确定全局最优层秩；PivGa利用参数化中的规范自由度对低秩因子进行无损压缩。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型对计算资源需求很高，低秩分解（如SVD）是LLM压缩的有前景方法，但存在层秩选择和参数冗余等实际障碍。

Method: 1. FermiGrad：使用费米函数将离散奇异值截断松弛为连续优化，通过梯度下降算法确定全局最优层秩。2. PivGa：利用低秩因子参数化中的固有规范自由度，对低秩因子进行额外的无损压缩。

Result: 论文提出了两种改进SVD LLM压缩的物理启发方法，解决了层秩选择和参数冗余问题，但摘要中未提供具体的实验结果数据。

Conclusion: 通过FermiGrad和PivGa两种物理启发的改进，可以更有效地进行LLM的低秩压缩，解决传统SVD压缩中的实际障碍。

Abstract: Large Language Models (LLMs) are very demanding in terms of their computational resources. Low-rank decompositions of LLM weights, e.g. via Singular Value Decomposition (SVD), is a promising approach for LLM compression, but presents several practical hurdles, e.g. selecting appropriate layer-wise ranks and getting rid of its parameter redundancy. In this work, we present two physics-inspired improvements to SVD LLM compression: (1) \textbf{FermiGrad}, a gradient-descent algorithm that determines globally optimal layer-wise ranks by relaxing the discrete singular-value truncation into a continuous optimization using the Fermi function; (2) \textbf{PivGa}, an additional \textit{lossless} compression of the low-rank factors that exploits the intrinsic gauge freedom in their parametrization.

</details>


### [74] [Optimizing Life Sciences Agents in Real-Time using Reinforcement Learning](https://arxiv.org/abs/2512.03065)
*Nihir Chadderwala*

Main category: cs.LG

TL;DR: 提出结合AWS Strands Agents与Thompson Sampling上下文bandits的框架，让AI代理仅从用户反馈中学习最优决策策略，在生命科学查询中提升15-30%用户满意度。


<details>
  <summary>Details</summary>
Motivation: 生命科学中的生成式AI代理面临关键挑战：如何为从简单事实性问题到复杂机制推理的多样化查询确定最优方法。传统方法依赖固定规则或昂贵的标注训练数据，都无法适应变化条件或用户偏好。

Method: 结合AWS Strands Agents与Thompson Sampling上下文bandits的框架，通过用户反馈学习优化三个关键维度：生成策略选择（直接vs.思维链）、工具选择（文献搜索、药物数据库等）和领域路由（药理学、分子生物学、临床专家）。

Result: 在生命科学查询的实证评估中，相比随机基线获得15-30%的用户满意度提升，在20-30个查询后出现清晰的学习模式。方法无需真实标签，能持续适应用户偏好。

Conclusion: 该框架为智能代理系统中的探索-利用困境提供了原则性解决方案，仅从用户反馈中学习最优决策策略，无需标注数据且能持续适应变化。

Abstract: Generative AI agents in life sciences face a critical challenge: determining the optimal approach for diverse queries ranging from simple factoid questions to complex mechanistic reasoning. Traditional methods rely on fixed rules or expensive labeled training data, neither of which adapts to changing conditions or user preferences. We present a novel framework that combines AWS Strands Agents with Thompson Sampling contextual bandits to enable AI agents to learn optimal decision-making strategies from user feedback alone. Our system optimizes three key dimensions: generation strategy selection (direct vs. chain-of-thought), tool selection (literature search, drug databases, etc.), and domain routing (pharmacology, molecular biology, clinical specialists). Through empirical evaluation on life science queries, we demonstrate 15-30\% improvement in user satisfaction compared to random baselines, with clear learning patterns emerging after 20-30 queries. Our approach requires no ground truth labels, adapts continuously to user preferences, and provides a principled solution to the exploration-exploitation dilemma in agentic AI systems.

</details>


### [75] [Hierarchical clustering of complex energy systems using pretopology](https://arxiv.org/abs/2512.03069)
*Loup-Noe Levy,Jeremie Bosom,Guillaume Guerard,Soufian Ben Amor,Marc Bui,Hai Tran*

Main category: cs.LG

TL;DR: 使用预拓扑学建模建筑能耗曲线，开发多准则层次分类算法实现自动能耗管理推荐系统


<details>
  <summary>Details</summary>
Motivation: 针对大规模分布式建筑能耗管理，传统逐个深度审计方法成本高、耗时长、需要大量专业人员，需要开发自动化方法来建立有效的能耗管理推荐系统

Method: 使用预拓扑学建模能耗曲线，开发基于预拓扑空间特性的多准则层次分类算法，并实现为Python库

Result: 在二维点数据集上能根据位置和大小识别聚类；在生成的时间序列数据集上使用皮尔逊相关系数获得ARI=1的完美聚类效果；在400个法国能源公司真实能耗站点数据上验证

Conclusion: 预拓扑学和多准则层次分类算法能够有效建模和分类大规模分布式建筑的能耗曲线，为优化建筑能耗管理提供自动化解决方案

Abstract: This article attempts answering the following problematic: How to model and classify energy consumption profiles over a large distributed territory to optimize the management of buildings' consumption?
  Doing case-by-case in depth auditing of thousands of buildings would require a massive amount of time and money as well as a significant number of qualified people. Thus, an automated method must be developed to establish a relevant and effective recommendations system.
  To answer this problematic, pretopology is used to model the sites' consumption profiles and a multi-criterion hierarchical classification algorithm, using the properties of pretopological space, has been developed in a Python library.
  To evaluate the results, three data sets are used: A generated set of dots of various sizes in a 2D space, a generated set of time series and a set of consumption time series of 400 real consumption sites from a French Energy company.
  On the point data set, the algorithm is able to identify the clusters of points using their position in space and their size as parameter. On the generated time series, the algorithm is able to identify the time series clusters using Pearson's correlation with an Adjusted Rand Index (ARI) of 1.

</details>


### [76] [Mixed Data Clustering Survey and Challenges](https://arxiv.org/abs/2512.03070)
*Guillaume Guerard,Sonia Djebali*

Main category: cs.LG

TL;DR: 本文提出了一种基于预拓扑空间的混合数据聚类方法，用于解决大数据环境下数值和分类变量混合的聚类挑战。


<details>
  <summary>Details</summary>
Motivation: 大数据时代带来了数据量、速度和多样性的挑战，混合数据（数值和分类变量）的聚类成为关键问题。传统聚类方法通常针对同质数据集设计，难以处理混合数据的复杂性，需要专门针对这种场景的方法。

Method: 提出了一种基于预拓扑空间的聚类方法。预拓扑空间提供了更灵活的结构来处理混合数据的复杂性，能够同时处理数值和分类变量。

Result: 通过与经典数值聚类算法和现有预拓扑方法进行基准测试，评估了所提方法的性能和有效性，验证了其在大数据范式下的适用性。

Conclusion: 基于预拓扑空间的聚类方法为解决大数据环境下的混合数据聚类问题提供了有效的解决方案，具有结构化和可解释性的优势，支持明智的决策制定。

Abstract: The advent of the big data paradigm has transformed how industries manage and analyze information, ushering in an era of unprecedented data volume, velocity, and variety. Within this landscape, mixed-data clustering has become a critical challenge, requiring innovative methods that can effectively exploit heterogeneous data types, including numerical and categorical variables. Traditional clustering techniques, typically designed for homogeneous datasets, often struggle to capture the additional complexity introduced by mixed data, underscoring the need for approaches specifically tailored to this setting. Hierarchical and explainable algorithms are particularly valuable in this context, as they provide structured, interpretable clustering results that support informed decision-making. This paper introduces a clustering method grounded in pretopological spaces. In addition, benchmarking against classical numerical clustering algorithms and existing pretopological approaches yields insights into the performance and effectiveness of the proposed method within the big data paradigm.

</details>


### [77] [PretopoMD: Pretopology-based Mixed Data Hierarchical Clustering](https://arxiv.org/abs/2512.03071)
*Loup-Noe Levy,Guillaume Guerard,Sonia Djebali,Soufian Ben Amor*

Main category: cs.LG

TL;DR: 提出基于预拓扑的新算法，无需降维即可聚类混合数据，使用析取范式构建可定制逻辑规则，实现用户定义的分层聚类，在保持数据完整性的同时提供可解释的聚类结果。


<details>
  <summary>Details</summary>
Motivation: 解决混合数据聚类中的挑战，避免传统降维技术导致的信息损失，提高聚类结果的可解释性，克服聚类数据可解释性问题。

Method: 基于预拓扑的算法，利用析取范式（DNF）构建可定制的逻辑规则和可调整的超参数，支持用户定义的分层聚类结构，直接从原始数据中构建聚类而无需降维。

Result: 通过分层树状图分析和比较聚类指标，该方法在准确性和可解释性方面表现出优越性能，能够从原始数据中清晰界定聚类，保持数据完整性，并构建有意义的聚类结构。

Conclusion: 该工作通过创新性地使用逻辑规则而非传统降维技术，在混合数据聚类领域做出了重要贡献，既增强了聚类形成又提高了清晰度，为解决聚类可解释性问题提供了新途径。

Abstract: This article presents a novel pretopology-based algorithm designed to address the challenges of clustering mixed data without the need for dimensionality reduction. Leveraging Disjunctive Normal Form, our approach formulates customizable logical rules and adjustable hyperparameters that allow for user-defined hierarchical cluster construction and facilitate tailored solutions for heterogeneous datasets. Through hierarchical dendrogram analysis and comparative clustering metrics, our method demonstrates superior performance by accurately and interpretably delineating clusters directly from raw data, thus preserving data integrity. Empirical findings highlight the algorithm's robustness in constructing meaningful clusters and reveal its potential in overcoming issues related to clustered data explainability. The novelty of this work lies in its departure from traditional dimensionality reduction techniques and its innovative use of logical rules that enhance both cluster formation and clarity, thereby contributing a significant advancement to the discourse on clustering mixed data.

</details>


### [78] [Model-Agnostic Fairness Regularization for GNNs with Incomplete Sensitive Information](https://arxiv.org/abs/2512.03074)
*Mahdi Tavassoli Kejani,Fadi Dornaika,Jean-Michel Loubes*

Main category: cs.LG

TL;DR: 提出一种模型无关的公平正则化框架，用于处理图神经网络中敏感属性仅部分可用的现实场景，在保持分类性能的同时显著减少偏见。


<details>
  <summary>Details</summary>
Motivation: 现有公平感知的GNN方法通常假设训练期间所有节点的敏感属性完全可用，这在实践中存在隐私和数据收集限制。需要解决敏感属性仅部分可用的现实场景下的公平性问题。

Method: 提出一种模型无关的公平正则化框架，将公平机会和统计奇偶性作为可微分正则化项集成到目标函数中，适用于敏感属性仅部分可用的场景。

Result: 在五个真实世界基准数据集上的评估表明，该方法在关键公平性指标上显著减少偏见，同时保持竞争力的节点分类性能，在公平性-准确性权衡方面优于基线模型。

Conclusion: 该框架为敏感属性仅部分可用的现实场景提供了一种有效的公平性解决方案，在减少偏见的同时最小化预测准确性的损失，具有良好的实用价值。

Abstract: Graph Neural Networks (GNNs) have demonstrated exceptional efficacy in relational learning tasks, including node classification and link prediction. However, their application raises significant fairness concerns, as GNNs can perpetuate and even amplify societal biases against protected groups defined by sensitive attributes such as race or gender. These biases are often inherent in the node features, structural topology, and message-passing mechanisms of the graph itself. A critical limitation of existing fairness-aware GNN methods is their reliance on the strong assumption that sensitive attributes are fully available for all nodes during training--a condition that poses a practical impediment due to privacy concerns and data collection constraints. To address this gap, we propose a novel, model-agnostic fairness regularization framework designed for the realistic scenario where sensitive attributes are only partially available. Our approach formalizes a fairness-aware objective function that integrates both equal opportunity and statistical parity as differentiable regularization terms. Through a comprehensive empirical evaluation across five real-world benchmark datasets, we demonstrate that the proposed method significantly mitigates bias across key fairness metrics while maintaining competitive node classification performance. Results show that our framework consistently outperforms baseline models in achieving a favorable fairness-accuracy trade-off, with minimal degradation in predictive accuracy. The datasets and source code will be publicly released at https://github.com/mtavassoli/GNN-FC.

</details>


### [79] [Risk-Entropic Flow Matching](https://arxiv.org/abs/2512.03078)
*Vahid R. Ramezani,Benjamin Englard*

Main category: cs.LG

TL;DR: 将倾斜风险（对数指数变换）应用于流匹配的损失函数，通过强调罕见或高损失事件来改进数据流形的几何结构恢复


<details>
  <summary>Details</summary>
Motivation: 标准流匹配使用均方误差损失，将所有到达同一时空点的速度目标压缩为单一条件均值，忽略了高阶条件信息（方差、偏度、多模态），这些信息编码了数据流形和少数分支的精细几何结构

Method: 将标准风险敏感（对数指数）变换应用于条件流匹配损失，得到的倾斜风险损失是每个时空点上有意义的条件熵流匹配目标的上界。通过该条件熵目标梯度的小阶展开，得到两个可解释的一阶修正：流匹配残差的协方差预处理，以及偏好不对称或罕见分支的偏尾项

Result: 在专门设计用于探测模糊性和尾部的合成数据上，风险敏感损失在统计指标上优于标准校正流匹配，并能更忠实地恢复几何结构

Conclusion: 倾斜风险损失为流匹配提供了一种有前景的方法，通过强调罕见事件和保留高阶条件信息来改进数据流形的几何结构学习

Abstract: Tilted (entropic) risk, obtained by applying a log-exponential transform to a base loss, is a well established tool in statistics and machine learning for emphasizing rare or high loss events while retaining a tractable optimization problem. In this work, our aim is to interpret its structure for Flow Matching (FM). FM learns a velocity field that transports samples from a simple source distribution to data by integrating an ODE. In rectified FM, training pairs are obtained by linearly interpolating between a source sample and a data sample, and a neural velocity field is trained to predict the straight line displacement using a mean squared error loss. This squared loss collapses all velocity targets that reach the same space-time point into a single conditional mean, thereby ignoring higher order conditional information (variance, skewness, multi-modality) that encodes fine geometric structure about the data manifold and minority branches. We apply the standard risk-sensitive (log-exponential) transform to the conditional FM loss and show that the resulting tilted risk loss is a natural upper-bound on a meaningful conditional entropic FM objective defined at each space-time point. Furthermore, we show that a small order expansion of the gradient of this conditional entropic objective yields two interpretable first order corrections: covariance preconditioning of the FM residual, and a skew tail term that favors asymmetric or rare branches. On synthetic data designed to probe ambiguity and tails, the resulting risk-sensitive loss improves statistical metrics and recovers geometric structure more faithfully than standard rectified FM.

</details>


### [80] [ALARM: Automated MLLM-Based Anomaly Detection in Complex-EnviRonment Monitoring with Uncertainty Quantification](https://arxiv.org/abs/2512.03101)
*Congjing Zhang,Feng Lin,Xinyi Zhao,Pei Guo,Wei Li,Lin Chen,Chaoyue Zhao,Shuai Huang*

Main category: cs.LG

TL;DR: ALARM是一个基于多模态大语言模型的可信视觉异常检测框架，通过不确定性量化、推理链、自反思和模型集成等技术提升在复杂环境中的可靠性和准确性。


<details>
  <summary>Details</summary>
Motivation: 在复杂环境中，视觉异常检测面临异常高度情境化和模糊性的挑战，需要不确定性量化来确保MLLM系统的可靠性。

Method: ALARM框架整合了不确定性量化与质量保证技术，包括推理链、自反思和MLLM集成，基于严格的概率推理流程和计算过程设计。

Result: 在真实世界智能家居基准数据和伤口图像分类数据上的广泛实证评估显示，ALARM具有优越性能，并在不同领域具有通用适用性。

Conclusion: ALARM框架通过集成不确定性量化与质量保证技术，为MLLM视觉异常检测系统提供了可靠决策支持，具有跨领域的通用应用价值。

Abstract: The advance of Large Language Models (LLMs) has greatly stimulated research interest in developing multi-modal LLM (MLLM)-based visual anomaly detection (VAD) algorithms that can be deployed in complex environments. The challenge is that in these complex environments, the anomalies are sometimes highly contextual and also ambiguous, and thereby, uncertainty quantification (UQ) is a crucial capacity for an MLLM-based VAD system to succeed. In this paper, we introduce our UQ-supported MLLM-based VAD framework called ALARM. ALARM integrates UQ with quality-assurance techniques like reasoning chain, self-reflection, and MLLM ensemble for robust and accurate performance and is designed based on a rigorous probabilistic inference pipeline and computational process. Extensive empirical evaluations are conducted using the real-world smart-home benchmark data and wound image classification data, which shows ALARM's superior performance and its generic applicability across different domains for reliable decision-making.

</details>


### [81] [Dynamic Correction of Erroneous State Estimates via Diffusion Bayesian Exploration](https://arxiv.org/abs/2512.03102)
*Yiwei Shi,Hongnan Ma,Mengyue Yang,Cunjia Liu,Weiru Liu*

Main category: cs.LG

TL;DR: 提出扩散驱动的贝叶斯探索框架，解决早期状态估计错误导致的永久性支持不变性问题，在危险气体定位任务中优于传统方法


<details>
  <summary>Details</summary>
Motivation: 在应急响应等高风险应用中，基于有限或偏差信息的早期状态估计可能与现实严重不符，导致灾难性后果。传统粒子滤波在平稳引导下存在"平稳诱导后验支持不变性"问题，使得初始先验排除的区域永久无法探索，即使新证据与当前信念矛盾也无法修正。

Method: 提出扩散驱动的贝叶斯探索框架：1) 通过熵正则化采样和协方差缩放扩散扩展后验支持；2) 使用Metropolis-Hastings检查验证提议并保持推理对意外证据的自适应性

Result: 在现实危险气体定位任务中：1) 当先验正确时，与强化学习和规划基线表现相当；2) 在先验错配情况下，显著优于传统SMC扰动和基于RL的方法；3) 提供理论保证证明DEPF解决S-PSI问题同时保持统计严谨性

Conclusion: 扩散驱动的贝叶斯探索框架能够原则性地实时修正早期状态估计错误，解决了传统粒子滤波中的永久性支持不变性问题，在高风险应用中具有重要价值

Abstract: In emergency response and other high-stakes societal applications, early-stage state estimates critically shape downstream outcomes. Yet, these initial state estimates-often based on limited or biased information-can be severely misaligned with reality, constraining subsequent actions and potentially causing catastrophic delays, resource misallocation, and human harm. Under the stationary bootstrap baseline (zero transition and no rejuvenation), bootstrap particle filters exhibit Stationarity-Induced Posterior Support Invariance (S-PSI), wherein regions excluded by the initial prior remain permanently unexplorable, making corrections impossible even when new evidence contradicts current beliefs. While classical perturbations can in principle break this lock-in, they operate in an always-on fashion and may be inefficient. To overcome this, we propose a diffusion-driven Bayesian exploration framework that enables principled, real-time correction of early state estimation errors. Our method expands posterior support via entropy-regularized sampling and covariance-scaled diffusion. A Metropolis-Hastings check validates proposals and keeps inference adaptive to unexpected evidence. Empirical evaluations on realistic hazardous-gas localization tasks show that our approach matches reinforcement learning and planning baselines when priors are correct. It substantially outperforms classical SMC perturbations and RL-based methods under misalignment, and we provide theoretical guarantees that DEPF resolves S-PSI while maintaining statistical rigor.

</details>


### [82] [Detecting AI Hallucinations in Finance: An Information-Theoretic Method Cuts Hallucination Rate by 92%](https://arxiv.org/abs/2512.03107)
*Mainak Singha*

Main category: cs.LG

TL;DR: ECLIPSE框架通过结合语义熵估计和困惑度分解来检测LLM幻觉，将幻觉视为模型语义熵与可用证据容量之间的不匹配。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型会产生流畅但无根据的答案（幻觉），这限制了其在高风险领域的安全部署。需要一种能够检测幻觉的机制。

Method: 提出ECLIPSE框架：1) 通过多样本聚类进行熵估计；2) 新颖的困惑度分解，测量模型如何使用检索到的证据；3) 证明在温和条件下，熵-容量目标是严格凸的，具有唯一稳定最优解。

Result: 在受控金融问答数据集上，ECLIPSE达到ROC AUC 0.89和平均精度0.90，显著优于仅使用语义熵的基线（AUC 0.50）。在Claude-3-Haiku上的消融实验显示AUC降至0.59，系数幅度下降95%，证明ECLIPSE依赖于校准的token级不确定性。

Conclusion: ECLIPSE是一种基于对数概率的原生机制，其有效性依赖于校准的token级不确定性。困惑度分解特征具有最大的学习系数，证实证据利用是幻觉检测的核心。这是一项受控机制研究，未来需要在更多领域和自然发生幻觉上进行验证。

Abstract: Large language models (LLMs) produce fluent but unsupported answers - hallucinations - limiting safe deployment in high-stakes domains. We propose ECLIPSE, a framework that treats hallucination as a mismatch between a model's semantic entropy and the capacity of available evidence. We combine entropy estimation via multi-sample clustering with a novel perplexity decomposition that measures how models use retrieved evidence. We prove that under mild conditions, the resulting entropy-capacity objective is strictly convex with a unique stable optimum. We evaluate on a controlled financial question answering dataset with GPT-3.5-turbo (n=200 balanced samples with synthetic hallucinations), where ECLIPSE achieves ROC AUC of 0.89 and average precision of 0.90, substantially outperforming a semantic entropy-only baseline (AUC 0.50). A controlled ablation with Claude-3-Haiku, which lacks token-level log probabilities, shows AUC dropping to 0.59 with coefficient magnitudes decreasing by 95% - demonstrating that ECLIPSE is a logprob-native mechanism whose effectiveness depends on calibrated token-level uncertainties. The perplexity decomposition features exhibit the largest learned coefficients, confirming that evidence utilization is central to hallucination detection. We position this work as a controlled mechanism study; broader validation across domains and naturally occurring hallucinations remains future work.

</details>


### [83] [E-valuator: Reliable Agent Verifiers with Sequential Hypothesis Testing](https://arxiv.org/abs/2512.03109)
*Shuvom Sadhuka,Drew Prinster,Clara Fannjiang,Gabriele Scalia,Aviv Regev,Hanchen Wang*

Main category: cs.LG

TL;DR: e-valuator：一种将任意黑盒验证器评分转换为具有可证明误报率控制的决策规则的方法，用于在线监控AI代理轨迹


<details>
  <summary>Details</summary>
Motivation: 现有AI代理验证器（如LLM评判器和过程奖励模型）的启发式评分虽然有用，但缺乏正确性保证，无法可靠决定代理是否会成功输出。需要一种能提供统计保证的方法来区分成功和失败的代理轨迹。

Method: 将区分成功轨迹（能正确响应用户提示的动作序列）和失败轨迹的问题构建为序贯假设检验问题。基于e-process工具开发序贯假设检验，在代理轨迹的每一步都保持统计有效性，支持任意长动作序列的在线监控。

Result: 在六个数据集和三个代理上的实验表明，e-valuator相比其他策略具有更高的统计功效和更好的误报率控制。还能用于快速终止问题轨迹以节省token消耗。

Conclusion: e-valuator提供了一个轻量级、模型无关的框架，将验证器启发式方法转换为具有统计保证的决策规则，使能部署更可靠的代理系统。

Abstract: Agentic AI systems execute a sequence of actions, such as reasoning steps or tool calls, in response to a user prompt. To evaluate the success of their trajectories, researchers have developed verifiers, such as LLM judges and process-reward models, to score the quality of each action in an agent's trajectory. Although these heuristic scores can be informative, there are no guarantees of correctness when used to decide whether an agent will yield a successful output. Here, we introduce e-valuator, a method to convert any black-box verifier score into a decision rule with provable control of false alarm rates. We frame the problem of distinguishing successful trajectories (that is, a sequence of actions that will lead to a correct response to the user's prompt) and unsuccessful trajectories as a sequential hypothesis testing problem. E-valuator builds on tools from e-processes to develop a sequential hypothesis test that remains statistically valid at every step of an agent's trajectory, enabling online monitoring of agents over arbitrarily long sequences of actions. Empirically, we demonstrate that e-valuator provides greater statistical power and better false alarm rate control than other strategies across six datasets and three agents. We additionally show that e-valuator can be used for to quickly terminate problematic trajectories and save tokens. Together, e-valuator provides a lightweight, model-agnostic framework that converts verifier heuristics into decisions rules with statistical guarantees, enabling the deployment of more reliable agentic systems.

</details>


### [84] [Beyond Additivity: Sparse Isotonic Shapley Regression toward Nonlinear Explainability](https://arxiv.org/abs/2512.03112)
*Jialai She*

Main category: cs.LG

TL;DR: SISR框架同时解决Shapley值的两个核心问题：通过单调变换恢复可加性，以及通过L0稀疏约束实现高效稀疏解释，提供理论保证的实用特征归因方法。


<details>
  <summary>Details</summary>
Motivation: 传统Shapley值框架面临两个主要挑战：1) 假设可加性的价值函数在现实世界（非高斯分布、重尾、特征依赖等）中经常被违反，导致归因失真；2) 在高维空间中通过后处理阈值化实现稀疏解释计算成本高且可能不一致。

Method: 提出Sparse Isotonic Shapley Regression (SISR)框架，同时学习单调变换以恢复可加性，并施加L0稀疏约束于Shapley向量。使用Pool-Adjacent-Violators算法进行高效保序回归，以及归一化硬阈值化进行支持选择。

Result: SISR能在多种场景下恢复真实变换，在高噪声下仍能实现强支持恢复。实验表明SISR能稳定不同收益方案下的归因，正确过滤无关特征，而标准Shapley值存在严重的排序和符号失真。

Conclusion: SISR通过统一非线性变换估计与稀疏性追求，推进了非线性可解释性的前沿，提供了理论扎实且实用的归因框架，首次证明无关特征和特征间依赖可导致真实收益变换显著偏离线性。

Abstract: Shapley values, a gold standard for feature attribution in Explainable AI, face two primary challenges. First, the canonical Shapley framework assumes that the worth function is additive, yet real-world payoff constructions--driven by non-Gaussian distributions, heavy tails, feature dependence, or domain-specific loss scales--often violate this assumption, leading to distorted attributions. Secondly, achieving sparse explanations in high dimensions by computing dense Shapley values and then applying ad hoc thresholding is prohibitively costly and risks inconsistency. We introduce Sparse Isotonic Shapley Regression (SISR), a unified nonlinear explanation framework. SISR simultaneously learns a monotonic transformation to restore additivity--obviating the need for a closed-form specification--and enforces an L0 sparsity constraint on the Shapley vector, enhancing computational efficiency in large feature spaces. Its optimization algorithm leverages Pool-Adjacent-Violators for efficient isotonic regression and normalized hard-thresholding for support selection, yielding implementation ease and global convergence guarantees. Analysis shows that SISR recovers the true transformation in a wide range of scenarios and achieves strong support recovery even in high noise. Moreover, we are the first to demonstrate that irrelevant features and inter-feature dependencies can induce a true payoff transformation that deviates substantially from linearity. Experiments in regression, logistic regression, and tree ensembles demonstrate that SISR stabilizes attributions across payoff schemes, correctly filters irrelevant features while standard Shapley values suffer severe rank and sign distortions. By unifying nonlinear transformation estimation with sparsity pursuit, SISR advances the frontier of nonlinear explainability, providing a theoretically grounded and practical attribution framework.

</details>


### [85] [Temporal Graph Neural Networks for Early Anomaly Detection and Performance Prediction via PV System Monitoring Data](https://arxiv.org/abs/2512.03114)
*Srijani Mukherjee,Laurent Vuillon,Liliane Bou Nassif,Stéphanie Giroux-Julien,Hervé Pabiou,Denys Dutykh,Ionnasis Tsanakas*

Main category: cs.LG

TL;DR: 提出基于时序图神经网络的方法，利用环境与运行参数预测光伏系统输出功率并检测异常


<details>
  <summary>Details</summary>
Motivation: 随着光伏系统快速增长，需要先进的性能监测和异常检测方法来确保最优运行

Method: 使用时序图神经网络，基于关键参数（辐照度、模块温度、环境温度）之间的图结构时序关系来预测电功率输出

Result: 基于法国里昂屋顶户外设施收集的数据，包括光伏模块功率测量和气象参数

Conclusion: 该方法能够有效预测光伏输出功率并检测异常，为光伏系统性能监测提供新方案

Abstract: The rapid growth of solar photovoltaic (PV) systems necessitates advanced methods for performance monitoring and anomaly detection to ensure optimal operation. In this study, we propose a novel approach leveraging Temporal Graph Neural Network (Temporal GNN) to predict solar PV output power and detect anomalies using environmental and operational parameters. The proposed model utilizes graph-based temporal relationships among key PV system parameters, including irradiance, module and ambient temperature to predict electrical power output. This study is based on data collected from an outdoor facility located on a rooftop in Lyon (France) including power measurements from a PV module and meteorological parameters.

</details>


### [86] [Real-Time Structural Health Monitoring with Bayesian Neural Networks: Distinguishing Aleatoric and Epistemic Uncertainty for Digital Twin Frameworks](https://arxiv.org/abs/2512.03115)
*Hanbin Cho,Jecheon Yu,Hyeonbin Moon,Jiyoung Yoon,Junhyeong Lee,Giyoung Kim,Jinhyoung Park,Seunghwa Ryu*

Main category: cs.LG

TL;DR: 提出一个结合PCA、贝叶斯神经网络和哈密顿蒙特卡洛的结构健康监测框架，能从稀疏应变测量重建全场应变分布并提供不确定性量化，在含裂纹的CFRP试样上验证有效。


<details>
  <summary>Details</summary>
Motivation: 结构健康监测需要实时分析传感器数据，但现有方法难以获得空间分辨的全场不确定度（包括偶然不确定度和认知不确定度），这限制了可靠决策制定。

Method: 集成框架结合主成分分析(PCA)、贝叶斯神经网络(BNN)和哈密顿蒙特卡洛(HMC)推理，将稀疏应变计测量映射到主要PCA模式上，重建全场应变分布并提供不确定性量化。

Result: 在含不同裂纹长度的碳纤维增强聚合物(CFRP)试样上进行循环四点弯曲测试验证，实现了准确的应变场重建（R平方值>0.9），同时能实时生成不确定性场。

Conclusion: 该框架能从含噪声的实验数据和裂纹引起的应变奇异性中提供稳健的全场应变重建，同时提供两种互补的不确定性场，支持可靠的决策制定，推动结构健康监测向可信数字孪生部署和风险感知结构诊断发展。

Abstract: Reliable real-time analysis of sensor data is essential for structural health monitoring (SHM) of high-value assets, yet a major challenge is to obtain spatially resolved full-field aleatoric and epistemic uncertainties for trustworthy decision-making. We present an integrated SHM framework that combines principal component analysis (PCA), a Bayesian neural network (BNN), and Hamiltonian Monte Carlo (HMC) inference, mapping sparse strain gauge measurements onto leading PCA modes to reconstruct full-field strain distributions with uncertainty quantification. The framework was validated through cyclic four-point bending tests on carbon fiber reinforced polymer (CFRP) specimens with varying crack lengths, achieving accurate strain field reconstruction (R squared value > 0.9) while simultaneously producing real-time uncertainty fields. A key contribution is that the BNN yields robust full-field strain reconstructions from noisy experimental data with crack-induced strain singularities, while also providing explicit representations of two complementary uncertainty fields. Considered jointly in full-field form, the aleatoric and epistemic uncertainty fields make it possible to diagnose at a local level, whether low-confidence regions are driven by data-inherent issues or by model-related limitations, thereby supporting reliable decision-making. Collectively, the results demonstrate that the proposed framework advances SHM toward trustworthy digital twin deployment and risk-aware structural diagnostics.

</details>


### [87] [Mitigating Intra- and Inter-modal Forgetting in Continual Learning of Unified Multimodal Models](https://arxiv.org/abs/2512.03125)
*Xiwen Wei,Mustafa Munir,Radu Marculescu*

Main category: cs.LG

TL;DR: MoDE提出了一种模态解耦专家架构，通过隔离模态特定更新和知识蒸馏来解决统一多模态生成模型中的模态内和模态间灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 统一多模态生成模型在持续学习新任务时面临严重的灾难性遗忘问题，包括模态内遗忘和模态间遗忘。虽然模态内遗忘已有研究，但模态间遗忘尚未被充分探索，作者发现其根源在于模态间的梯度冲突。

Method: 提出模态解耦专家架构，通过隔离模态特定更新来缓解梯度冲突，并利用知识蒸馏来防止灾难性遗忘和保留预训练能力。与之前保持模态耦合的方法不同，MoDE显式解耦模态以防止干扰。

Result: 在多个基准测试中，MoDE显著缓解了模态间和模态内遗忘，在统一多模态生成设置中优于先前的持续学习基线方法。

Conclusion: MoDE通过模态解耦架构有效解决了统一多模态生成模型中的持续学习问题，为多模态系统的持续学习提供了轻量级且可扩展的解决方案。

Abstract: Unified Multimodal Generative Models (UMGMs) unify visual understanding and image generation within a single autoregressive framework. However, their ability to continually learn new tasks is severely hindered by catastrophic forgetting, both within a modality (intra-modal) and across modalities (inter-modal). While intra-modal forgetting has been studied in prior continual learning (CL) work, inter-modal forgetting remains largely unexplored. In this paper, we identify and empirically validate this phenomenon in UMGMs and provide a theoretical explanation rooted in gradient conflict between modalities. To address both intra- and inter-modal forgetting, we propose Modality-Decoupled Experts (MoDE), a lightweight and scalable architecture that isolates modality-specific updates to mitigate the gradient conflict and leverages knowledge distillation to prevent catastrophic forgetting and preserve pre-trained capabilities. Unlike previous CL methods that remain modality-coupled and suffer from modality gradient conflict, MoDE explicitly decouples modalities to prevent interference. Experiments across diverse benchmarks demonstrate that MoDE significantly mitigates both inter- and intra-modal forgetting, outperforming prior CL baselines in unified multimodal generation settings. Codes will be publicly available: https://github.com/Christina200/MoDE-official.git

</details>


### [88] [Atomic Diffusion Models for Small Molecule Structure Elucidation from NMR Spectra](https://arxiv.org/abs/2512.03127)
*Ziyu Xiong,Yichi Zhang,Foyez Alauddin,Chu Xin Cheng,Joon Soo An,Mohammad R. Seyedsayamdost,Ellen D. Zhong*

Main category: cs.LG

TL;DR: ChefNMR：基于原子扩散模型和Transformer架构，直接从1D NMR谱和化学式预测未知分子结构的端到端框架，在天然产物结构预测中达到超过65%的准确率。


<details>
  <summary>Details</summary>
Motivation: NMR谱解析是确定小分子结构的关键技术，尤其在天然产物和临床治疗药物发现中至关重要。然而，传统NMR谱解析过程耗时、需要大量专业经验，限制了分子发现的效率。

Method: 将结构解析构建为条件生成问题，采用基于非等变Transformer架构的原子扩散模型。构建了包含超过111,000个天然产物的模拟1D NMR谱数据集进行训练。

Result: ChefNMR在具有挑战性的天然产物化合物结构预测中取得了超过65%的准确率，这是目前最好的结果。该框架显著推进了小分子结构自动解析的进程。

Conclusion: ChefNMR为自动化小分子结构解析迈出了重要一步，展示了深度学习在加速分子发现方面的巨大潜力，有望改变传统NMR谱解析的工作流程。

Abstract: Nuclear Magnetic Resonance (NMR) spectroscopy is a cornerstone technique for determining the structures of small molecules and is especially critical in the discovery of novel natural products and clinical therapeutics. Yet, interpreting NMR spectra remains a time-consuming, manual process requiring extensive domain expertise. We introduce ChefNMR (CHemical Elucidation From NMR), an end-to-end framework that directly predicts an unknown molecule's structure solely from its 1D NMR spectra and chemical formula. We frame structure elucidation as conditional generation from an atomic diffusion model built on a non-equivariant transformer architecture. To model the complex chemical groups found in natural products, we generated a dataset of simulated 1D NMR spectra for over 111,000 natural products. ChefNMR predicts the structures of challenging natural product compounds with an unsurpassed accuracy of over 65%. This work takes a significant step toward solving the grand challenge of automating small-molecule structure elucidation and highlights the potential of deep learning in accelerating molecular discovery. Code is available at https://github.com/ml-struct-bio/chefnmr.

</details>


### [89] [Contrastive Deep Learning for Variant Detection in Wastewater Genomic Sequencing](https://arxiv.org/abs/2512.03158)
*Adele Chinda,Richmond Azumah,Hemanth Demakethepalli Venkateswara*

Main category: cs.LG

TL;DR: 提出基于VQ-VAE的无监督病毒变异检测框架，用于废水基因组监测，无需参考基因组或变异标签，在SARS-CoV-2废水测序数据上取得高准确率。


<details>
  <summary>Details</summary>
Motivation: 废水基因组监测面临高测序噪声、低病毒覆盖率、片段化读取和缺乏变异标签等挑战，传统基于参考的变异检测方法难以处理新突变且计算资源需求大。

Method: 使用向量量化变分自编码器(VQ-VAE)从k-mer标记化序列中学习基因组模式的离散码本，无需参考基因组或变异标签；扩展基础架构包括掩码重建预训练（处理缺失数据）和对比学习（获得高判别性嵌入）。

Result: 在约10万条SARS-CoV-2废水测序数据上，VQ-VAE达到99.52%平均标记级准确率和56.33%精确序列匹配率，码本利用率为19.73%（512个码中101个活跃）。对比微调显著改善聚类：64维嵌入Silhouette分数提升35%（0.31到0.42），128维嵌入提升42%（0.31到0.44）。

Conclusion: 该无参考框架为基因组监测提供了可扩展、可解释的方法，可直接应用于公共卫生监测，展示了嵌入维度对变异判别能力的重要影响。

Abstract: Wastewater-based genomic surveillance has emerged as a powerful tool for population-level viral monitoring, offering comprehensive insights into circulating viral variants across entire communities. However, this approach faces significant computational challenges stemming from high sequencing noise, low viral coverage, fragmented reads, and the complete absence of labeled variant annotations. Traditional reference-based variant calling pipelines struggle with novel mutations and require extensive computational resources. We present a comprehensive framework for unsupervised viral variant detection using Vector-Quantized Variational Autoencoders (VQ-VAE) that learns discrete codebooks of genomic patterns from k-mer tokenized sequences without requiring reference genomes or variant labels. Our approach extends the base VQ-VAE architecture with masked reconstruction pretraining for robustness to missing data and contrastive learning for highly discriminative embeddings. Evaluated on SARS-CoV-2 wastewater sequencing data comprising approximately 100,000 reads, our VQ-VAE achieves 99.52% mean token-level accuracy and 56.33% exact sequence match rate while maintaining 19.73% codebook utilization (101 of 512 codes active), demonstrating efficient discrete representation learning. Contrastive fine-tuning with different projection dimensions yields substantial clustering improvements: 64-dimensional embeddings achieve +35% Silhouette score improvement (0.31 to 0.42), while 128-dimensional embeddings achieve +42% improvement (0.31 to 0.44), clearly demonstrating the impact of embedding dimensionality on variant discrimination capability. Our reference-free framework provides a scalable, interpretable approach to genomic surveillance with direct applications to public health monitoring.

</details>


### [90] [Plantain: Plan-Answer Interleaved Reasoning](https://arxiv.org/abs/2512.03176)
*Anthony Liang,Jonathan Berant,Adam Fisch,Abhimanyu Goyal,Kalpesh Krishna,Jacob Eisenstein*

Main category: cs.LG

TL;DR: 提出交错推理(IR)和Plantain方法，让语言模型在思考过程中输出中间结果，减少用户等待时间并允许早期干预，相比传统"先思考后回答"方法在数学推理和编程任务上提升6%准确率，减少60%首次响应时间。


<details>
  <summary>Details</summary>
Motivation: 传统语言模型推理时长时间沉默思考，不给用户任何提示，如果推理基于错误前提，用户无法及时干预纠正，造成时间浪费和糟糕体验。人类对话中会进行轻量级、增量的确认来确保双方理解一致，因此研究语言模型是否能学习类似行为。

Method: 提出交错推理(IR)方法，模型在思考和生成最终答案之间交替输出中间响应。进一步提出Plantain(计划-思考-答案交错)方法，第一个中间响应是执行任务的明确分步计划，允许用户干预并为后续推理步骤提供早期反馈。

Result: Plantain方法在多个具有挑战性的数学推理和编程基准测试中，pass@1指标提升约6%，同时相对于"先思考后回答"基线，首次响应时间减少超过60%。

Conclusion: 交错推理特别是Plantain方法能够有效减少感知延迟，提高模型性能，同时允许用户早期干预，改善了人机交互体验，是传统"先思考后回答"方法的有前景替代方案。

Abstract: Reasoning models often spend a significant amount of time thinking before they generate a visible response. In the meantime, they do not give the user any hints as to whether their reasoning is on the right track, and do not give the user any recourse to stop and correct them if their reasoning is flawed. This creates a frustrating, but unfortunately common, experience: the user's time is wasted while the model reasons from a false premise that could have easily been corrected. In contrast, human speakers typically perform lightweight, incremental grounding acts to ensure that participants in the conversation are on the same page; here we ask if language models can learn to leverage a similar type of behavior? With this motivation, we propose interleaved reasoning (IR), in which the model alternates between thinking and surfacing intermediate responses, as an alternative to the standard "think-then-answer" approach. By providing useful information to the user earlier, IR reduces perceived latency, the time a user waits for an initial output, without compromising the quality of the final response. We further introduce a specialization of interleaved reasoning, Plantain (Plan-Thought-Answer Interleaving), where the first intermediate response is an explicit, step-by-step plan for executing the task. This plan-first strategy allows for user intervention and early feedback for subsequent reasoning steps. We demonstrate that Plantain yields an ~6% improvement in pass@1 across several challenging math reasoning and coding benchmarks, while reducing time-to-first-response by over 60% relative to think-then-answer baselines.

</details>


### [91] [Neighborhood density estimation using space-partitioning based hashing schemes](https://arxiv.org/abs/2512.03187)
*Aashi Jindal*

Main category: cs.LG

TL;DR: FiRE/FiRE.1是用于单细胞RNA测序数据中罕见细胞亚群检测的草图算法，Enhash是用于流数据概念漂移检测的高效集成学习器


<details>
  <summary>Details</summary>
Motivation: 解决大规模单细胞RNA测序数据中罕见细胞亚群快速检测的挑战，以及流数据中概念漂移的高效检测问题

Method: FiRE/FiRE.1使用草图技术进行异常检测；Enhash使用投影哈希构建集成学习器进行概念漂移检测

Result: FiRE/FiRE.1在罕见细胞亚群检测上优于现有技术；Enhash在各种漂移类型中在时间和准确度上都具有竞争力

Conclusion: 提出的两种算法分别在单细胞RNA测序异常检测和流数据概念漂移检测中表现出色，具有实际应用价值

Abstract: This work introduces FiRE/FiRE.1, a novel sketching-based algorithm for anomaly detection to quickly identify rare cell sub-populations in large-scale single-cell RNA sequencing data. This method demonstrated superior performance against state-of-the-art techniques. Furthermore, the thesis proposes Enhash, a fast and resource-efficient ensemble learner that uses projection hashing to detect concept drift in streaming data, proving highly competitive in time and accuracy across various drift types.

</details>


### [92] [Scaling Internal-State Policy-Gradient Methods for POMDPs](https://arxiv.org/abs/2512.03204)
*Douglas Aberdeen,Jonathan Baxter*

Main category: cs.LG

TL;DR: 本文提出了几种改进算法，用于在无限时域设置中学习具有记忆的策略，包括已知环境模型时的直接学习和通过模拟学习，并在大型POMDP问题上进行了测试。


<details>
  <summary>Details</summary>
Motivation: 策略梯度方法在部分可观察环境中学习动作机制方面受到关注，但在需要记忆时效果不佳，因此需要开发改进算法来处理需要记忆的策略学习问题。

Method: 开发了多种改进算法：1) 当环境模型已知时直接学习记忆策略；2) 通过模拟学习记忆策略；在无限时域设置中实现。

Result: 在大型POMDP问题上进行了比较测试，包括噪声机器人导航和多智能体问题，验证了算法的有效性。

Conclusion: 提出的改进算法能够有效学习需要记忆的策略，解决了策略梯度方法在记忆需求场景中的局限性，为部分可观察环境中的策略学习提供了更好的解决方案。

Abstract: Policy-gradient methods have received increased attention recently as a mechanism for learning to act in partially observable environments. They have shown promise for problems admitting memoryless policies but have been less successful when memory is required. In this paper we develop several improved algorithms for learning policies with memory in an infinite-horizon setting -- directly when a known model of the environment is available, and via simulation otherwise. We compare these algorithms on some large POMDPs, including noisy robot navigation and multi-agent problems.

</details>


### [93] [A Multi-Agent, Policy-Gradient approach to Network Routing](https://arxiv.org/abs/2512.03211)
*Nigel Tao,Jonathan Baxter,Lex Weaver*

Main category: cs.LG

TL;DR: OLPOMDP算法应用于网络路由问题，多个分布式路由器代理学习协作行为，无需显式通信，通过奖励塑形提升收敛速度。


<details>
  <summary>Details</summary>
Motivation: 网络路由是一个分布式决策问题，具有数值性能指标（如平均传输时间）。传统方法可能无法有效处理分布式代理之间的协作，需要探索强化学习在路由优化中的应用。

Method: 使用OLPOMDP（策略梯度强化学习算法）应用于模拟网络路由，多个分布式代理（路由器）学习协作行为，无需显式通信。通过奖励塑形技术，明确惩罚次优行为模式来改进学习。

Result: 代理成功学习到协作行为，避免了仅对个体有利但对整体性能有害的行为。奖励塑形显著提高了收敛速度。

Conclusion: OLPOMDP算法能有效解决分布式网络路由问题，代理可学习协作行为而无需显式通信，奖励塑形是提升学习效率的关键技术。

Abstract: Network routing is a distributed decision problem which naturally admits numerical performance measures, such as the average time for a packet to travel from source to destination. OLPOMDP, a policy-gradient reinforcement learning algorithm, was successfully applied to simulated network routing under a number of network models. Multiple distributed agents (routers) learned co-operative behavior without explicit inter-agent communication, and they avoided behavior which was individually desirable, but detrimental to the group's overall performance. Furthermore, shaping the reward signal by explicitly penalizing certain patterns of sub-optimal behavior was found to dramatically improve the convergence rate.

</details>


### [94] [Perch 2.0 transfers 'whale' to underwater tasks](https://arxiv.org/abs/2512.03219)
*Andrea Burns,Lauren Harrell,Bart van Merriënboer,Vincent Dumoulin,Jenny Hamer,Tom Denton*

Main category: cs.LG

TL;DR: Perch 2.0生物声学基础模型在海洋哺乳动物音频任务上通过少量样本迁移学习表现出色，优于其他预训练模型。


<details>
  <summary>Details</summary>
Motivation: 尽管Perch 2.0在训练数据中几乎不包含海洋哺乳动物音频，但研究者希望评估其在海洋哺乳动物和水下音频任务上的迁移学习能力，特别是在少量标注样本的情况下。

Method: 使用Perch 2.0生成的嵌入进行线性探测（linear probing），并与多个其他预训练生物声学模型（包括Perch 1.0、SurfPerch、AVES-bio、BirdAVES、Birdnet V2.3等）进行对比，评估在少量样本迁移学习任务上的性能。

Result: Perch 2.0的嵌入在少量样本迁移学习中表现出持续的高性能，在大多数任务上优于其他嵌入模型，特别适合用于开发海洋哺乳动物分类的线性分类器。

Conclusion: Perch 2.0模型是开发海洋哺乳动物分类线性分类器的推荐选择，特别是在标注样本有限的情况下，其嵌入表现出优越的迁移学习能力。

Abstract: Perch 2.0 is a supervised bioacoustics foundation model pretrained on 14,597 species, including birds, mammals, amphibians, and insects, and has state-of-the-art performance on multiple benchmarks. Given that Perch 2.0 includes almost no marine mammal audio or classes in the training data, we evaluate Perch 2.0 performance on marine mammal and underwater audio tasks through few-shot transfer learning. We perform linear probing with the embeddings generated from this foundation model and compare performance to other pretrained bioacoustics models. In particular, we compare Perch 2.0 with previous multispecies whale, Perch 1.0, SurfPerch, AVES-bio, BirdAVES, and Birdnet V2.3 models, which have open-source tools for transfer-learning and agile modeling. We show that the embeddings from the Perch 2.0 model have consistently high performance for few-shot transfer learning, generally outperforming alternative embedding models on the majority of tasks, and thus is recommended when developing new linear classifiers for marine mammal classification with few labeled examples.

</details>


### [95] [SPARK: Stepwise Process-Aware Rewards for Reference-Free Reinforcement Learning](https://arxiv.org/abs/2512.03244)
*Salman Rahman,Sruthi Gorantla,Arpit Gupta,Swastik Roy,Nanyun Peng,Yang Liu*

Main category: cs.LG

TL;DR: SPARK框架通过三阶段方法实现无参考强化学习：1) 生成器产生多样解，验证器并行和顺序评估；2) 用验证输出训练生成式过程奖励模型；3) 将PRM-CoT作为奖励模型用于数学推理RL，超越基于真实答案的方法。


<details>
  <summary>Details</summary>
Motivation: 过程奖励模型(PRMs)需要昂贵的步骤级标注或真实参考，限制了其应用。作者希望开发无需真实答案或可验证参考的强化学习方法，在缺乏真实答案的领域实现有效训练。

Method: SPARK三阶段框架：1) 生成器产生多样解，验证器通过并行扩展(自一致性)和顺序扩展(元批判)评估；2) 用验证输出作为合成训练数据微调生成式过程奖励模型；3) 将PRM-CoT作为奖励模型用于RL训练，并引入格式约束防止奖励黑客攻击。

Result: 在ProcessBench上达到67.5 F1，优于参考引导训练的66.4和GPT-4o的61.9。在六个数学推理基准上平均准确率47.4%，超越基于真实答案的RLVR(43.9%)。实现了超越真实答案方法的无参考RL训练。

Conclusion: SPARK框架实现了无需真实答案或可验证参考的强化学习，在缺乏真实答案的领域开辟了新可能性，展示了合成验证数据可以超越真实监督的效果。

Abstract: Process reward models (PRMs) that provide dense, step-level feedback have shown promise for reinforcement learning, yet their adoption remains limited by the need for expensive step-level annotations or ground truth references. We propose SPARK: a three-stage framework where in the first stage a generator model produces diverse solutions and a verifier model evaluates them using parallel scaling (self-consistency) and sequential scaling (meta-critique). In the second stage, we use these verification outputs as synthetic training data to fine-tune generative process reward models, which subsequently serve as reward signals during training. We show that aggregating multiple independent verifications at the step level produces training data for process reward models that surpass ground-truth outcome supervision, achieving 67.5 F1 on ProcessBench (a benchmark for identifying erroneous steps in mathematical reasoning) compared to 66.4 for reference-guided training and 61.9 for GPT-4o. In the final stage, we apply our generative PRM with chain-of-thought verification (PRM-CoT) as the reward model in RL experiments on mathematical reasoning, and introduce format constraints to prevent reward hacking. Using Qwen2.5-Math-7B, we achieve 47.4% average accuracy across six mathematical reasoning benchmarks, outperforming ground-truth-based RLVR (43.9%). Our work enables reference-free RL training that exceeds ground-truth methods, opening new possibilities for domains lacking verifiable answers or accessible ground truth.

</details>


### [96] [Too Late to Recall: Explaining the Two-Hop Problem in Multimodal Knowledge Retrieval](https://arxiv.org/abs/2512.03276)
*Constantin Venhoff,Ashkan Khakzar,Sonia Joseph,Philip Torr,Neel Nanda*

Main category: cs.LG

TL;DR: 研究发现视觉语言模型在事实回忆任务上表现下降，原因是实体表示形成太晚，无法有效利用LLM已有的知识回忆机制。


<details>
  <summary>Details</summary>
Motivation: 许多视觉语言模型在事实回忆任务上表现不如其文本LLM骨干模型，需要探究多模态微调在扩展LLM机制到视觉输入上的有效性。

Method: 对14种不同架构、规模和训练设置的VLM进行基准测试，使用归因修补、激活修补和探测技术分析性能差异，并尝试两种性能恢复方法。

Result: 14个模型中有11个表现下降；性能下降的VLM因实体表示形成太晚而无法利用LLM的事实回忆电路；性能高的VLM能早期形成实体表示。

Conclusion: 早期实体表示形成的速度决定VLM能否有效利用预训练LLM机制；机制分析能解释多模态对齐中的系统性失败。

Abstract: Training vision language models (VLMs) aims to align visual representations from a vision encoder with the textual representations of a pretrained large language model (LLM). However, many VLMs exhibit reduced factual recall performance compared to their LLM backbones, raising the question of how effective multimodal fine-tuning is at extending existing mechanisms within the LLM to visual inputs. We argue that factual recall based on visual inputs requires VLMs to solve a two-hop problem: (1) forming entity representations from visual inputs, and (2) recalling associated factual knowledge based on these entity representations. By benchmarking 14 VLMs with various architectures (LLaVA, Native, Cross-Attention), sizes (7B-124B parameters), and training setups on factual recall tasks against their original LLM backbone models, we find that 11 of 14 models exhibit factual recall degradation. We select three models with high and two models with low performance degradation, and use attribution patching, activation patching, and probing to show that degraded VLMs struggle to use the existing factual recall circuit of their LLM backbone, because they resolve the first hop too late in the computation. In contrast, high-performing VLMs resolve entity representations early enough to reuse the existing factual recall mechanism. Finally, we demonstrate two methods to recover performance: patching entity representations from the LLM backbone into the VLM, and prompting with chain-of-thought reasoning. Our results highlight that the speed of early entity resolution critically determines how effective VLMs are in using preexisting LLM mechanisms. More broadly, our work illustrates how mechanistic analysis can explain and unveil systematic failures in multimodal alignment.

</details>


### [97] [BlendedNet++: A Large-Scale Blended Wing Body Aerodynamics Dataset and Benchmark](https://arxiv.org/abs/2512.03280)
*Nicholas Sung,Steven Spreizer,Mohamed Elrefaie,Matthew C. Jones,Faez Ahmed*

Main category: cs.LG

TL;DR: BlendedNet++：一个包含12,000+混合翼体飞机几何形状的大规模空气动力学数据集和基准测试，提供集成力/力矩系数和密集表面场数据，用于前向代理预测和逆向设计任务。


<details>
  <summary>Details</summary>
Motivation: 当前机器学习空气动力学代理模型面临大型场解析数据集稀缺的问题，限制了精确点预测和可重复逆向设计的进展。需要标准化数据集和基准来促进公平、可重复的研究。

Method: 创建包含12,000+独特几何形状的混合翼体飞机数据集，每个在单一飞行条件下进行稳态RANS CFD模拟。建立前向代理基准测试六种模型架构，并实现基于条件扩散模型的逆向设计任务。

Result: 数据集包含12,490个空气动力学结果，提供集成系数和密集表面场数据。建立了统一的前向和逆向协议，包含多模型基线，支持跨架构和优化范式的公平比较。

Conclusion: BlendedNet++为场级空气动力学和逆向设计提供了可重复研究的催化剂，数据集、分割、基线和脚本将在接受后发布，有望推动该领域的标准化研究。

Abstract: Despite progress in machine learning-based aerodynamic surrogates, the scarcity of large, field-resolved datasets limits progress on accurate pointwise prediction and reproducible inverse design for aircraft. We introduce BlendedNet++, a large-scale aerodynamic dataset and benchmark focused on blended wing body (BWB) aircraft. The dataset contains over 12,000 unique geometries, each simulated at a single flight condition, yielding 12,490 aerodynamic results for steady RANS CFD. For every case, we provide (i) integrated force/moment coefficients CL, CD, CM and (ii) dense surface fields of pressure and skin friction coefficients Cp and (Cfx, Cfy, Cfz). Using this dataset, we standardize a forward-surrogate benchmark to predict pointwise fields across six model families: GraphSAGE, GraphUNet, PointNet, a coordinate Transformer (Transolver-style), a FiLMNet (coordinate MLP with feature-wise modulation), and a Graph Neural Operator Transformer (GNOT). Finally, we present an inverse design task of achieving a specified lift-to-drag ratio under fixed flight conditions, implemented via a conditional diffusion model. To assess performance, we benchmark this approach against gradient-based optimization on the same surrogate and a diffusion-optimization hybrid that first samples with the conditional diffusion model and then further optimizes the designs. BlendedNet++ provides a unified forward and inverse protocol with multi-model baselines, enabling fair, reproducible comparison across architectures and optimization paradigms. We expect BlendedNet++ to catalyze reproducible research in field-level aerodynamics and inverse design; resources (dataset, splits, baselines, and scripts) will be released upon acceptance.

</details>


### [98] [Multi-Frequency Federated Learning for Human Activity Recognition Using Head-Worn Sensors](https://arxiv.org/abs/2512.03287)
*Dario Fenoglio,Mohan Li,Davide Casnici,Matias Laporte,Shkurta Gashi,Silvia Santini,Martin Gjoreski,Marc Langheinrich*

Main category: cs.LG

TL;DR: 提出多频联邦学习用于头戴设备活动识别，解决隐私问题和设备采样频率差异


<details>
  <summary>Details</summary>
Motivation: 传统人类活动识别依赖集中式用户数据，存在隐私风险；不同设备采样频率不同，需要跨设备联合学习

Method: 采用多频联邦学习框架，支持隐私保护的机器学习，并处理设备间采样频率差异

Result: 在两个数据集上相比频率特定方法有改进，表明多频联邦学习在活动识别任务中具有潜力

Conclusion: 多频联邦学习为头戴设备活动识别提供隐私保护解决方案，代码已开源供进一步研究

Abstract: Human Activity Recognition (HAR) benefits various application domains, including health and elderly care. Traditional HAR involves constructing pipelines reliant on centralized user data, which can pose privacy concerns as they necessitate the uploading of user data to a centralized server. This work proposes multi-frequency Federated Learning (FL) to enable: (1) privacy-aware ML; (2) joint ML model learning across devices with varying sampling frequency. We focus on head-worn devices (e.g., earbuds and smart glasses), a relatively unexplored domain compared to traditional smartwatch- or smartphone-based HAR. Results have shown improvements on two datasets against frequency-specific approaches, indicating a promising future in the multi-frequency FL-HAR task. The proposed network's implementation is publicly available for further research and development.

</details>


### [99] [ASPEN: An Adaptive Spectral Physics-Enabled Network for Ginzburg-Landau Dynamics](https://arxiv.org/abs/2512.03290)
*Julian Evan Chrisnanto,Nurfauzi Fadillah,Yulison Herry Chrisnanto*

Main category: cs.LG

TL;DR: 提出ASPEN架构，通过自适应谱层解决PINNs在非线性多尺度问题中的谱偏差问题，成功求解复杂Ginzburg-Landau方程。


<details>
  <summary>Details</summary>
Motivation: 传统PINNs在处理刚性、多尺度、非线性PDE系统时存在谱偏差问题，无法有效表示高频分量，导致求解失败。

Method: 引入ASPEN架构，在网络输入阶段集成自适应谱层和可学习傅里叶特征，动态调整谱基以适应解所需的频率内容。

Result: ASPEN成功求解复杂Ginzburg-Landau方程，预测解与高分辨率真值视觉无差别，物理残差中位数低至5.10×10^-3，正确捕捉物理特性。

Conclusion: 自适应谱基的引入使ASPEN成为处理复杂动力系统的鲁棒物理一致求解器，为标准PINNs失败的挑战性物理问题提供了新解决方案。

Abstract: Physics-Informed Neural Networks (PINNs) have emerged as a powerful, mesh-free paradigm for solving partial differential equations (PDEs). However, they notoriously struggle with stiff, multi-scale, and nonlinear systems due to the inherent spectral bias of standard multilayer perceptron (MLP) architectures, which prevents them from adequately representing high-frequency components. In this work, we introduce the Adaptive Spectral Physics-Enabled Network (ASPEN), a novel architecture designed to overcome this critical limitation. ASPEN integrates an adaptive spectral layer with learnable Fourier features directly into the network's input stage. This mechanism allows the model to dynamically tune its own spectral basis during training, enabling it to efficiently learn and represent the precise frequency content required by the solution. We demonstrate the efficacy of ASPEN by applying it to the complex Ginzburg-Landau equation (CGLE), a canonical and challenging benchmark for nonlinear, stiff spatio-temporal dynamics. Our results show that a standard PINN architecture catastrophically fails on this problem, diverging into non-physical oscillations. In contrast, ASPEN successfully solves the CGLE with exceptional accuracy. The predicted solution is visually indistinguishable from the high-resolution ground truth, achieving a low median physics residual of 5.10 x 10^-3. Furthermore, we validate that ASPEN's solution is not only pointwise accurate but also physically consistent, correctly capturing emergent physical properties, including the rapid free energy relaxation and the long-term stability of the domain wall front. This work demonstrates that by incorporating an adaptive spectral basis, our framework provides a robust and physically-consistent solver for complex dynamical systems where standard PINNs fail, opening new options for machine learning in challenging physical domains.

</details>


### [100] [Adaptive Regime-Switching Forecasts with Distribution-Free Uncertainty: Deep Switching State-Space Models Meet Conformal Prediction](https://arxiv.org/abs/2512.03298)
*Echo Diyun LU,Charles Findling,Marianne Clausel,Alessandro Leite,Wei Gong,Pierric Kersaudy*

Main category: cs.LG

TL;DR: 该研究将自适应共形推理（ACI）与深度切换状态空间模型结合，为非平稳时间序列中的切换机制预测提供分布无关的不确定性量化，并开发了统一的共形包装器，可在多种序列模型上提供在线预测区间保证。


<details>
  <summary>Details</summary>
Motivation: 时间序列中的机制转换经常破坏平稳性，使得校准的不确定性变得与点预测精度同等重要。研究旨在解决非平稳时间序列预测中的不确定性量化问题，特别是在存在机制切换的情况下。

Method: 将深度切换状态空间模型与自适应共形推理（ACI）及其聚合变体（AgACI）耦合。开发了一个统一的共形包装器，可应用于多种序列基线模型（包括S4、MC-Dropout GRU、稀疏高斯过程和变点局部模型），在非平稳性和模型误设下提供在线预测区间。

Result: 在合成和真实数据集上，共形化的预测器实现了接近名义水平的覆盖率，同时保持了有竞争力的准确性，并且通常提高了区间效率（即更窄的预测区间）。

Conclusion: 通过结合深度切换模型与自适应共形推理，可以在非平稳时间序列中实现分布无关的不确定性量化，为机制切换预测提供具有有限样本边际保证的可靠预测区间，同时保持预测准确性。

Abstract: Regime transitions routinely break stationarity in time series, making calibrated uncertainty as important as point accuracy. We study distribution-free uncertainty for regime-switching forecasting by coupling Deep Switching State Space Models with Adaptive Conformal Inference (ACI) and its aggregated variant (AgACI). We also introduce a unified conformal wrapper that sits atop strong sequence baselines including S4, MC-Dropout GRU, sparse Gaussian processes, and a change-point local model to produce online predictive bands with finite-sample marginal guarantees under nonstationarity and model misspecification. Across synthetic and real datasets, conformalized forecasters achieve near-nominal coverage with competitive accuracy and generally improved band efficiency.

</details>


### [101] [HydroDCM: Hydrological Domain-Conditioned Modulation for Cross-Reservoir Inflow Prediction](https://arxiv.org/abs/2512.03300)
*Pengfei Hu,Fan Ming,Xiaoxue Han,Chang Lu,Yue Ning,Dan Lu*

Main category: cs.LG

TL;DR: 提出HydroDCM框架，通过伪域标签引导对抗学习提取不变特征，结合元数据轻量适配层，解决多水库流域预测中的域泛化问题


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在水库入库流量预测中表现良好，但在不同水库间应用时因分布差异（域偏移问题）性能下降。传统域泛化方法难以处理水文系统中每个水库的独特流入模式以及空间元数据的间接重要影响

Method: HydroDCM框架：1) 利用水库空间元数据构建伪域标签；2) 通过对抗学习提取不变时序特征；3) 推理时通过目标水库元数据指导的轻量条件层适配特征，平衡域不变性与位置特异性

Result: 在科罗拉多河上游流域30个真实水库上的实验表明，该方法在多域条件下显著优于最先进的域泛化基线方法，且保持计算高效

Conclusion: HydroDCM通过结合伪域引导的对抗学习和元数据驱动的轻量适配，有效解决了多水库水文系统的域泛化问题，为跨水库流量预测提供了可扩展解决方案

Abstract: Deep learning models have shown promise in reservoir inflow prediction, yet their performance often deteriorates when applied to different reservoirs due to distributional differences, referred to as the domain shift problem. Domain generalization (DG) solutions aim to address this issue by extracting domain-invariant representations that mitigate errors in unseen domains. However, in hydrological settings, each reservoir exhibits unique inflow patterns, while some metadata beyond observations like spatial information exerts indirect but significant influence. This mismatch limits the applicability of conventional DG techniques to many-domain hydrological systems. To overcome these challenges, we propose HydroDCM, a scalable DG framework for cross-reservoir inflow forecasting. Spatial metadata of reservoirs is used to construct pseudo-domain labels that guide adversarial learning of invariant temporal features. During inference, HydroDCM adapts these features through light-weight conditioning layers informed by the target reservoir's metadata, reconciling DG's invariance with location-specific adaptation. Experiment results on 30 real-world reservoirs in the Upper Colorado River Basin demonstrate that our method substantially outperforms state-of-the-art DG baselines under many-domain conditions and remains computationally efficient.

</details>


### [102] [Robust Tabular Foundation Models](https://arxiv.org/abs/2512.03307)
*Matthew Peroni,Franck Le,Vadim Sheinin*

Main category: cs.LG

TL;DR: RTFM提出了一种对抗性训练框架，通过参数化生成器分布来强调对模型特别具有挑战性的合成数据集，从而提升表格基础模型的鲁棒性和性能。


<details>
  <summary>Details</summary>
Motivation: 表格基础模型(TFMs)在结构化数据上显示出超越传统ML方法的潜力。现有研究主要关注设计高质量的数据生成器先验来提升预训练性能，但作者发现参数化生成器分布可以从对抗鲁棒性角度出发，在训练中调整生成器以强调对模型特别困难的数据集。

Method: 提出RTFM框架：1) 引入最优性差距度量，计算TFM性能与XGBoost、CatBoost、Random Forests等强基线最佳可达性能的差异；2) 基于此设计模型无关的对抗训练框架，通过参数化生成器分布来生成对模型具有挑战性的合成数据集；3) 应用于TabPFN V2分类器。

Result: RTFM显著提升了基准测试性能：相比原始TabPFN和其他基线算法，平均归一化AUC提升高达6%，且仅需不到10万个额外合成数据集。这些结果展示了仅使用合成数据进行针对性对抗训练和微调TFMs的新方向。

Conclusion: RTFM框架为表格基础模型提供了一种有效的对抗训练方法，通过参数化生成器分布来强调困难数据集，显著提升了模型性能，展示了仅使用合成数据进行针对性训练的新方向。

Abstract: The development of tabular foundation models (TFMs) has accelerated in recent years, showing strong potential to outperform traditional ML methods for structured data. A key finding is that TFMs can be pretrained entirely on synthetic datasets, opening opportunities to design data generators that encourage desirable model properties. Prior work has mainly focused on crafting high-quality priors over generators to improve overall pretraining performance. Our insight is that parameterizing the generator distribution enables an adversarial robustness perspective: during training, we can adapt the generator to emphasize datasets that are particularly challenging for the model. We formalize this by introducing an optimality gap measure, given by the difference between TFM performance and the best achievable performance as estimated by strong baselines such as XGBoost, CatBoost, and Random Forests. Building on this idea, we propose Robust Tabular Foundation Models (RTFM), a model-agnostic adversarial training framework. Applied to the TabPFN V2 classifier, RTFM improves benchmark performance, with up to a 6% increase in mean normalized AUC over the original TabPFN and other baseline algorithms, while requiring less than 100k additional synthetic datasets. These results highlight a promising new direction for targeted adversarial training and fine-tuning of TFMs using synthetic data alone.

</details>


### [103] [Retrofitting Earth System Models with Cadence-Limited Neural Operator Updates](https://arxiv.org/abs/2512.03309)
*Aniruddha Bora,Shixuan Zhang,Khemraj Shukla,Bryce Harrop,George Em. Karniadakis,L. Ruby Leung*

Main category: cs.LG

TL;DR: 提出一种基于算子学习的框架，通过在线应用偏差修正趋势来改进地球系统模型预测，使用U-Net架构变体在多尺度特征提取方面优于基准，在混合模拟中保持稳定性和计算可行性。


<details>
  <summary>Details</summary>
Motivation: 传统的数据同化偏差修正方法在模型自由运行时效果有限，需要一种能够在线修正偏差并保持长期稳定性的方法，以解决地球系统模型因分辨率、参数化和初始条件不确定性带来的预测限制。

Method: 开发基于U-Net的算子学习框架，包括Inception U-Net(IUNet)和多尺度网络(M&M)，结合不同上采样和感受野来捕捉多尺度非线性特征。在E3SM模型运行时约束下训练，将瞬时模型状态映射到偏差修正趋势，并在积分过程中在线应用。

Result: 两种架构在离线测试中都优于标准U-Net基线，表明功能丰富性而非参数数量驱动性能。在在线混合E3SM运行中，M&M在变量和垂直层次上提供最一致的偏差减少。ML增强配置在多年模拟中保持稳定且计算可行。

Conclusion: 该框架强调长期稳定性、可移植性和更新频率限制，展示了表达性ML算子在学习和结构化跨尺度关系以及改造传统ESM方面的实用性，为可扩展混合建模提供了实用途径。

Abstract: Coarse resolution, imperfect parameterizations, and uncertain initial states and forcings limit Earth-system model (ESM) predictions. Traditional bias correction via data assimilation improves constrained simulations but offers limited benefit once models run freely. We introduce an operator-learning framework that maps instantaneous model states to bias-correction tendencies and applies them online during integration. Building on a U-Net backbone, we develop two operator architectures Inception U-Net (IUNet) and a multi-scale network (M\&M) that combine diverse upsampling and receptive fields to capture multiscale nonlinear features under Energy Exascale Earth System Model (E3SM) runtime constraints. Trained on two years E3SM simulations nudged toward ERA5 reanalysis, the operators generalize across height levels and seasons. Both architectures outperform standard U-Net baselines in offline tests, indicating that functional richness rather than parameter count drives performance. In online hybrid E3SM runs, M\&M delivers the most consistent bias reductions across variables and vertical levels. The ML-augmented configurations remain stable and computationally feasible in multi-year simulations, providing a practical pathway for scalable hybrid modeling. Our framework emphasizes long-term stability, portability, and cadence-limited updates, demonstrating the utility of expressive ML operators for learning structured, cross-scale relationships and retrofitting legacy ESMs.

</details>


### [104] [Cache What Lasts: Token Retention for Memory-Bounded KV Cache in LLMs](https://arxiv.org/abs/2512.03324)
*Ngoc Bui,Shubham Sharma,Simran Lamba,Saumitra Mishra,Rex Ying*

Main category: cs.LG

TL;DR: TRIM-KV：一种通过轻量级保留门学习token内在重要性的方法，在内存受限时根据预测的保留分数淘汰低重要性token，实现高效的长序列LLM推理。


<details>
  <summary>Details</summary>
Motivation: 长序列LLM推理中，自注意力的二次计算成本和不断增长的KV缓存是核心瓶颈。现有方法（如量化、卸载或启发式KV淘汰）要么协调成本高，要么依赖不可靠的注意力重要性代理。

Method: 提出TRIM-KV方法，通过轻量级保留门在token创建时学习其内在重要性。每个门预测一个随时间衰减的保留分数，反映token对特定层和头的长期效用。当内存预算超限时淘汰低分token，确保缓存始终包含最关键token。通过蒸馏和容量损失进行高效训练，仅需微调门且推理开销可忽略。

Result: 在数学推理（GSM8K、MATH-500、AIME24）、过程生成（LongProc）、对话长记忆基准（LongMemEval）和长上下文理解（LongBench、SCBench）上，TRIM-KV始终优于强淘汰和可学习检索基线，尤其在低内存情况下。在某些设置中甚至超越全缓存模型，表明选择性保留可作为正则化形式，抑制无信息token的噪声。

Conclusion: TRIM-KV通过学习的保留分数有效管理KV缓存，不仅提高效率，还提供层和头特定角色的洞察，为LLM可解释性开辟新路径。保留分数与人类直觉一致，自然恢复下沉token、滑动窗口和要点压缩等启发式方法，无需显式设计。

Abstract: Memory and computation remain core bottlenecks in long-horizon LLM inference due to the quadratic cost of self-attention and the ever-growing key-value (KV) cache. Existing strategies for memory-bounded inference, such as quantization, offloading, or heuristic KV eviction, either incur high orchestration costs or rely on unreliable attention-based proxies of importance. We propose TRIM-KV, a novel approach that learns each token's intrinsic importance at creation time via a lightweight retention gate. Each gate predicts a scalar retention score that decays over time, reflecting the long-term utility of the token for a specific layer and head. Tokens with low scores are evicted when the memory budget is exceeded, ensuring that the cache always contains the most critical tokens. TRIM-KV is trained efficiently through distillation from a frozen LLM combined with a capacity loss, requiring only gate fine-tuning and adding negligible inference overhead. Across mathematical reasoning (GSM8K, MATH-500, AIME24), procedural generation (LongProc), conversational long-memory benchmarks (LongMemEval), and long-context understanding (LongBench and SCBench), TRIM-KV consistently outperforms strong eviction and learnable retrieval baselines, especially in low-memory regimes. Remarkably, it even surpasses full-cache models in some settings, showing that selective retention can serve as a form of regularization, suppressing noise from uninformative tokens. Qualitative analyses further reveal that learned retention scores align with human intuition, naturally recovering heuristics such as sink tokens, sliding windows, and gist compression without explicit design. Beyond efficiency, retention scores provide insights into layer- and head-specific roles, suggesting a new path toward LLM interpretability.

</details>


### [105] [Single-Round Scalable Analytic Federated Learning](https://arxiv.org/abs/2512.03336)
*Alan T. L. Bacellar,Mustafa Munir,Felipe M. G. França,Priscila M. V. Lima,Radu Marculescu,Lizy K. John*

Main category: cs.LG

TL;DR: SAFLe框架通过引入结构化头部和稀疏分组嵌入，实现非线性表达能力，同时保持单轮联邦学习的优势，在准确性和效率上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 联邦学习面临通信开销大和异构数据性能下降两大挑战。现有方法存在局限：AFL只适用于线性模型，DeepAFL恢复了准确性但牺牲了单轮优势。需要打破这种权衡。

Method: 提出SAFLe框架，引入结构化头部（分桶特征）和稀疏分组嵌入，证明这种非线性架构在数学上等价于高维线性回归，从而可以使用AFL的单轮不变聚合法则。

Result: SAFLe在联邦视觉任务中建立了新的最先进水平，在所有基准测试中显著优于线性AFL和多轮DeepAFL，实现了高效可扩展的解决方案。

Conclusion: SAFLe成功打破了联邦学习中准确性与效率的权衡，通过数学等价性实现了非线性表达能力和单轮聚合的优势，为联邦视觉提供了高效可扩展的解决方案。

Abstract: Federated Learning (FL) is plagued by two key challenges: high communication overhead and performance collapse on heterogeneous (non-IID) data. Analytic FL (AFL) provides a single-round, data distribution invariant solution, but is limited to linear models. Subsequent non-linear approaches, like DeepAFL, regain accuracy but sacrifice the single-round benefit. In this work, we break this trade-off. We propose SAFLe, a framework that achieves scalable non-linear expressivity by introducing a structured head of bucketed features and sparse, grouped embeddings. We prove this non-linear architecture is mathematically equivalent to a high-dimensional linear regression. This key equivalence allows SAFLe to be solved with AFL's single-shot, invariant aggregation law. Empirically, SAFLe establishes a new state-of-the-art for analytic FL, significantly outperforming both linear AFL and multi-round DeepAFL in accuracy across all benchmarks, demonstrating a highly efficient and scalable solution for federated vision.

</details>


### [106] [Breaking Determinism: Stochastic Modeling for Reliable Off-Policy Evaluation in Ad Auctions](https://arxiv.org/abs/2512.03354)
*Hongseon Yeom,Jaeyoul Shin,Soojin Min,Jeongmin Yoon,Seunghak Yu,Dongyeop Kang*

Main category: cs.LG

TL;DR: 提出首个确定性广告拍卖中的离线策略评估框架，利用出价景观模型近似倾向得分，实现可靠的离线评估，显著减少在线A/B测试的成本和风险。


<details>
  <summary>Details</summary>
Motivation: 在线A/B测试消耗大量工程资源且存在收入损失风险，而传统离线策略评估方法在确定性拍卖环境中因非获胜广告曝光概率为零而无法应用。

Method: 重新利用出价景观模型近似倾向得分，推导稳健的近似倾向得分，使自归一化逆倾向评分等稳定估计器能够在确定性拍卖环境中进行反事实评估。

Result: 在AuctionNet仿真基准和大型工业平台2周在线A/B测试中验证，方法在CTR预测上达到92%的平均方向准确率，显著优于参数基线。

Conclusion: 这是首个实用且经过验证的确定性拍卖环境可靠离线策略评估框架，为昂贵且高风险的在线实验提供了高效替代方案。

Abstract: Online A/B testing, the gold standard for evaluating new advertising policies, consumes substantial engineering resources and risks significant revenue loss from deploying underperforming variations. This motivates the use of Off-Policy Evaluation (OPE) for rapid, offline assessment. However, applying OPE to ad auctions is fundamentally more challenging than in domains like recommender systems, where stochastic policies are common. In online ad auctions, it is common for the highest-bidding ad to win the impression, resulting in a deterministic, winner-takes-all setting. This results in zero probability of exposure for non-winning ads, rendering standard OPE estimators inapplicable. We introduce the first principled framework for OPE in deterministic auctions by repurposing the bid landscape model to approximate the propensity score. This model allows us to derive robust approximate propensity scores, enabling the use of stable estimators like Self-Normalized Inverse Propensity Scoring (SNIPS) for counterfactual evaluation. We validate our approach on the AuctionNet simulation benchmark and against 2-weeks online A/B test from a large-scale industrial platform. Our method shows remarkable alignment with online results, achieving a 92\% Mean Directional Accuracy (MDA) in CTR prediction, significantly outperforming the parametric baseline. MDA is the most critical metric for guiding deployment decisions, as it reflects the ability to correctly predict whether a new model will improve or harm performance. This work contributes the first practical and validated framework for reliable OPE in deterministic auction environments, offering an efficient alternative to costly and risky online experiments.

</details>


### [107] [A2G-QFL: Adaptive Aggregation with Two Gains in Quantum Federated learning](https://arxiv.org/abs/2512.03363)
*Shanika Iroshi Nanayakkara,Shiva Raj Pokhrel*

Main category: cs.LG

TL;DR: 提出A2G（自适应双增益聚合）框架，解决量子联邦学习中因客户端质量不均、量子隐形传态保真度随机、设备不稳定以及局部与全局模型几何不匹配导致的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习聚合规则假设欧几里得拓扑和均匀通信可靠性，不适用于新兴的量子联邦系统。量子使能和异构经典网络中的联邦学习面临客户端质量不均、量子隐形传态保真度随机、设备不稳定以及局部与全局模型几何不匹配等挑战，导致性能显著下降。

Method: 提出A2G（自适应聚合与双增益）框架，包含两个增益：几何增益调节几何混合，QoS增益基于隐形传态保真度、延迟和不稳定性调节客户端重要性。开发了A2G更新规则，在平滑性和有界方差假设下建立收敛保证。

Result: A2G在量子经典混合测试平台上表现出改进的稳定性和更高的准确性，特别是在异构和噪声条件下。该框架能够恢复FedAvg、QoS感知平均和基于流形的聚合作为特例。

Conclusion: A2G框架为量子联邦学习提供了一种有效的自适应聚合方法，能够处理量子网络特有的挑战，在异构和噪声环境中实现更好的性能和稳定性。

Abstract: Federated learning (FL) deployed over quantum enabled and heterogeneous classical networks faces significant performance degradation due to uneven client quality, stochastic teleportation fidelity, device instability, and geometric mismatch between local and global models. Classical aggregation rules assume euclidean topology and uniform communication reliability, limiting their suitability for emerging quantum federated systems. This paper introduces A2G (Adaptive Aggregation with Two Gains), a dual gain framework that jointly regulates geometric blending through a geometry gain and modulates client importance using a QoS gain derived from teleportation fidelity, latency, and instability. We develop the A2G update rule, establish convergence guarantees under smoothness and bounded variance assumptions, and show that A2G recovers FedAvg, QoS aware averaging, and manifold based aggregation as special cases. Experiments on a quantum classical hybrid testbed demonstrate improved stability and higher accuracy under heterogeneous and noisy conditions.

</details>


### [108] [MAGE-ID: A Multimodal Generative Framework for Intrusion Detection Systems](https://arxiv.org/abs/2512.03375)
*Mahdi Arab Loodaricheh,Mohammad Hossein Manshaei,Anita Raja*

Main category: cs.LG

TL;DR: MAGE-ID是一个基于扩散的多模态攻击生成框架，用于入侵检测系统的数据增强，通过联合训练Transformer和CNN编码器，将表格流量特征与转换图像耦合，解决了数据不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 现代入侵检测系统面临异构网络流量、不断演变的网络威胁以及良性流量与攻击流量之间显著数据不平衡的挑战。现有生成模型仅限于单模态，无法捕捉跨域依赖关系。

Method: 提出MAGE-ID（多模态攻击生成器），这是一个基于扩散的生成框架，通过统一的潜在先验将表格流量特征与其转换图像耦合。联合训练基于Transformer和CNN的变分编码器与EDM风格去噪器，实现平衡且连贯的多模态合成。

Result: 在CIC-IDS-2017和NSL-KDD数据集上的评估显示，MAGE-ID在保真度、多样性和下游检测性能方面显著优于TabSyn和TabDDPM，证明了其用于多模态IDS增强的有效性。

Conclusion: MAGE-ID通过多模态生成方法有效解决了入侵检测中的数据不平衡问题，为IDS数据增强提供了更有效的解决方案。

Abstract: Modern Intrusion Detection Systems (IDS) face severe challenges due to heterogeneous network traffic, evolving cyber threats, and pronounced data imbalance between benign and attack flows. While generative models have shown promise in data augmentation, existing approaches are limited to single modalities and fail to capture cross-domain dependencies. This paper introduces MAGE-ID (Multimodal Attack Generator for Intrusion Detection), a diffusion-based generative framework that couples tabular flow features with their transformed images through a unified latent prior. By jointly training Transformer and CNN-based variational encoders with an EDM style denoiser, MAGE-ID achieves balanced and coherent multimodal synthesis. Evaluations on CIC-IDS-2017 and NSL-KDD demonstrate significant improvements in fidelity, diversity, and downstream detection performance over TabSyn and TabDDPM, highlighting the effectiveness of MAGE-ID for multimodal IDS augmentation.

</details>


### [109] [UniQL: Unified Quantization and Low-rank Compression for Adaptive Edge LLMs](https://arxiv.org/abs/2512.03383)
*Hung-Yueh Chiang,Chi-Chih Chang,Yu-Chen Lu,Chien-Yu Lin,Kai-Chiang Wu,Mohamed S. Abdelfattah,Diana Marculescu*

Main category: cs.LG

TL;DR: UniQL：一个统一的边缘LLM后训练量化和低秩压缩框架，支持Transformer、SSM和混合模型，实现4-5.7倍内存减少和2.7-3.4倍吞吐提升，精度损失在5%以内。


<details>
  <summary>Details</summary>
Motivation: 在移动设备上部署大语言模型面临内存有限和计算资源共享的挑战，资源可用性受设备当前工作负载影响，增加了模型部署的不确定性。

Method: 提出UniQL统一框架，集成量化和低秩压缩，包含高效结构化权重排序（加速20倍）、量化感知SVD、SSM状态感知权重排序、融合RoPE内核等技术，支持云端单次工作流和端侧可配置剪枝率（最高35%）。

Result: 量化剪枝模型实现4-5.7倍内存减少和2.7-3.4倍吞吐提升，在15%剪枝率下，Transformer（Llama3、Qwen2.5）、SSM（Mamba2）和混合模型（Nemotron-H、Bamba-v2）的精度损失控制在5%以内。

Conclusion: UniQL为边缘LLM部署提供高效解决方案，通过统一的量化和压缩框架支持多种模型架构，显著减少内存占用并提升推理速度，同时保持模型精度。

Abstract: Deploying large language model (LLM) models on mobile platforms faces significant challenges due to the limited memory and shared computational resources of the device. Resource availability may be an issue as it is directly impacted by the current device workload, adding to the uncertainty of model deployment. We introduce UniQL, a unified post-training quantization and low-rank compression framework with on-device configurable pruning rates for edge LLMs. UniQL is a general framework that integrates quantization and low-rank compression for Transformers, State Space Models (SSMs), and hybrid models to support diverse edge applications. In our proposed joint framework, we introduce an efficient structured weight-sorting method that speeds up computation by 20x, quantization-aware singular value decomposition (SVD) to minimize quantization errors, state-aware weight sorting for SSMs, and a fused rotary positional embedding (RoPE) kernel for pruned models. Our framework performs weight-sorting, fine-tuning, and quantization in the cloud in a single-pass workflow, while enabling on-device configurable pruning rates up to 35%. Our experiments show that quantized and pruned models achieve a memory reduction of 4x-5.7x and a token-throughput improvement of 2.7x-3.4x, maintaining accuracy within 5% of the original models at 15% pruning across Transformers (Llama3 and Qwen2.5), SSMs (Mamba2), and hybrid models (Nemotron-H and Bamba-v2). The code and quantized models are available at: https://github.com/enyac-group/UniQL.

</details>


### [110] [VS-Graph: Scalable and Efficient Graph Classification Using Hyperdimensional Computing](https://arxiv.org/abs/2512.03394)
*Hamed Poursiami,Shay Snyder,Guojing Cong,Thomas Potok,Maryam Parsa*

Main category: cs.LG

TL;DR: VS-Graph：一种基于向量符号架构的图学习框架，通过尖峰扩散机制和关联消息传递，在保持高效性的同时达到与图神经网络相当的分类性能，训练速度提升高达450倍。


<details>
  <summary>Details</summary>
Motivation: 图神经网络（GNN）在图分类任务中表现出色但计算成本高，限制了其在资源受限设备上的部署。超维计算（HDC）虽然轻量高效，但现有基于HDC的图方法通常难以达到GNN的预测性能。因此需要开发一种既能保持HDC效率又能接近GNN表达能力的图学习方法。

Method: 提出VS-Graph框架，包含两个核心组件：1）尖峰扩散机制（Spike Diffusion）用于拓扑驱动的节点识别；2）关联消息传递方案（Associative Message Passing）用于在高维向量空间内实现多跳邻域聚合。该方法无需基于梯度的优化或反向传播。

Result: 在MUTAG和DD等标准基准测试中，VS-Graph比先前的HDC基线性能提升4-5%，达到与现代GNN相当的准确率。在多个数据集上匹配或超过GNN基线性能，同时训练速度提升高达450倍。即使在超向量维度降至D=128时仍保持高精度，展示了在边缘和神经形态硬件上超高效执行的潜力。

Conclusion: VS-Graph成功缩小了HDC效率与消息传递表达能力之间的差距，提供了一种无需梯度优化的高效图学习方法，为在资源受限设备上部署图学习模型开辟了新途径。

Abstract: Graph classification is a fundamental task in domains ranging from molecular property prediction to materials design. While graph neural networks (GNNs) achieve strong performance by learning expressive representations via message passing, they incur high computational costs, limiting their scalability and deployment on resource-constrained devices. Hyperdimensional Computing (HDC), also known as Vector Symbolic Architectures (VSA), offers a lightweight, brain-inspired alternative, yet existing HDC-based graph methods typically struggle to match the predictive performance of GNNs. In this work, we propose VS-Graph, a vector-symbolic graph learning framework that narrows the gap between the efficiency of HDC and the expressive power of message passing. VS-Graph introduces a Spike Diffusion mechanism for topology-driven node identification and an Associative Message Passing scheme for multi-hop neighborhood aggregation entirely within the high-dimensional vector space. Without gradient-based optimization or backpropagation, our method achieves competitive accuracy with modern GNNs, outperforming the prior HDC baseline by 4-5% on standard benchmarks such as MUTAG and DD. It also matches or exceeds the performance of the GNN baselines on several datasets while accelerating the training by a factor of up to 450x. Furthermore, VS-Graph maintains high accuracy even with the hypervector dimensionality reduced to D=128, demonstrating robustness under aggressive dimension compression and paving the way for ultra-efficient execution on edge and neuromorphic hardware.

</details>


### [111] [Tuning-Free Structured Sparse Recovery of Multiple Measurement Vectors using Implicit Regularization](https://arxiv.org/abs/2512.03393)
*Lakshmi Jayalal,Sheetal Kalyani*

Main category: cs.LG

TL;DR: 提出一种基于隐式正则化的免调参框架，用于解决多测量向量（MMV）中的联合稀疏信号恢复问题，无需先验知识或参数调整。


<details>
  <summary>Details</summary>
Motivation: 传统MMV方法（如M-OMP和M-FOCUSS）需要仔细的参数调整或对信号稀疏度和噪声方差的先验知识，这在实际应用中存在局限性。

Method: 通过过参数化引入隐式正则化，将估计矩阵重新参数化为因子，分离共享的行支持与个体向量条目。对标准最小二乘目标应用梯度下降，优化动态自然促进期望的行稀疏结构。

Result: 理论证明：在足够小且平衡的初始化下，优化动态表现出"动量效应"，使真实支持中的行范数增长显著快于其他行，保证解轨迹收敛到理想的行稀疏解。实证结果显示性能与现有方法相当。

Conclusion: 该框架为MMV问题提供了一种免调参解决方案，无需先验信息即可实现与传统方法相当的性能，克服了传统方法的参数调整限制。

Abstract: Recovering jointly sparse signals in the multiple measurement vectors (MMV) setting is a fundamental problem in machine learning, but traditional methods like multiple measurement vectors orthogonal matching pursuit (M-OMP) and multiple measurement vectors FOCal Underdetermined System Solver (M-FOCUSS) often require careful parameter tuning or prior knowledge of the sparsity of the signal and/or noise variance. We introduce a novel tuning-free framework that leverages Implicit Regularization (IR) from overparameterization to overcome this limitation. Our approach reparameterizes the estimation matrix into factors that decouple the shared row-support from individual vector entries. We show that the optimization dynamics inherently promote the desired row-sparse structure by applying gradient descent to a standard least-squares objective on these factors. We prove that with a sufficiently small and balanced initialization, the optimization dynamics exhibit a "momentum-like" effect, causing the norms of rows in the true support to grow significantly faster than others. This formally guarantees that the solution trajectory converges towards an idealized row-sparse solution. Additionally, empirical results demonstrate that our approach achieves performance comparable to established methods without requiring any prior information or tuning.

</details>


### [112] [Better World Models Can Lead to Better Post-Training Performance](https://arxiv.org/abs/2512.03400)
*Prakhar Gupta,Henry Conklin,Sarah-Jane Leslie,Andrew Lee*

Main category: cs.LG

TL;DR: 研究显示，在Transformer中明确加入世界建模目标能改善状态表示的可线性解码性和因果可控性，从而提升强化学习后训练在序列规划任务上的效果，尤其是在复杂任务状态下。


<details>
  <summary>Details</summary>
Motivation: 研究明确的世界建模目标如何影响Transformer的内部表示和下游能力，特别是在不同训练阶段。探索世界建模质量对强化学习后训练性能的影响。

Method: 使用2x2x2魔方作为测试环境，比较标准的下一个token预测与两种明确的世界建模策略：(i)状态预测预训练和(ii)状态预测+下一个token联合目标。使用Group Relative Policy Optimization (GRPO)进行后训练，通过线性探测和因果干预评估表示质量。

Result: 明确的世界建模产生了更可线性解码和因果可控的状态表示。更重要的是，改进的状态表示导致GRPO获得更高的性能提升，尤其是在更难的魔方状态下。

Conclusion: 优化状态表示可以提高后训练在序列规划任务中的有效性，表明明确的世界建模目标能改善Transformer的内部表示并提升下游任务性能。

Abstract: In this work we study how explicit world-modeling objectives affect the internal representations and downstream capability of Transformers across different training stages. We use a controlled 2x2x2 Rubik's Cube and ask: (1) how does explicitly pretraining a world model affect the model's latent representations, and (2) how does world-model quality affect the model's performance after reinforcement learning post-training? We compare standard next-token prediction to two explicit world-modeling strategies -- (i) state-prediction pretraining and (ii) a joint state-prediction + next-token objective -- and assess task performance after Group Relative Policy Optimization (GRPO) is applied as post-training. We evaluate the representation quality with linear probes and causal interventions. We find that explicit world-modeling yields more linearly decodable and causally steerable state representations. More importantly, we find that improved state representations lead to higher gains for GRPO, especially on harder cube states. Our results indicate that sharpening state representations can improve the effectiveness of post-training for sequence-planning tasks.

</details>


### [113] [ATHENA: Agentic Team for Hierarchical Evolutionary Numerical Algorithms](https://arxiv.org/abs/2512.03476)
*Juan Diego Toscano,Daniel T. Chen,George Em Karniadakis*

Main category: cs.LG

TL;DR: ATHENA是一个自主代理框架，通过层次化进化数值算法管理端到端计算研究生命周期，在科学计算和科学机器学习中实现超人类性能，验证误差达到10^{-14}。


<details>
  <summary>Details</summary>
Motivation: 解决科学计算和科学机器学习中理论概念化与计算实现之间的差距，这是一个主要的瓶颈问题。当前标准自动化工具无法处理复杂的科学问题，需要更智能的系统来管理完整的研究流程。

Method: 基于HENA循环（层次化进化数值算法），这是一个知识驱动的诊断过程，被构建为上下文多臂老虎机问题。系统作为在线学习器分析先前试验，从组合空间中选择结构"动作"，通过专家蓝图指导，将这些动作转换为可执行代码以生成科学奖励。

Result: 在科学计算中，自主识别数学对称性以获得精确解析解，或在基础模型失败时推导稳定数值求解器。在科学机器学习中，进行深度诊断处理病态公式，结合混合符号-数值工作流解决多物理问题。框架实现超人类性能，验证误差达到10^{-14}。

Conclusion: ATHENA代表了范式转变，从实现机制转向方法论创新，通过"人在回路"协作干预可以弥合稳定性差距，将结果提高一个数量级，加速科学发现。

Abstract: Bridging the gap between theoretical conceptualization and computational implementation is a major bottleneck in Scientific Computing (SciC) and Scientific Machine Learning (SciML). We introduce ATHENA (Agentic Team for Hierarchical Evolutionary Numerical Algorithms), an agentic framework designed as an Autonomous Lab to manage the end-to-end computational research lifecycle. Its core is the HENA loop, a knowledge-driven diagnostic process framed as a Contextual Bandit problem. Acting as an online learner, the system analyzes prior trials to select structural `actions' ($A_n$) from combinatorial spaces guided by expert blueprints (e.g., Universal Approximation, Physics-Informed constraints). These actions are translated into executable code ($S_n$) to generate scientific rewards ($R_n$). ATHENA transcends standard automation: in SciC, it autonomously identifies mathematical symmetries for exact analytical solutions or derives stable numerical solvers where foundation models fail. In SciML, it performs deep diagnosis to tackle ill-posed formulations and combines hybrid symbolic-numeric workflows (e.g., coupling PINNs with FEM) to resolve multiphysics problems. The framework achieves super-human performance, reaching validation errors of $10^{-14}$. Furthermore, collaborative ``human-in-the-loop" intervention allows the system to bridge stability gaps, improving results by an order of magnitude. This paradigm shift focuses from implementation mechanics to methodological innovation, accelerating scientific discovery.

</details>


### [114] [Full-Stack Alignment: Co-Aligning AI and Institutions with Thick Models of Value](https://arxiv.org/abs/2512.03399)
*Joe Edelman,Tan Zhi-Xuan,Ryan Lowe,Oliver Klingefjord,Vincent Wang-Mascianica,Matija Franklin,Ryan Othniel Kearns,Ellie Hain,Atrisha Sarkar,Michiel Bakker,Fazl Barez,David Duvenaud,Jakob Foerster,Iason Gabriel,Joseph Gubbels,Bryce Goodman,Andreas Haupt,Jobst Heitzig,Julian Jara-Ettinger,Atoosa Kasirzadeh,James Ravi Kirkpatrick,Andrew Koh,W. Bradley Knox,Philipp Koralus,Joel Lehman,Sydney Levine,Samuele Marro,Manon Revel,Toby Shorin,Morgan Sutherland,Michael Henry Tessler,Ivan Vendrov,James Wilken-Smith*

Main category: cs.LG

TL;DR: 论文提出"全栈对齐"概念，认为仅对齐AI系统与操作者意图不够，需要同时对齐AI系统及其所在机构与人类价值观，并建议使用"厚价值模型"来有效表示价值观。


<details>
  <summary>Details</summary>
Motivation: 当前AI对齐方法存在局限：即使AI系统完美对齐其操作组织的意图，如果该组织的目标与其他机构和个人不匹配，仍可能导致不良社会结果。现有价值观表示方法（如效用函数、偏好排序或无结构文本）难以区分价值观与其他信号、支持原则性规范推理和建模集体利益。

Method: 提出"厚价值模型"方法，结构化表示价值观和规范，使系统能够区分持久价值观与短暂偏好、建模个体选择的社会嵌入性，并在新领域进行规范性推理。该方法不强制特定个人或集体繁荣愿景。

Result: 在五个领域展示了厚价值模型的应用：AI价值管理、规范能力代理、双赢谈判系统、意义保持经济机制和民主监管机构。

Conclusion: 需要全栈对齐（同时对齐AI系统及其机构与人类价值观），而厚价值模型是实现这一目标的有效方法，能够解决当前价值观表示方法的局限性，支持更全面的AI对齐和社会价值整合。

Abstract: Beneficial societal outcomes cannot be guaranteed by aligning individual AI systems with the intentions of their operators or users. Even an AI system that is perfectly aligned to the intentions of its operating organization can lead to bad outcomes if the goals of that organization are misaligned with those of other institutions and individuals. For this reason, we need full-stack alignment, the concurrent alignment of AI systems and the institutions that shape them with what people value. This can be done without imposing a particular vision of individual or collective flourishing. We argue that current approaches for representing values, such as utility functions, preference orderings, or unstructured text, struggle to address these and other issues effectively. They struggle to distinguish values from other signals, to support principled normative reasoning, and to model collective goods. We propose thick models of value will be needed. These structure the way values and norms are represented, enabling systems to distinguish enduring values from fleeting preferences, to model the social embedding of individual choices, and to reason normatively, applying values in new domains. We demonstrate this approach in five areas: AI value stewardship, normatively competent agents, win-win negotiation systems, meaning-preserving economic mechanisms, and democratic regulatory institutions.

</details>


### [115] [Physics-Driven Learning Framework for Tomographic Tactile Sensing](https://arxiv.org/abs/2512.03512)
*Xuanxuan Yang,Xiuyang Zhang,Haofeng Chen,Gang Ma,Xiaojie Wang*

Main category: cs.LG

TL;DR: PhyDNN：一种将EIT前向模型嵌入学习目标的物理驱动深度重建框架，用于高质量层析触觉传感，减少伪影并提高重建精度。


<details>
  <summary>Details</summary>
Motivation: 电阻抗层析成像（EIT）因其布线简单和形状灵活而成为大面积触觉传感的有吸引力的解决方案，但其非线性逆问题常导致严重伪影和不准确的接触重建。

Method: 提出PhyDNN框架，将EIT前向模型直接嵌入学习目标，联合最小化预测与真实电导率图之间的差异，并强制与正向偏微分方程的一致性。设计了可微分前向算子网络来近似非线性EIT响应，实现快速物理引导训练。

Result: 在16电极软传感器上的大量仿真和真实触觉实验表明，PhyDNN在重建接触形状、位置和压力分布方面持续优于NOSER、TV和标准DNN，产生更少伪影、更清晰边界和更高指标分数。

Conclusion: PhyDNN通过将物理约束嵌入深度学习框架，减少了深度网络的黑盒性质，提高了物理合理性和泛化能力，为高质量层析触觉传感提供了有效解决方案。

Abstract: Electrical impedance tomography (EIT) provides an attractive solution for large-area tactile sensing due to its minimal wiring and shape flexibility, but its nonlinear inverse problem often leads to severe artifacts and inaccurate contact reconstruction. This work presents PhyDNN, a physics-driven deep reconstruction framework that embeds the EIT forward model directly into the learning objective. By jointly minimizing the discrepancy between predicted and ground-truth conductivity maps and enforcing consistency with the forward PDE, PhyDNN reduces the black-box nature of deep networks and improves both physical plausibility and generalization. To enable efficient backpropagation, we design a differentiable forward-operator network that accurately approximates the nonlinear EIT response, allowing fast physics-guided training. Extensive simulations and real tactile experiments on a 16-electrode soft sensor show that PhyDNN consistently outperforms NOSER, TV, and standard DNNs in reconstructing contact shape, location, and pressure distribution. PhyDNN yields fewer artifacts, sharper boundaries, and higher metric scores, demonstrating its effectiveness for high-quality tomographic tactile sensing.

</details>


### [116] [When, How Long and How Much? Interpretable Neural Networks for Time Series Regression by Learning to Mask and Aggregate](https://arxiv.org/abs/2512.03578)
*Florent Forest,Amaury Wei,Olga Fink*

Main category: cs.LG

TL;DR: MAGNETS是一种用于时间序列外生回归任务的可解释神经网络架构，通过掩码聚合学习人类可理解的概念，无需标注即可提供透明决策过程。


<details>
  <summary>Details</summary>
Motivation: 当前时间序列外生回归模型虽然预测性能强，但通常是黑盒模型，难以理解驱动决策的时间模式。现有的后验可解释性技术产生的解释粗糙、嘈杂或不稳定，而内在可解释方法需要概念标注、无法捕捉特征交互、表达能力有限且难以扩展到高维多元数据。

Method: 提出MAGNETS（Mask-and-AGgregate NEtwork for Time Series）架构，通过掩码聚合学习紧凑的人类可理解概念，每个概念对应基于掩码的选定输入特征聚合，明确揭示哪些特征驱动预测以及何时重要。预测通过透明加性结构组合这些学习到的概念。

Result: 该方法无需任何标注即可学习人类可理解的概念，能够明确显示驱动预测的特征及其在时间序列中的重要性，提供清晰的模型决策过程洞察。

Conclusion: MAGNETS解决了现有可解释时间序列回归方法的局限性，提供了一种无需标注、能够捕捉特征交互、表达复杂时间模式且可扩展到高维多元数据的内在可解释神经网络架构。

Abstract: Time series extrinsic regression (TSER) refers to the task of predicting a continuous target variable from an input time series. It appears in many domains, including healthcare, finance, environmental monitoring, and engineering. In these settings, accurate predictions and trustworthy reasoning are both essential. Although state-of-the-art TSER models achieve strong predictive performance, they typically operate as black boxes, making it difficult to understand which temporal patterns drive their decisions. Post-hoc interpretability techniques, such as feature attribution, aim to to explain how the model arrives at its predictions, but often produce coarse, noisy, or unstable explanations. Recently, inherently interpretable approaches based on concepts, additive decompositions, or symbolic regression, have emerged as promising alternatives. However, these approaches remain limited: they require explicit supervision on the concepts themselves, often cannot capture interactions between time-series features, lack expressiveness for complex temporal patterns, and struggle to scale to high-dimensional multivariate data.
  To address these limitations, we propose MAGNETS (Mask-and-AGgregate NEtwork for Time Series), an inherently interpretable neural architecture for TSER. MAGNETS learns a compact set of human-understandable concepts without requiring any annotations. Each concept corresponds to a learned, mask-based aggregation over selected input features, explicitly revealing both which features drive predictions and when they matter in the sequence. Predictions are formed as combinations of these learned concepts through a transparent, additive structure, enabling clear insight into the model's decision process.

</details>


### [117] [GaussDetect-LiNGAM:Causal Direction Identification without Gaussianity test](https://arxiv.org/abs/2512.03428)
*Ziyi Ding,Xiao-Ping Zhang*

Main category: cs.LG

TL;DR: 提出GaussDetect-LiNGAM方法，通过利用前向模型噪声高斯性与反向回归残差独立性之间的等价关系，无需显式高斯性检验即可进行双变量因果发现。


<details>
  <summary>Details</summary>
Motivation: 传统LiNGAM方法依赖脆弱且对样本敏感的高斯性检验，这限制了因果推断在实际应用中的可靠性和可访问性。需要一种更稳健的方法来避免这些检验的局限性。

Method: 基于理论证明：在线性、无环和外生性假设下，前向模型噪声的高斯性等价于反向模型中回归变量与残差的独立性。利用这一等价关系，用稳健的基于核的独立性检验替代高斯性检验。

Result: 实验验证了理论等价性，表明GaussDetect-LiNGAM在不同噪声类型和样本量下保持高一致性，同时减少了每个决策所需的检验次数（TPD）。

Conclusion: 该方法提高了因果推断的效率和实际适用性，使LiNGAM在现实场景中更加可访问和可靠，无需依赖脆弱的高斯性检验。

Abstract: We propose GaussDetect-LiNGAM, a novel approach for bivariate causal discovery that eliminates the need for explicit Gaussianity tests by leveraging a fundamental equivalence between noise Gaussianity and residual independence in the reverse regression. Under the standard LiNGAM assumptions of linearity, acyclicity, and exogeneity, we prove that the Gaussianity of the forward-model noise is equivalent to the independence between the regressor and residual in the reverse model. This theoretical insight allows us to replace fragile and sample-sensitive Gaussianity tests with robust kernel-based independence tests. Experimental results validate the equivalence and demonstrate that GaussDetect-LiNGAM maintains high consistency across diverse noise types and sample sizes, while reducing the number of tests per decision (TPD). Our method enhances both the efficiency and practical applicability of causal inference, making LiNGAM more accessible and reliable in real-world scenarios.

</details>


### [118] [Grokked Models are Better Unlearners](https://arxiv.org/abs/2512.03437)
*Yuanbang Liang,Yang Li*

Main category: cs.LG

TL;DR: 研究发现，在模型完成"顿悟"（grokking）阶段后应用机器学习遗忘方法，相比在早期阶段应用，能实现更高效、更稳定、副作用更小的数据遗忘效果。


<details>
  <summary>Details</summary>
Motivation: 探索"顿悟"（延迟泛化现象）是否有助于机器学习遗忘任务，即在不完全重新训练的情况下移除特定数据的影响。研究比较在顿悟前后应用标准遗忘方法的效果差异。

Method: 在视觉任务（CNNs/ResNets在CIFAR、SVHN、ImageNet）和语言任务（transformer在TOFU风格设置）上，比较在顿悟前后应用标准遗忘方法的效果。分析特征和曲率以理解机制。

Result: 从顿悟后检查点开始遗忘，相比早期停止的模型，能实现：(1) 更高效的遗忘（更少更新达到目标遗忘水平），(2) 更少的副作用（在保留数据和测试集上性能下降更小），(3) 更稳定的更新（跨种子更一致）。

Conclusion: 顿悟后模型学习到更模块化的表示，减少了遗忘和保留子集之间的梯度对齐，从而促进选择性遗忘。何时训练模型（顿悟前vs后）是改进现有遗忘方法的正交杠杆。

Abstract: Grokking-delayed generalization that emerges well after a model has fit the training data-has been linked to robustness and representation quality. We ask whether this training regime also helps with machine unlearning, i.e., removing the influence of specified data without full retraining. We compare applying standard unlearning methods before versus after the grokking transition across vision (CNNs/ResNets on CIFAR, SVHN, and ImageNet) and language (a transformer on a TOFU-style setup). Starting from grokked checkpoints consistently yields (i) more efficient forgetting (fewer updates to reach a target forget level), (ii) less collateral damage (smaller drops on retained and test performance), and (iii) more stable updates across seeds, relative to early-stopped counterparts under identical unlearning algorithms. Analyses of features and curvature further suggest that post-grokking models learn more modular representations with reduced gradient alignment between forget and retain subsets, which facilitates selective forgetting. Our results highlight when a model is trained (pre- vs. post-grokking) as an orthogonal lever to how unlearning is performed, providing a practical recipe to improve existing unlearning methods without altering their algorithms.

</details>


### [119] [The promising potential of vision language models for the generation of textual weather forecasts](https://arxiv.org/abs/2512.03623)
*Edward C. C. Steele,Dinesh Mane,Emilio Monti,Luis Orus,Rebecca Chantrill-Cheyette,Matthew Couch,Kirstine I. Dale,Simon Eaton,Govindarajan Rangarajan,Amir Majlesi,Steven Ramsdale,Michael Sharpe,Craig Smith,Jonathan Smith,Rebecca Yates,Holly Ellis,Charles Ewen*

Main category: cs.LG

TL;DR: 使用视觉语言模型从视频编码的网格天气数据直接生成航运预报文本，探索多模态基础模型在气象产品服务中的新应用。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态基础模型能力强大，但在气象产品和服务生成方面的应用仍处于起步阶段。需要加速这些模型在气象领域的应用和采纳。

Method: 探索性地使用视觉语言模型，直接从视频编码的网格天气数据生成经典的航运预报文本。

Result: 早期结果显示，这种方法在提高生产效率和促进服务创新方面展现出有前景的可扩展技术机会。

Conclusion: 这项研究为气象企业及其他领域展示了多模态基础模型在增强生产效率和推动服务创新方面的潜力。

Abstract: Despite the promising capability of multimodal foundation models, their application to the generation of meteorological products and services remains nascent. To accelerate aspiration and adoption, we explore the novel use of a vision language model for writing the iconic Shipping Forecast text directly from video-encoded gridded weather data. These early results demonstrate promising scalable technological opportunities for enhancing production efficiency and service innovation within the weather enterprise and beyond.

</details>


### [120] [Multi-Modal Opinion Integration for Financial Sentiment Analysis using Cross-Modal Attention](https://arxiv.org/abs/2512.03464)
*Yujing Liu,Chen Yang*

Main category: cs.LG

TL;DR: 本文提出了一种用于金融情感分析的端到端深度学习框架，通过跨模态注意力机制整合时效性意见和流行性意见两种模态，在837家公司数据集上达到83.5%的准确率，显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有金融情感分析方法难以有效整合多样化的意见模态并捕捉它们之间的细粒度交互。金融市场中的公众意见具有时效性（近期市场更新）和流行性（趋势性集体情感）两种不同信息渠道，需要专门的方法来整合这两种模态。

Method: 提出端到端深度学习框架：1) 使用BERT（中文-wwm-ext）进行特征嵌入；2) 设计金融多头跨注意力机制（FMHCA）促进两种意见模态间的信息交换；3) 通过Transformer层优化处理特征；4) 使用多模态因子双线性池化进行特征融合；5) 分类为负面、中性和正面情感。

Result: 在涵盖837家公司的综合数据集上进行广泛实验，该方法达到83.5%的准确率，显著优于包括BERT+Transformer在内的基线方法，性能提升21%。

Conclusion: 该框架通过有效整合时效性和流行性两种金融意见模态，展示了支持更准确金融决策和风险管理的潜力，为金融情感分析提供了新的跨模态整合方法。

Abstract: In recent years, financial sentiment analysis of public opinion has become increasingly important for market forecasting and risk assessment. However, existing methods often struggle to effectively integrate diverse opinion modalities and capture fine-grained interactions across them. This paper proposes an end-to-end deep learning framework that integrates two distinct modalities of financial opinions: recency modality (timely opinions) and popularity modality (trending opinions), through a novel cross-modal attention mechanism specifically designed for financial sentiment analysis. While both modalities consist of textual data, they represent fundamentally different information channels: recency-driven market updates versus popularity-driven collective sentiment. Our model first uses BERT (Chinese-wwm-ext) for feature embedding and then employs our proposed Financial Multi-Head Cross-Attention (FMHCA) structure to facilitate information exchange between these distinct opinion modalities. The processed features are optimized through a transformer layer and fused using multimodal factored bilinear pooling for classification into negative, neutral, and positive sentiment. Extensive experiments on a comprehensive dataset covering 837 companies demonstrate that our approach achieves an accuracy of 83.5%, significantly outperforming baselines including BERT+Transformer by 21 percent. These results highlight the potential of our framework to support more accurate financial decision-making and risk management.

</details>


### [121] [Bayesian Event-Based Model for Disease Subtype and Stage Inference](https://arxiv.org/abs/2512.03467)
*Hongtao Hao,Joseph L. Austerweil*

Main category: cs.LG

TL;DR: 本文提出了一种贝叶斯子类型事件模型（BEBMS），在疾病进展子类型推断任务上显著优于现有的SuStaIn方法，并在阿尔茨海默病数据上得到更符合科学共识的结果。


<details>
  <summary>Details</summary>
Motivation: 慢性疾病在不同患者中的进展方式存在差异，通常存在少数几种进展子类型。现有的SuStaIn方法虽然广泛应用，但其鲁棒性需要评估。本文旨在开发更稳健的贝叶斯方法来推断疾病进展子类型。

Method: 提出了贝叶斯子类型事件模型（BEBMS），这是一种基于贝叶斯原理的事件模型变体。通过合成数据实验，在不同程度的模型误设情况下，比较BEBMS与SuStaIn在排序、分期和子类型分配任务上的性能。最后将两种方法应用于真实的阿尔茨海默病数据集。

Result: 在合成数据实验中，BEBMS在排序、分期和子类型分配任务上显著优于SuStaIn。在阿尔茨海默病数据应用中，BEBMS的结果比SuStaIn更符合该疾病进展的科学共识。

Conclusion: BEBMS作为一种贝叶斯子类型事件模型，在疾病进展子类型推断方面比SuStaIn更稳健和准确，为理解疾病异质性提供了更好的工具。

Abstract: Chronic diseases often progress differently across patients. Rather than randomly varying, there are typically a small number of subtypes for how a disease progresses across patients. To capture this structured heterogeneity, the Subtype and Stage Inference Event-Based Model (SuStaIn) estimates the number of subtypes, the order of disease progression for each subtype, and assigns each patient to a subtype from primarily cross-sectional data. It has been widely applied to uncover the subtypes of many diseases and inform our understanding of them. But how robust is its performance? In this paper, we develop a principled Bayesian subtype variant of the event-based model (BEBMS) and compare its performance to SuStaIn in a variety of synthetic data experiments with varied levels of model misspecification. BEBMS substantially outperforms SuStaIn across ordering, staging, and subtype assignment tasks. Further, we apply BEBMS and SuStaIn to a real-world Alzheimer's data set. We find BEBMS has results that are more consistent with the scientific consensus of Alzheimer's disease progression than SuStaIn.

</details>


### [122] [Dynamically Scaled Activation Steering](https://arxiv.org/abs/2512.03661)
*Alex Ferrando,Xavier Suau,Jordi Gonzàlez,Pau Rodriguez*

Main category: cs.LG

TL;DR: DSAS是一种动态缩放激活引导框架，通过自适应调整引导强度，只在检测到不良行为时进行干预，从而在毒性缓解和效用保持之间实现更好的权衡。


<details>
  <summary>Details</summary>
Motivation: 现有激活引导方法对所有输入统一应用干预，在不需要引导时会降低模型性能。需要一种能自适应决定何时引导以及如何引导的方法。

Method: DSAS将"何时引导"与"如何引导"解耦，在生成时计算上下文相关的缩放因子，选择性调整任何引导方法的强度，并可端到端联合优化。

Result: DSAS与现有引导方法结合时，能持续改进帕累托前沿，在毒性缓解和效用保持之间实现更好权衡。在文本到图像扩散模型中也有效，能调节特定概念。

Conclusion: DSAS提供了一种方法无关的引导框架，能以最小计算开销自适应调整引导强度，同时提高可解释性，识别哪些标记需要引导以及需要多少引导。

Abstract: Activation steering has emerged as a powerful method for guiding the behavior of generative models towards desired outcomes such as toxicity mitigation. However, most existing methods apply interventions uniformly across all inputs, degrading model performance when steering is unnecessary. We introduce Dynamically Scaled Activation Steering (DSAS), a method-agnostic steering framework that decouples when to steer from how to steer. DSAS adaptively modulates the strength of existing steering transformations across layers and inputs, intervening strongly only when undesired behavior is detected. At generation time, DSAS computes context-dependent scaling factors that selectively adjust the strength of any steering method. We also show how DSAS can be jointly optimized end-to-end together with the steering function. When combined with existing steering methods, DSAS consistently improves the Pareto front with respect to steering alone, achieving a better trade-off between toxicity mitigation and utility preservation. We further demonstrate DSAS's generality by applying it to a text-to-image diffusion model, showing how adaptive steering allows the modulation of specific concepts. Finally, DSAS introduces minimal computational overhead while improving interpretability, pinpointing which tokens require steering and by how much.

</details>


### [123] [SweetDeep: A Wearable AI Solution for Real-Time Non-Invasive Diabetes Screening](https://arxiv.org/abs/2512.03471)
*Ian Henriques,Lynda Elhassar,Sarvesh Relekar,Denis Walrave,Shayan Hassantabar,Vishu Ghanakota,Adel Laoui,Mahmoud Aich,Rafia Tir,Mohamed Zerguine,Samir Louafi,Moncef Kimouche,Emmanuel Cosson,Niraj K Jha*

Main category: cs.LG

TL;DR: SweetDeep是一个轻量级神经网络，利用三星智能手表在自由生活条件下收集的生理和人口统计数据，以少于3000个参数实现82.5%的糖尿病检测准确率。


<details>
  <summary>Details</summary>
Motivation: 全球2型糖尿病发病率上升，需要可扩展且经济高效的筛查方法。当前诊断依赖侵入性、昂贵的生化检测，而现有基于可穿戴设备的研究多在受控环境下进行，缺乏真实世界验证。

Method: 使用三星Galaxy Watch 7在欧盟和中东地区收集285名参与者的生理和人口统计数据，在自由生活条件下连续6天监测，每人每天提供多个2分钟传感器记录。开发了少于3000个参数的紧凑神经网络SweetDeep，结合工程特征和轻量架构。

Result: SweetDeep在三折交叉验证中达到82.5%的患者级准确率（82.1%宏F1，79.7%灵敏度，84.6%特异性），预期校准误差5.5%。在允许模型对低置信度预测（<10%）弃权的情况下，剩余患者的准确率提升至84.5%。

Conclusion: 工程特征与轻量架构的结合能够在真实世界可穿戴设备设置中实现准确、快速且可泛化的2型糖尿病检测，为大规模糖尿病筛查提供了有前景的非侵入性解决方案。

Abstract: The global rise in type 2 diabetes underscores the need for scalable and cost-effective screening methods. Current diagnosis requires biochemical assays, which are invasive and costly. Advances in consumer wearables have enabled early explorations of machine learning-based disease detection, but prior studies were limited to controlled settings. We present SweetDeep, a compact neural network trained on physiological and demographic data from 285 (diabetic and non-diabetic) participants in the EU and MENA regions, collected using Samsung Galaxy Watch 7 devices in free-living conditions over six days. Each participant contributed multiple 2-minute sensor recordings per day, totaling approximately 20 recordings per individual. Despite comprising fewer than 3,000 parameters, SweetDeep achieves 82.5% patient-level accuracy (82.1% macro-F1, 79.7% sensitivity, 84.6% specificity) under three-fold cross-validation, with an expected calibration error of 5.5%. Allowing the model to abstain on less than 10% of low-confidence patient predictions yields an accuracy of 84.5% on the remaining patients. These findings demonstrate that combining engineered features with lightweight architectures can support accurate, rapid, and generalizable detection of type 2 diabetes in real-world wearable settings.

</details>


### [124] [Quantum Topological Graph Neural Networks for Detecting Complex Fraud Patterns](https://arxiv.org/abs/2512.03696)
*Mohammad Doost,Mohammad Manthouri*

Main category: cs.LG

TL;DR: 提出QTGNN框架，结合量子嵌入、变分图卷积和拓扑数据分析，用于大规模金融网络中的欺诈交易检测。


<details>
  <summary>Details</summary>
Motivation: 传统欺诈检测方法难以捕捉复杂交易动态和结构异常，需要结合量子机器学习、图理论和拓扑分析的新方法。

Method: 量子数据嵌入增强纠缠、变分量子图卷积非线性动态、高阶拓扑不变量提取、混合量子-经典异常学习自适应优化、拓扑归因可解释决策。

Result: 在PaySim和Elliptic金融数据集上优于经典和量子基线方法，通过ROC-AUC、精确率和误报率等指标验证，可扩展到大规模交易网络。

Conclusion: QTGNN为金融欺诈检测提供了理论严谨、可解释且实用的解决方案，桥接了量子机器学习、图理论和拓扑分析。

Abstract: We propose a novel QTGNN framework for detecting fraudulent transactions in large-scale financial networks. By integrating quantum embedding, variational graph convolutions, and topological data analysis, QTGNN captures complex transaction dynamics and structural anomalies indicative of fraud. The methodology includes quantum data embedding with entanglement enhancement, variational quantum graph convolutions with non-linear dynamics, extraction of higher-order topological invariants, hybrid quantum-classical anomaly learning with adaptive optimization, and interpretable decision-making via topological attribution. Rigorous convergence guarantees ensure stable training on noisy intermediate-scale quantum (NISQ) devices, while stability of topological signatures provides robust fraud detection. Optimized for NISQ hardware with circuit simplifications and graph sampling, the framework scales to large transaction networks. Simulations on financial datasets, such as PaySim and Elliptic, benchmark QTGNN against classical and quantum baselines, using metrics like ROC-AUC, precision, and false positive rate. An ablation study evaluates the contributions of quantum embeddings, topological features, non-linear channels, and hybrid learning. QTGNN offers a theoretically sound, interpretable, and practical solution for financial fraud detection, bridging quantum machine learning, graph theory, and topological analysis.

</details>


### [125] [Joint Progression Modeling (JPM): A Probabilistic Framework for Mixed-Pathology Progression](https://arxiv.org/abs/2512.03475)
*Hongtao Hao,Joseph L. Austerweil*

Main category: cs.LG

TL;DR: 提出联合进展模型(JPM)处理神经退行性疾病中的混合病理问题，通过概率框架将单病轨迹视为部分排序，构建联合进展先验，相比传统单病模型提升约21%排序准确性。


<details>
  <summary>Details</summary>
Motivation: 传统事件模型(EBMs)假设个体只有单一疾病，但神经退行性疾病中混合病理很常见，需要能够处理多病理联合进展的模型。

Method: 提出联合进展模型(JPM)概率框架，将单病轨迹视为部分排序，构建联合进展先验。研究了四种变体：Pairwise、Bradley-Terry、Plackett-Luce和Mallows，分析校准性、分离性和锐度三个特性。

Result: 所有变体都具备校准性，分离性接近完美；锐度因变体而异，可通过输入部分排序的简单特征预测。在合成实验中，JPM比强基线SA-EBM提升约21%排序准确性。在NACC数据中，Mallows变体和基线模型与AD和VaD混合病理进展的文献更一致。

Conclusion: JPM是处理神经退行性疾病混合病理进展的有效框架，相比传统单病模型显著提升准确性，为理解多病理联合进展提供了新工具。

Abstract: Event-based models (EBMs) infer disease progression from cross-sectional data, and standard EBMs assume a single underlying disease per individual. In contrast, mixed pathologies are common in neurodegeneration. We introduce the Joint Progression Model (JPM), a probabilistic framework that treats single-disease trajectories as partial rankings and builds a prior over joint progressions. We study several JPM variants (Pairwise, Bradley-Terry, Plackett-Luce, and Mallows) and analyze three properties: (i) calibration -- whether lower model energy predicts smaller distance to the ground truth ordering; (ii) separation -- the degree to which sampled rankings are distinguishable from random permutations; and (iii) sharpness -- the stability of sampled aggregate rankings. All variants are calibrated, and all achieve near-perfect separation; sharpness varies by variant and is well-predicted by simple features of the input partial rankings (number and length of rankings, conflict, and overlap). In synthetic experiments, JPM improves ordering accuracy by roughly 21 percent over a strong EBM baseline (SA-EBM) that treats the joint disease as a single condition. Finally, using NACC, we find that the Mallows variant of JPM and the baseline model (SA-EBM) have results that are more consistent with prior literature on the possible disease progression of the mixed pathology of AD and VaD.

</details>


### [126] [Modal Logical Neural Networks](https://arxiv.org/abs/2512.03491)
*Antonin Sulc*

Main category: cs.LG

TL;DR: MLNNs是一个神经符号框架，将深度学习与模态逻辑的形式语义相结合，通过引入基于可能世界语义的模态算子神经元，实现可微分的"逻辑护栏"系统。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习缺乏形式逻辑推理能力，特别是在处理必然性和可能性等模态概念时。需要一种能够结合神经网络学习能力和逻辑推理严谨性的框架。

Method: 基于Kripke语义，引入专门的模态算子神经元（□和◇），在可能世界上操作。可访问关系可以是用户固定的已知规则，也可以由神经网络参数化学习。整个框架端到端可微，通过最小化逻辑矛盾损失进行学习。

Result: 在四个案例研究中验证：语法护栏、未知的公理检测、多智能体认知信任、自然语言谈判中的建设性欺骗检测。实验表明，强制执行或学习可访问关系可以提高逻辑一致性和可解释性。

Conclusion: MLNNs提供了一个灵活的神经符号框架，能够同时进行数据驱动的逻辑结构学习和在该结构内的演绎推理，增强了深度学习系统的逻辑一致性和可解释性。

Abstract: We propose Modal Logical Neural Networks (MLNNs), a neurosymbolic framework that integrates deep learning with the formal semantics of modal logic, enabling reasoning about necessity and possibility. Drawing on Kripke semantics, we introduce specialized neurons for the modal operators $\Box$ and $\Diamond$ that operate over a set of possible worlds, enabling the framework to act as a differentiable ``logical guardrail.'' The architecture is highly flexible: the accessibility relation between worlds can either be fixed by the user to enforce known rules or, as an inductive feature, be parameterized by a neural network. This allows the model to optionally learn the relational structure of a logical system from data while simultaneously performing deductive reasoning within that structure.
  This versatile construction is designed for flexibility. The entire framework is differentiable from end to end, with learning driven by minimizing a logical contradiction loss. This not only makes the system resilient to inconsistent knowledge but also enables it to learn nonlinear relationships that can help define the logic of a problem space. We illustrate MLNNs on four case studies: grammatical guardrailing, axiomatic detection of the unknown, multi-agent epistemic trust, and detecting constructive deception in natural language negotiation. These experiments demonstrate how enforcing or learning accessibility can increase logical consistency and interpretability without changing the underlying task architecture.

</details>


### [127] [DVPO: Distributional Value Modeling-based Policy Optimization for LLM Post-Training](https://arxiv.org/abs/2512.03847)
*Dingwei Zhu,Zhiheng Xi,Shihan Dou,Yuhui Wang,Sixian Li,Junjie Ye,Honglin Guo,Shichun Liu,Chenhao Huang,Yajie Yang,Junlin Shang,Senjie Jin,Ming Zhang,Jiazheng Zhang,Caishuang Huang,Yunke Zhang,Demei Yan,Yuran Wang,Tao Gui*

Main category: cs.LG

TL;DR: DVPO是一个新的RL框架，结合条件风险理论和分布价值建模，通过token级价值分布和不对称风险正则化来平衡鲁棒性和泛化性，在噪声监督下优于PPO、GRPO等方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界部署中，LLM后训练常面临噪声或不完整的监督信号，现有方法（如RFQI、CQL、PPO、GRPO）要么忽视泛化性，要么产生过于保守的策略，导致在不同真实场景中性能不稳定。

Method: DVPO结合条件风险理论和分布价值建模，学习token级价值分布以提供细粒度监督，并应用不对称风险正则化来塑造分布尾部：压缩下尾以抑制噪声负偏差，扩展上尾以保持探索多样性。

Result: 在多轮对话、数学推理和科学QA的广泛实验中，DVPO在噪声监督下一致优于PPO、GRPO和基于鲁棒Bellman的PPO，显示出其在现实世界LLM后训练中的潜力。

Conclusion: DVPO通过分布价值建模和风险感知策略优化，有效平衡了鲁棒性和泛化性，为现实世界中噪声监督下的LLM后训练提供了一个有前景的解决方案。

Abstract: Reinforcement learning (RL) has shown strong performance in LLM post-training, but real-world deployment often involves noisy or incomplete supervision. In such settings, complex and unreliable supervision signals can destabilize training and harm generalization. While existing approaches such as worst-case optimization (e.g., RFQI, CQL) and mean-based methods (e.g., PPO, GRPO) can improve stability, they often overlook generalization and may produce overly conservative policies, leading to uneven performance across diverse real scenarios. To this end, we introduce DVPO (Distributional Value Modeling with Risk-aware Policy Optimization), a new RL framework that combines conditional risk theory with distributional value modeling to better balance robustness and generalization. DVPO learns token-level value distributions to provide fine-grained supervision, and applies an asymmetric risk regularization to shape the distribution tails: it contracts the lower tail to dampen noisy negative deviations, while expanding the upper tail to preserve exploratory diversity. Across extensive experiments and analysis in multi-turn dialogue, math reasoning, and scientific QA, DVPO consistently outperforms PPO, GRPO, and robust Bellman-based PPO under noisy supervision, showing its potential for LLM post-training in the real-world.

</details>


### [128] [Scalable Decision Focused Learning via Online Trainable Surrogates](https://arxiv.org/abs/2512.03861)
*Gaetano Signorelli,Michele Lombardi*

Main category: cs.LG

TL;DR: 提出一种基于替代损失的加速方法，用于决策导向学习，减少训练时昂贵的内层求解器调用，同时保持解的质量。


<details>
  <summary>Details</summary>
Motivation: 决策支持系统需要解决复杂的优化问题，传统训练的估计器会导致次优解。决策导向学习虽然能解决这个问题，但训练时计算成本高、可扩展性差。

Method: 提出一种加速方法，用高效的替代损失函数替换昂贵的损失函数评估。该方法使用无偏估计器减少虚假局部最优风险，提供局部置信度信息，支持黑盒设置，并能补偿优化模型简化及考虑补救行动。

Result: 该方法显著减少了昂贵的内层求解器调用次数，同时解决方案质量与其他最先进技术相当。

Conclusion: 提出的替代损失加速方法有效解决了决策导向学习的可扩展性问题，在保持解质量的同时大幅降低计算成本。

Abstract: Decision support systems often rely on solving complex optimization problems that may require to estimate uncertain parameters beforehand. Recent studies have shown how using traditionally trained estimators for this task can lead to suboptimal solutions. Using the actual decision cost as a loss function (called Decision Focused Learning) can address this issue, but with a severe loss of scalability at training time. To address this issue, we propose an acceleration method based on replacing costly loss function evaluations with an efficient surrogate. Unlike previously defined surrogates, our approach relies on unbiased estimators reducing the risk of spurious local optima and can provide information on its local confidence allowing one to switch to a fallback method when needed. Furthermore, the surrogate is designed for a black-box setting, which enables compensating for simplifications in the optimization model and account- ing for recourse actions during cost computation. In our results, the method reduces costly inner solver calls, with a solution quality comparable to other state-of-the-art techniques.

</details>


### [129] [Adaptive sampling using variational autoencoder and reinforcement learning](https://arxiv.org/abs/2512.03525)
*Adil Rasheed,Mikael Aleksander Jansen Shahly,Muhammad Faisal Aftab*

Main category: cs.LG

TL;DR: 提出自适应稀疏感知框架，结合变分自编码器先验和强化学习进行顺序测量选择，优于传统压缩感知、最优传感器布局和生成模型方法


<details>
  <summary>Details</summary>
Motivation: 传统压缩感知使用通用基和随机测量，效率和质量有限；最优传感器布局基于历史数据但使用固定线性基，无法适应非线性或样本特异性变化；生成模型压缩感知虽使用深度生成先验但仍采用次优随机采样

Method: 提出自适应稀疏感知框架，将变分自编码器作为先验模型，结合强化学习来顺序选择测量位置，实现针对特定样本的自适应采样

Result: 实验表明该方法在稀疏测量下的重建性能优于传统压缩感知、最优传感器布局和生成模型压缩感知方法

Conclusion: 通过结合变分自编码器先验和强化学习的自适应测量选择，能够显著提高稀疏感知的重建质量和效率

Abstract: Compressed sensing enables sparse sampling but relies on generic bases and random measurements, limiting efficiency and reconstruction quality. Optimal sensor placement uses historcal data to design tailored sampling patterns, yet its fixed, linear bases cannot adapt to nonlinear or sample-specific variations. Generative model-based compressed sensing improves reconstruction using deep generative priors but still employs suboptimal random sampling. We propose an adaptive sparse sensing framework that couples a variational autoencoder prior with reinforcement learning to select measurements sequentially. Experiments show that this approach outperforms CS, OSP, and Generative model-based reconstruction from sparse measurements.

</details>


### [130] [Hyperdimensional Computing for Sustainable Manufacturing: An Initial Assessment](https://arxiv.org/abs/2512.03864)
*Danny Hoang,Anandkumar Patel,Ruimen Chen,Rajiv Malhotra,Farhad Imani*

Main category: cs.LG

TL;DR: 本研究比较了智能加工中AI模型的能耗、精度和速度，引入超维计算作为替代方案，在保持精度的同时大幅降低能耗和计算时间。


<details>
  <summary>Details</summary>
Motivation: 智能制造能提高效率和降低能耗，但AI模型的高能耗可能抵消这些收益。需要寻找既能保持精度又能大幅降低能耗的AI方法。

Method: 使用原位传感预测智能加工的几何质量，比较常见AI模型的能耗、精度和速度。引入超维计算作为替代方案，并与传统模型进行对比。

Result: 超维计算在精度上与常规模型相当，但训练能耗降低200倍，推理能耗降低175-1000倍。训练时间减少200倍，推理时间减少300-600倍。

Conclusion: 超维计算展示了在保持精度的同时大幅降低能耗和计算时间的潜力，为节能智能制造提供了有前景的解决方案。

Abstract: Smart manufacturing can significantly improve efficiency and reduce energy consumption, yet the energy demands of AI models may offset these gains. This study utilizes in-situ sensing-based prediction of geometric quality in smart machining to compare the energy consumption, accuracy, and speed of common AI models. HyperDimensional Computing (HDC) is introduced as an alternative, achieving accuracy comparable to conventional models while drastically reducing energy consumption, 200$\times$ for training and 175 to 1000$\times$ for inference. Furthermore, HDC reduces training times by 200$\times$ and inference times by 300 to 600$\times$, showcasing its potential for energy-efficient smart manufacturing.

</details>


### [131] [Parameter-Efficient Augment Plugin for Class-Incremental Learning](https://arxiv.org/abs/2512.03537)
*Zhiming Xu,Baile Xu,Jian Zhao,Furao Shen,Suorong Yang*

Main category: cs.LG

TL;DR: 提出DLC方法，通过LoRA插件扩展范式解决类增量学习问题，在ImageNet-100上仅用4%参数实现8%精度提升


<details>
  <summary>Details</summary>
Motivation: 现有类增量学习方法存在遗忘问题或稳定性-可塑性困境，扩展方法虽然精度高但参数增长显著。需要一种高效且参数友好的增量学习方案

Method: 将基于回放或蒸馏训练的特征提取器作为基础模型，为每个任务使用LoRA注入任务特定残差。推理时聚合带任务特定残差的表示，并引入轻量级权重单元分配重要性分数

Result: 在ImageNet-100上，仅用标准ResNet-18的4%参数就实现了8%的精度提升，在固定内存预算下超越现有最优方法

Conclusion: DLC方法提供了一种即插即用的高效扩展范式，显著提升了类增量学习的性能效率比，解决了参数增长与性能提升的平衡问题

Abstract: Existing class-incremental learning (CIL) approaches based on replay or knowledge distillation are often constrained by forgetting or the stability-plasticity dilemma. Some expansion-based approaches could achieve higher accuracy. However, they always require significant parameter increases. In this paper, we propose a plugin extension paradigm termed the Deployment of extra LoRA Components (DLC) for non-pre-trained CIL scenarios.We treat the feature extractor trained through replay or distillation as a base model with rich knowledge. For each task, we use Low-Rank Adaptation (LoRA) to inject task-specific residuals into the base model's deep layers. During inference, representations with task-specific residuals are aggregated to produce classification predictions. To mitigate interference from non-target LoRA plugins, we introduce a lightweight weighting unit. This unit learns to assign importance scores to different LoRA-tuned representations. Like downloadable contents in software, our method serves as a plug-and-play enhancement that efficiently extends the base methods. Remarkably, on the large-scale ImageNet-100, with merely 4 % of the parameters of a standard ResNet-18, our DLC model achieves a significant 8 % improvement in accuracy, demonstrating exceptional efficiency. Moreover, it could surpass state-of-the-art methods under the fixed memory budget.

</details>


### [132] [Towards Irreversible Machine Unlearning for Diffusion Models](https://arxiv.org/abs/2512.03564)
*Xun Yuan,Zilong Zhao,Jiayu Li,Aryan Pasikhani,Prosanta Gope,Biplab Sikdar*

Main category: cs.LG

TL;DR: 本文提出了一种针对扩散模型微调式遗忘学习的新攻击方法DiMRA，以及相应的防御方法DiMUM。DiMRA能够逆转遗忘学习效果，使模型重新生成已遗忘的内容；DiMUM则通过记忆替代数据来防止生成目标内容，提高鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在生成合成图像方面表现出色，但存在安全、隐私和版权问题，需要遗忘学习技术来让模型忘记特定训练数据。然而现有的微调式遗忘学习方法存在安全漏洞，可能被攻击逆转，因此需要更鲁棒的解决方案。

Method: 1. 提出DiMRA攻击：在没有遗忘元素先验知识的情况下，通过在辅助数据集上优化已遗忘的扩散模型，逆转遗忘学习效果，使模型重新生成已遗忘的内容。
2. 提出DiMUM防御：采用记忆替代数据或特征的方法来替换目标遗忘数据或特征，而不是传统的"遗忘"方式，从而防止生成目标内容并提高鲁棒性。

Result: 1. DiMRA成功逆转了最先进的微调式扩散模型遗忘学习方法，暴露了这类技术的重大安全漏洞。
2. DiMUM在保持扩散模型生成性能的同时，显著增强了对抗DiMRA攻击的鲁棒性，表现出优越的性能。

Conclusion: 微调式扩散模型遗忘学习方法存在被逆转攻击的严重漏洞，需要更鲁棒的解决方案。DiMUM通过记忆替代数据的创新方法，既能有效防止生成目标内容，又能抵抗DiMRA攻击，为扩散模型的安全应用提供了更可靠的保护。

Abstract: Diffusion models are renowned for their state-of-the-art performance in generating synthetic images. However, concerns related to safety, privacy, and copyright highlight the need for machine unlearning, which can make diffusion models forget specific training data and prevent the generation of sensitive or unwanted content. Current machine unlearning methods for diffusion models are primarily designed for conditional diffusion models and focus on unlearning specific data classes or features. Among these methods, finetuning-based machine unlearning methods are recognized for their efficiency and effectiveness, which update the parameters of pre-trained diffusion models by minimizing carefully designed loss functions. However, in this paper, we propose a novel attack named Diffusion Model Relearning Attack (DiMRA), which can reverse the finetuning-based machine unlearning methods, posing a significant vulnerability of this kind of technique. Without prior knowledge of the unlearning elements, DiMRA optimizes the unlearned diffusion model on an auxiliary dataset to reverse the unlearning, enabling the model to regenerate previously unlearned elements. To mitigate this vulnerability, we propose a novel machine unlearning method for diffusion models, termed as Diffusion Model Unlearning by Memorization (DiMUM). Unlike traditional methods that focus on forgetting, DiMUM memorizes alternative data or features to replace targeted unlearning data or features in order to prevent generating such elements. In our experiments, we demonstrate the effectiveness of DiMRA in reversing state-of-the-art finetuning-based machine unlearning methods for diffusion models, highlighting the need for more robust solutions. We extensively evaluate DiMUM, demonstrating its superior ability to preserve the generative performance of diffusion models while enhancing robustness against DiMRA.

</details>


### [133] [Guided Flow Policy: Learning from High-Value Actions in Offline Reinforcement Learning](https://arxiv.org/abs/2512.03973)
*Franki Nguimatsia Tiofack,Théotime Le Hellard,Fabian Schramm,Nicolas Perrin-Gilbert,Justin Carpentier*

Main category: cs.LG

TL;DR: GFP通过结合多步流匹配策略和蒸馏单步演员，使用加权行为克隆来专注于克隆数据集中的高价值动作，而非盲目模仿所有状态-动作对，在离线强化学习中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习中，传统的行为正则化方法通常不加区分地让策略保持接近数据集分布，无法区分高价值和低价值动作，这限制了性能提升。

Method: 提出引导流策略(GFP)，将多步流匹配策略与蒸馏的单步演员相结合。演员通过加权行为克隆指导流策略专注于克隆数据集中的高价值动作，而流策略则约束演员保持与数据集最佳转移的对齐同时最大化批评者价值。

Result: 在OGBench、Minari和D4RL基准测试的144个状态和像素任务中实现了最先进的性能，特别是在次优数据集和挑战性任务上取得了显著提升。

Conclusion: GFP通过流策略和演员之间的相互引导机制，有效区分并专注于数据集中的高价值动作，解决了传统行为正则化方法的局限性，在离线强化学习中取得了突破性进展。

Abstract: Offline reinforcement learning often relies on behavior regularization that enforces policies to remain close to the dataset distribution. However, such approaches fail to distinguish between high-value and low-value actions in their regularization components. We introduce Guided Flow Policy (GFP), which couples a multi-step flow-matching policy with a distilled one-step actor. The actor directs the flow policy through weighted behavior cloning to focus on cloning high-value actions from the dataset rather than indiscriminately imitating all state-action pairs. In turn, the flow policy constrains the actor to remain aligned with the dataset's best transitions while maximizing the critic. This mutual guidance enables GFP to achieve state-of-the-art performance across 144 state and pixel-based tasks from the OGBench, Minari, and D4RL benchmarks, with substantial gains on suboptimal datasets and challenging tasks. Webpage: https://simple-robotics.github.io/publications/guided-flow-policy/

</details>


### [134] [Optimal Transportation and Alignment Between Gaussian Measures](https://arxiv.org/abs/2512.03579)
*Sanjit Dandapanthula,Aleksandr Podkopaev,Shiva Prasad Kasiviswanathan,Aaditya Ramdas,Ziv Goldfeld*

Main category: cs.LG

TL;DR: 本文为高斯分布下的最优传输和Gromov-Wasserstein对齐提供了完整的理论框架和闭式解，解决了文献中的多个开放问题，并在知识蒸馏和异构聚类中展示了应用价值。


<details>
  <summary>Details</summary>
Motivation: 最优传输和Gromov-Wasserstein对齐是数据科学中比较、转换和聚合异构数据集的重要几何框架，但由于计算成本高，大规模应用通常依赖于高斯分布在二次成本下的闭式解。本文旨在填补文献中的空白，扩展这些框架的适用性。

Method: 1. 针对可分离希尔伯特空间中未中心化高斯分布的内积GW对齐，给出了闭式表达式（需通过酉算子进行二次优化），并推导了紧致的解析上下界；2. 当至少一个高斯分布中心化时，提供完全闭式解；3. 为中心化高斯分布提供IGW重心解析解；4. 将具有成对二次成本的高斯多边际OT简化为可处理的优化问题，并提出使用秩缺陷约束的高效算法。

Result: 1. 解决了未中心化高斯分布IGW对齐的开放问题；2. 为中心化情况提供了完全闭式解和重心解析解；3. 实现了高斯多边际OT的高效计算；4. 在合成和真实数据集上的知识蒸馏和异构聚类应用中展示了方法的实用性。

Conclusion: 本文为高斯分布下的最优传输和Gromov-Wasserstein对齐提供了全面的理论框架，填补了文献中的关键空白，扩展了这些几何方法的适用性，并在实际应用中展示了其价值。

Abstract: Optimal transport (OT) and Gromov-Wasserstein (GW) alignment provide interpretable geometric frameworks for comparing, transforming, and aggregating heterogeneous datasets -- tasks ubiquitous in data science and machine learning. Because these frameworks are computationally expensive, large-scale applications often rely on closed-form solutions for Gaussian distributions under quadratic cost. This work provides a comprehensive treatment of Gaussian, quadratic cost OT and inner product GW (IGW) alignment, closing several gaps in the literature to broaden applicability. First, we treat the open problem of IGW alignment between uncentered Gaussians on separable Hilbert spaces by giving a closed-form expression up to a quadratic optimization over unitary operators, for which we derive tight analytic upper and lower bounds. If at least one Gaussian measure is centered, the solution reduces to a fully closed-form expression, which we further extend to an analytic solution for the IGW barycenter between centered Gaussians. We also present a reduction of Gaussian multimarginal OT with pairwise quadratic costs to a tractable optimization problem and provide an efficient algorithm to solve it using a rank-deficiency constraint. To demonstrate utility, we apply our results to knowledge distillation and heterogeneous clustering on synthetic and real-world datasets.

</details>


### [135] [MarkTune: Improving the Quality-Detectability Trade-off in Open-Weight LLM Watermarking](https://arxiv.org/abs/2512.04044)
*Yizhou Zhao,Zhiwei Steven Wu,Adam Block*

Main category: cs.LG

TL;DR: MarkTune是一种针对开源权重语言模型的水印方法，通过基于策略的微调框架，在保持文本质量的同时嵌入可检测的水印信号，显著改善了质量-可检测性权衡。


<details>
  <summary>Details</summary>
Motivation: 开源权重语言模型对水印技术提出了严峻挑战，因为一旦模型权重公开，就无法强制执行推理时干预。现有的开源模型水印技术（如GaussMark）通常需要修改模型权重，但要达到与推理时水印相当的检测能力，往往需要明显降低生成质量的权重扰动。

Method: MarkTune是一个理论上有原则的、基于策略的微调框架，将GaussMark信号作为奖励，同时通过正则化防止文本质量下降。该方法在模型的表示空间中进行更细粒度、水印感知的权重更新，同时保持生成质量。

Result: MarkTune将GaussMark的质量-可检测性边界推近到接近推理时水印的水平，对改写和微调攻击保持鲁棒性，并表现出很强的泛化能力：在一个数据集上微调的模型在未见数据集上仍保持显著的水印检测能力。

Conclusion: MarkTune作为一种通用策略，能够在开源权重语言模型中嵌入鲁棒、高质量的水印，解决了开源模型水印的关键挑战。

Abstract: Watermarking aims to embed hidden signals in generated text that can be reliably detected when given access to a secret key. Open-weight language models pose acute challenges for such watermarking schemes because the inference-time interventions that dominate contemporary approaches cannot be enforced once model weights are public. Existing watermaking techniques for open-weight models, such as the recently proposed GaussMark, typically rely on small modifications to model weights, which can yield signals detectable to those equipped with a secret key, but achieving detection power comparable to inference-time watermarks generally requires weight perturbations that noticeably reduce generation quality. We introduce MarkTune, a theoretically principled, on-policy fine-tuning framework that treats the GaussMark signal as a reward while simultaneously regularizing against degradation in text quality. We derive MarkTune as an improvement on GaussMark and demonstrate that MarkTune consistently improves the quality-detectability trade-off over GaussMark by steering finer-grained, watermark-aware weight updates within the model's representation space while preserving generation quality. Empirically, we show that MarkTune pushes the quality-detectability frontier of GaussMark close to that of inference-time watermarking, remains robust to paraphrasing and fine-tuning attacks, and exhibits strong generalization: a model fine-tuned on one dataset retains substantial watermark detection power on unseen datasets. Together, these results establish MarkTune as a general strategy for embedding robust, high-quality watermarks into open-weight LMs.

</details>


### [136] [Federated Learning and Trajectory Compression for Enhanced AIS Coverage](https://arxiv.org/abs/2512.03584)
*Thomas Gräupl,Andreas Reisenbauer,Marcel Hecko,Anil Rasouli,Anita Graser,Melitta Dragaschnig,Axel Weissenfeld,Gilles Dejaegere,Mahmoud Sakr*

Main category: cs.LG

TL;DR: VesselEdge系统利用联邦学习和带宽受限轨迹压缩技术，将船舶转变为移动传感器，通过扩展AIS覆盖范围来增强海上态势感知能力。


<details>
  <summary>Details</summary>
Motivation: 当前海上态势感知面临AIS覆盖范围有限、数据传输带宽受限的挑战，需要一种能够实时检测异常并高效传输数据的解决方案。

Method: 系统结合了M3fed联邦学习模型和BWC-DR-A轨迹压缩算法，将船舶作为移动传感器，优先传输异常数据，在低带宽连接下实现高效数据传输。

Result: 初步结果显示VesselEdge系统能有效提高AIS覆盖范围和海上态势感知能力，使用历史数据验证了其有效性。

Conclusion: VesselEdge系统通过联邦学习和轨迹压缩技术，为海上态势感知提供了一种创新的解决方案，能够扩展AIS覆盖并实现实时异常检测。

Abstract: This paper presents the VesselEdge system, which leverages federated learning and bandwidth-constrained trajectory compression to enhance maritime situational awareness by extending AIS coverage. VesselEdge transforms vessels into mobile sensors, enabling real-time anomaly detection and efficient data transmission over low-bandwidth connections. The system integrates the M3fed model for federated learning and the BWC-DR-A algorithm for trajectory compression, prioritizing anomalous data. Preliminary results demonstrate the effectiveness of VesselEdge in improving AIS coverage and situational awareness using historical data.

</details>


### [137] [Observation-driven correction of numerical weather prediction for marine winds](https://arxiv.org/abs/2512.03606)
*Matteo Peduto,Qidong Yang,Jonathan Giezendanner,Devis Tuia,Sherrie Wang*

Main category: cs.LG

TL;DR: 提出基于Transformer的深度学习架构，通过同化最新观测数据来校正全球天气预报系统(GFS)的风场输出，实现海洋风场预报的改进


<details>
  <summary>Details</summary>
Motivation: 海洋风场预报对航行安全和能源运营至关重要，但由于海洋观测数据稀疏、异质且时间变化大，准确预报具有挑战性。现有数值天气预报模型存在系统性误差需要校正

Method: 采用Transformer架构，通过掩码和基于集合的注意力机制处理不规则观测数据，使用交叉注意力将预测与最近观测-预报对关联，采用循环时间嵌入和坐标感知位置表示实现单次推理

Result: 在大西洋区域使用ICOADS观测数据评估，模型在所有48小时预报时效内均降低GFS 10米风场RMSE，1小时时效改进45%，48小时时效改进13%，沿海和航线区域改进最显著

Conclusion: 该研究展示了一种实用的低延迟后处理方法，通过校正系统性预报误差来补充数值天气预报，能够处理多种观测平台数据并同时生成站点预测和区域网格产品

Abstract: Accurate marine wind forecasts are essential for safe navigation, ship routing, and energy operations, yet they remain challenging because observations over the ocean are sparse, heterogeneous, and temporally variable. We reformulate wind forecasting as observation-informed correction of a global numerical weather prediction (NWP) model. Rather than forecasting winds directly, we learn local correction patterns by assimilating the latest in-situ observations to adjust the Global Forecast System (GFS) output. We propose a transformer-based deep learning architecture that (i) handles irregular and time-varying observation sets through masking and set-based attention mechanisms, (ii) conditions predictions on recent observation-forecast pairs via cross-attention, and (iii) employs cyclical time embeddings and coordinate-aware location representations to enable single-pass inference at arbitrary spatial coordinates. We evaluate our model over the Atlantic Ocean using observations from the International Comprehensive Ocean-Atmosphere Data Set (ICOADS) as reference. The model reduces GFS 10-meter wind RMSE at all lead times up to 48 hours, achieving 45% improvement at 1-hour lead time and 13% improvement at 48-hour lead time. Spatial analyses reveal the most persistent improvements along coastlines and shipping routes, where observations are most abundant. The tokenized architecture naturally accommodates heterogeneous observing platforms (ships, buoys, tide gauges, and coastal stations) and produces both site-specific predictions and basin-scale gridded products in a single forward pass. These results demonstrate a practical, low-latency post-processing approach that complements NWP by learning to correct systematic forecast errors.

</details>


### [138] [Fare Comparison App of Uber, Ola and Rapido](https://arxiv.org/abs/2512.04065)
*Ashlesha Gopinath Sawant,Sahil S. Jadhav,Vidhan R. Jain,Shriraj S. Jagtap,Prachi Jadhav,Soham Jadhav,Ichha Raina*

Main category: cs.LG

TL;DR: 开发了一个网约车比价网站，通过API获取Ola、Uber、Rapido的实时价格，为用户提供最优选择，解决出行成本和时间效率问题。


<details>
  <summary>Details</summary>
Motivation: 用户在日常出行中选择网约车服务时面临困难，难以找到既经济又高效的出行方案。当前缺乏透明化的比价工具，用户无法轻松比较不同平台的价格和服务。

Method: 开发了一个Web应用程序，使用Python后端通过API获取Ola、Uber、Rapido的实时票价数据，进行价格比较分析，并利用Android Studio模拟器、Appium和位置比较技术解决数据访问的技术挑战。

Result: 成功创建了一个功能完整的比价平台，能够为用户提供不同网约车服务的实时价格对比，并推荐最优出行选择，提高了出行决策的透明度和效率。

Conclusion: 该项目通过技术手段解决了网约车比价难题，为用户提供了透明化的出行决策工具，提升了用户体验和出行效率，具有实际应用价值。

Abstract: In todays increasing world, it is very important to have good hailing services like Ola, Uber, and Rapido as it is very essential for our daily transportation. Users often face difficulties in choosing the most appropriate and efficient ride that would lead to both cost-effective and would take us to our destination in less time. This project provides you with the web application that helps you to select the most beneficial ride for you by providing users with the fare comparison between Ola, Uber, Rapido for the destination entered by the user. The backend is use to fetch the data, providing users with the fare comparison for the ride and finally providing with the best option using Python. This research paper also addresses the problem and challenges faced in accessing the data using APIs, Android Studios emulator, Appium and location comparison. Thus, the aim of the project is to provide transparency to the users in ride-hailing services and increase efficiency and provide users with better experience.

</details>


### [139] [CoGraM: Context-sensitive granular optimization method with rollback for robust model fusion](https://arxiv.org/abs/2512.03610)
*Julius Lenz*

Main category: cs.LG

TL;DR: CoGraM是一种多阶段、上下文敏感、基于损失的迭代优化方法，用于合并神经网络而无需重新训练，解决了权重平均和Fisher合并等方法精度损失和不稳定的问题。


<details>
  <summary>Details</summary>
Motivation: 联邦学习和分布式学习中需要在不重新训练的情况下合并神经网络，但现有方法如权重平均或Fisher合并经常导致精度损失且在不同种子下不稳定。

Method: CoGraM是一种多阶段、上下文敏感、基于损失的迭代优化方法，通过跨层、神经元和权重级别的优化，对齐决策与损失差异和阈值，并通过回滚防止有害更新。

Result: CoGraM能够显著改善合并后的网络性能，解决了Fisher等方法的弱点。

Conclusion: CoGraM为联邦学习和分布式学习中的神经网络合并问题提供了一个有效的优化解决方案，能够在不重新训练的情况下获得更好的合并结果。

Abstract: Merging neural networks without retraining is central to federated and distributed learning. Common methods such as weight averaging or Fisher merging often lose accuracy and are unstable across seeds. CoGraM (Contextual Granular Merging) is a multi-stage, context-sensitive, loss-based, and iterative optimization method across layers, neurons, and weight levels that aligns decisions with loss differences and thresholds and prevents harmful updates through rollback. CoGraM is an optimization method that addresses the weaknesses of methods such as Fisher and can significantly improve the merged network.

</details>


### [140] [Conditional updates of neural network weights for increased out of training performance](https://arxiv.org/abs/2512.03653)
*Jan Saynisch-Wagner,Saran Rajendran Sari*

Main category: cs.LG

TL;DR: 提出一种增强神经网络在训练数据与应用数据不相似（如分布外问题、模式/机制转移）时性能的方法，通过重训练获取权重异常、建立预测因子回归、外推权重到应用数据，在气候科学三个用例中验证了时空和跨域外推的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决神经网络在训练数据与应用数据不相似时的性能下降问题，特别是针对分布外问题、模式转移和机制转移等实际应用场景，提高神经网络在实际应用中的泛化能力。

Method: 三步骤方法：1) 对训练数据集的合理子集进行重训练，记录权重异常；2) 选择合理预测因子，建立预测因子与权重异常之间的回归关系；3) 将权重外推到应用数据，从而外推神经网络本身。

Result: 在气候科学的三个用例中成功展示了该方法，实现了神经网络在时间、空间和跨域的外推，证明了该方法在分布外问题上的有效性。

Conclusion: 该方法能够有效增强神经网络在训练数据与应用数据不相似情况下的性能，为处理分布外问题、模式转移和机制转移提供了可行的解决方案，在气候科学等多个领域具有应用潜力。

Abstract: This study proposes a method to enhance neural network performance when training data and application data are not very similar, e.g., out of distribution problems, as well as pattern and regime shifts. The method consists of three main steps: 1) Retrain the neural network towards reasonable subsets of the training data set and note down the resulting weight anomalies. 2) Choose reasonable predictors and derive a regression between the predictors and the weight anomalies. 3) Extrapolate the weights, and thereby the neural network, to the application data. We show and discuss this method in three use cases from the climate sciences, which include successful temporal, spatial and cross-domain extrapolations of neural networks.

</details>


### [141] [Cyclical Temporal Encoding and Hybrid Deep Ensembles for Multistep Energy Forecasting](https://arxiv.org/abs/2512.03656)
*Salim Khazem,Houssam Kanso*

Main category: cs.LG

TL;DR: 提出一个结合循环时间编码与LSTM-CNN混合架构的统一深度学习框架，用于提升多步能源预测精度


<details>
  <summary>Details</summary>
Motivation: 准确的电力消费预测对需求管理和智能电网运营至关重要，需要有效处理周期性时间模式和长短期依赖关系

Method: 使用正弦余弦编码处理日历属性以保留周期结构，采用LSTM-CNN-MLP集成模型分别处理长期季节效应和短期局部模式，为每个预测时域专门训练元学习器

Result: 在一年全国消费数据集上，所有七个预测时域均取得一致改进，混合模型在RMSE和MAE指标上优于单个架构和现有方法

Conclusion: 循环时间表示与互补深度学习结构的结合具有显著优势，这是首个在统一短期能源预测框架中联合评估时间编码、日历特征和混合集成架构的工作

Abstract: Accurate electricity consumption forecasting is essential for demand management and smart grid operations. This paper introduces a unified deep learning framework that integrates cyclical temporal encoding with hybrid LSTM-CNN architectures to enhance multistep energy forecasting. We systematically transform calendar-based attributes using sine cosine encodings to preserve periodic structure and evaluate their predictive relevance through correlation analysis. To exploit both long-term seasonal effects and short-term local patterns, we employ an ensemble model composed of an LSTM, a CNN, and a meta-learner of MLP regressors specialized for each forecast horizon. Using a one year national consumption dataset, we conduct an extensive experimental study including ablation analyses with and without cyclical encodings and calendar features and comparisons with established baselines from the literature. Results demonstrate consistent improvements across all seven forecast horizons, with our hybrid model achieving lower RMSE and MAE than individual architectures and prior methods. These findings confirm the benefit of combining cyclical temporal representations with complementary deep learning structures. To our knowledge, this is the first work to jointly evaluate temporal encodings, calendar-based features, and hybrid ensemble architectures within a unified short-term energy forecasting framework.

</details>


### [142] [Feature-aware Modulation for Learning from Temporal Tabular Data](https://arxiv.org/abs/2512.03678)
*Hao-Run Cai,Han-Jia Ye*

Main category: cs.LG

TL;DR: 本文提出了一种特征感知的时间调制机制，通过调整特征的统计属性（如尺度和偏度）来对齐跨时间阶段的特征语义，从而在表格数据中平衡泛化性和适应性。


<details>
  <summary>Details</summary>
Motivation: 表格机器学习在现实部署中面临时间分布偏移的挑战，静态模型假设固定映射以确保泛化，而自适应模型可能过度拟合瞬态模式，导致鲁棒性与适应性之间的困境。

Method: 提出特征感知的时间调制机制，该机制基于时间上下文条件化特征表示，调制统计属性（如尺度和偏度），通过特征转换策略缓解跨时间阶段的特征表示差异。

Result: 基准评估验证了该方法在处理表格数据时间偏移方面的有效性，实现了轻量级但强大的适应能力。

Conclusion: 通过分析特征语义演变（特别是客观和主观意义）引入的概念漂移，发现特征转换策略能够缓解跨时间阶段的特征表示差异，提出的特征感知时间调制机制有效平衡了泛化性和适应性。

Abstract: While tabular machine learning has achieved remarkable success, temporal distribution shifts pose significant challenges in real-world deployment, as the relationships between features and labels continuously evolve. Static models assume fixed mappings to ensure generalization, whereas adaptive models may overfit to transient patterns, creating a dilemma between robustness and adaptability. In this paper, we analyze key factors essential for constructing an effective dynamic mapping for temporal tabular data. We discover that evolving feature semantics-particularly objective and subjective meanings-introduce concept drift over time. Crucially, we identify that feature transformation strategies are able to mitigate discrepancies in feature representations across temporal stages. Motivated by these insights, we propose a feature-aware temporal modulation mechanism that conditions feature representations on temporal context, modulating statistical properties such as scale and skewness. By aligning feature semantics across time, our approach achieves a lightweight yet powerful adaptation, effectively balancing generalizability and adaptability. Benchmark evaluations validate the effectiveness of our method in handling temporal shifts in tabular data.

</details>


### [143] [Unlocking the Invisible Urban Traffic Dynamics under Extreme Weather: A New Physics-Constrained Hamiltonian Learning Algorithm](https://arxiv.org/abs/2512.03744)
*Xuhui Lin,Qiuchen Lu*

Main category: cs.LG

TL;DR: 提出一种物理约束的哈密顿学习算法，通过结构不可逆性检测和能量景观重构来区分城市交通系统的真实恢复与虚假恢复，识别传统指标遗漏的隐藏结构损伤。


<details>
  <summary>Details</summary>
Motivation: 当前城市交通系统韧性评估方法依赖表面恢复指标，无法检测隐藏的结构损伤，不能区分真实恢复与"虚假恢复"（交通指标正常化但系统动力学永久退化）。

Method: 开发物理约束的哈密顿学习算法，结合结构不可逆性检测和能量景观重构：提取低维状态表示，通过物理约束优化识别准哈密顿结构，通过能量景观比较量化结构变化。

Result: 分析伦敦2021年极端降雨事件显示，虽然表面指标完全恢复，但算法检测到64.8%的传统监测遗漏的结构损伤，证明了虚假恢复现象的存在。

Conclusion: 该框架为主动结构风险评估提供工具，使基础设施投资能够基于真实系统健康而非误导性的表面指标，提高城市交通系统的韧性管理能力。

Abstract: Urban transportation systems face increasing resilience challenges from extreme weather events, but current assessment methods rely on surface-level recovery indicators that miss hidden structural damage. Existing approaches cannot distinguish between true recovery and "false recovery," where traffic metrics normalize, but the underlying system dynamics permanently degrade. To address this, a new physics-constrained Hamiltonian learning algorithm combining "structural irreversibility detection" and "energy landscape reconstruction" has been developed. Our approach extracts low-dimensional state representations, identifies quasi-Hamiltonian structures through physics-constrained optimization, and quantifies structural changes via energy landscape comparison. Analysis of London's extreme rainfall in 2021 demonstrates that while surface indicators were fully recovered, our algorithm detected 64.8\% structural damage missed by traditional monitoring. Our framework provides tools for proactive structural risk assessment, enabling infrastructure investments based on true system health rather than misleading surface metrics.

</details>


### [144] [Universally Converging Representations of Matter Across Scientific Foundation Models](https://arxiv.org/abs/2512.03750)
*Sathya Edamadaka,Soojung Yang,Ju Li,Rafael Gómez-Bombarelli*

Main category: cs.LG

TL;DR: 研究发现不同模态的60多个科学模型在化学系统上具有高度对齐的内部表示，表明它们学习到了物理现实的共同底层表示，但模型仍受限于训练数据和归纳偏置，未能实现真正通用的表示。


<details>
  <summary>Details</summary>
Motivation: 研究不同模态和架构的机器学习模型是否学习到相似的内部物质表示，这对于构建能够可靠泛化到训练域之外的科学基础模型至关重要。虽然语言和视觉领域已观察到表示收敛现象，但在科学领域尚未系统探索。

Method: 分析了近60个科学模型的表示对齐情况，涵盖字符串、图、3D原子结构和蛋白质等多种模态。研究了在不同化学系统上训练的模型表示相似性，以及机器学习原子间势能在性能提升过程中的表示收敛情况。

Result: 发现不同数据集训练的模型在小分子上具有高度相似的表示；原子间势能模型随着性能提升在表示空间中收敛；识别出两种不同的模型状态：在类似训练数据的输入上，高性能模型高度对齐而弱模型在表示空间中发散到局部最优；在完全不同结构的输入上，几乎所有模型都坍缩到低信息表示。

Conclusion: 表示对齐可作为科学模型基础级通用性的定量基准。当前模型仍受限于训练数据和归纳偏置，未能编码真正通用的结构。该工作可用于追踪随着模型规模扩大而出现的通用物质表示，以及选择在模态、物质领域和科学任务间转移性最好的模型。

Abstract: Machine learning models of vastly different modalities and architectures are being trained to predict the behavior of molecules, materials, and proteins. However, it remains unclear whether they learn similar internal representations of matter. Understanding their latent structure is essential for building scientific foundation models that generalize reliably beyond their training domains. Although representational convergence has been observed in language and vision, its counterpart in the sciences has not been systematically explored. Here, we show that representations learned by nearly sixty scientific models, spanning string-, graph-, 3D atomistic, and protein-based modalities, are highly aligned across a wide range of chemical systems. Models trained on different datasets have highly similar representations of small molecules, and machine learning interatomic potentials converge in representation space as they improve in performance, suggesting that foundation models learn a common underlying representation of physical reality. We then show two distinct regimes of scientific models: on inputs similar to those seen during training, high-performing models align closely and weak models diverge into local sub-optima in representation space; on vastly different structures from those seen during training, nearly all models collapse onto a low-information representation, indicating that today's models remain limited by training data and inductive bias and do not yet encode truly universal structure. Our findings establish representational alignment as a quantitative benchmark for foundation-level generality in scientific models. More broadly, our work can track the emergence of universal representations of matter as models scale, and for selecting and distilling models whose learned representations transfer best across modalities, domains of matter, and scientific tasks.

</details>


### [145] [Origin-Conditional Trajectory Encoding: Measuring Urban Configurational Asymmetries through Neural Decomposition](https://arxiv.org/abs/2512.03755)
*Stephen Law,Tao Yang,Nanjiang Chen,Xuhui Lin*

Main category: cs.LG

TL;DR: 提出条件轨迹编码器，联合学习空间和运动表示，利用几何特征保持起点依赖的不对称性，量化城市形态造成的认知不平等


<details>
  <summary>Details</summary>
Motivation: 当前城市轨迹分析方法存在碎片化：轨迹学习忽略空间上下文，空间嵌入方法忽略时间动态。存在三个主要问题：缺乏空间和时间表示的联合训练、忽略导航中的方向不对称性（A→B≠B→A）、过度依赖辅助数据而非城市空间的基本几何特性

Method: 引入条件轨迹编码器，使用双向LSTM处理可见性比率和曲率等几何特征，通过可学习的起点嵌入进行条件化，将表示分解为共享的城市模式和起点特定特征，通过对比学习实现

Result: 在六个合成城市和北京西城区的真实数据验证表明，城市形态会产生系统性的认知不平等，为城市规划和导航系统提供定量工具

Conclusion: 该框架为城市规划者提供评估体验公平性的定量工具，为建筑师提供布局决策的认知影响洞察，并为导航系统实现起点感知分析

Abstract: Urban analytics increasingly relies on AI-driven trajectory analysis, yet current approaches suffer from methodological fragmentation: trajectory learning captures movement patterns but ignores spatial context, while spatial embedding methods encode street networks but miss temporal dynamics. Three gaps persist: (1) lack of joint training that integrates spatial and temporal representations, (2) origin-agnostic treatment that ignores directional asymmetries in navigation ($A \to B \ne B \to A$), and (3) over-reliance on auxiliary data (POIs, imagery) rather than fundamental geometric properties of urban space. We introduce a conditional trajectory encoder that jointly learns spatial and movement representations while preserving origin-dependent asymmetries using geometric features. This framework decomposes urban navigation into shared cognitive patterns and origin-specific spatial narratives, enabling quantitative measurement of cognitive asymmetries across starting locations. Our bidirectional LSTM processes visibility ratio and curvature features conditioned on learnable origin embeddings, decomposing representations into shared urban patterns and origin-specific signatures through contrastive learning. Results from six synthetic cities and real-world validation on Beijing's Xicheng District demonstrate that urban morphology creates systematic cognitive inequalities. This provides urban planners quantitative tools for assessing experiential equity, offers architects insights into layout decisions' cognitive impacts, and enables origin-aware analytics for navigation systems.

</details>


### [146] [Deep Unfolding: Recent Developments, Theory, and Design Guidelines](https://arxiv.org/abs/2512.03768)
*Nir Shlezinger,Santiago Segarra,Yi Zhang,Dvir Avrahami,Zohar Davidov,Tirza Routtenberg,Yonina C. Eldar*

Main category: cs.LG

TL;DR: 深度展开是一种将迭代优化算法转化为结构化可训练机器学习架构的框架，旨在结合传统优化的理论保证与机器学习的数据驱动能力


<details>
  <summary>Details</summary>
Motivation: 传统优化方法虽然具有可解释性和理论保证，但通常需要代理目标函数、仔细的超参数调优且计算延迟大；而机器学习虽然提供强大的数据驱动建模能力，但缺乏优化驱动推理所需的结构、透明度和效率。深度展开旨在桥接这两个范式

Method: 通过系统地将迭代优化算法转化为结构化、可训练的机器学习架构，提供四种代表性的深度展开设计范式，并讨论其特有的训练方案

Result: 建立了展开优化器的收敛性和泛化保证的理论进展，提供了比较定性和实证研究，展示了其在复杂性、可解释性和鲁棒性方面的相对权衡

Conclusion: 深度展开作为一个有前景的框架，成功地将传统优化的理论优势与机器学习的数据驱动能力相结合，为信号处理中的优化问题提供了新的解决方案

Abstract: Optimization methods play a central role in signal processing, serving as the mathematical foundation for inference, estimation, and control. While classical iterative optimization algorithms provide interpretability and theoretical guarantees, they often rely on surrogate objectives, require careful hyperparameter tuning, and exhibit substantial computational latency. Conversely, machine learning (ML ) offers powerful data-driven modeling capabilities but lacks the structure, transparency, and efficiency needed for optimization-driven inference. Deep unfolding has recently emerged as a compelling framework that bridges these two paradigms by systematically transforming iterative optimization algorithms into structured, trainable ML architectures. This article provides a tutorial-style overview of deep unfolding, presenting a unified perspective of methodologies for converting optimization solvers into ML models and highlighting their conceptual, theoretical, and practical implications. We review the foundations of optimization for inference and for learning, introduce four representative design paradigms for deep unfolding, and discuss the distinctive training schemes that arise from their iterative nature. Furthermore, we survey recent theoretical advances that establish convergence and generalization guarantees for unfolded optimizers, and provide comparative qualitative and empirical studies illustrating their relative trade-offs in complexity, interpretability, and robustness.

</details>


### [147] [Forensic Activity Classification Using Digital Traces from iPhones: A Machine Learning-based Approach](https://arxiv.org/abs/2512.03786)
*Conor McCarthy,Jan Peter van Zandwijk,Marcel Worring,Zeno Geradts*

Main category: cs.LG

TL;DR: 该研究提出了一种基于机器学习的方法，将智能手机运动传感器数据转换为不同身体活动类型的似然比，用于法医调查中的活动识别。


<details>
  <summary>Details</summary>
Motivation: 智能手机和智能手表在日常生活中的普及提供了丰富的用户行为信息。特别是手机内置运动传感器产生的数字痕迹，为法医调查人员了解个人身体活动提供了机会。

Method: 开发基于机器学习的方法，将数字痕迹转换为不同身体活动类型的似然比。使用新的数据集NFI_FARED进行评估，该数据集包含来自四种不同iPhone型号的数字痕迹，标注了19种活动类型。方法还可扩展到同时分析多个活动（或活动组）并创建活动时间线。

Result: 在171种可能的成对活动组合中，该方法能够为167种组合产生有用的似然比系统。数据集和所有代码已公开，以促进该领域的进一步研究。

Conclusion: 该方法能够有效利用智能手机运动传感器数据进行法医调查中的活动识别，为调查的早期和后期阶段提供支持。公开数据集和代码有助于推动该研究领域的发展。

Abstract: Smartphones and smartwatches are ever-present in daily life, and provide a rich source of information on their users' behaviour. In particular, digital traces derived from the phone's embedded movement sensors present an opportunity for a forensic investigator to gain insight into a person's physical activities. In this work, we present a machine learning-based approach to translate digital traces into likelihood ratios (LRs) for different types of physical activities. Evaluating on a new dataset, NFI\_FARED, which contains digital traces from four different types of iPhones labelled with 19 activities, it was found that our approach could produce useful LR systems to distinguish 167 out of a possible 171 activity pairings. The same approach was extended to analyse likelihoods for multiple activities (or groups of activities) simultaneously and create activity timelines to aid in both the early and latter stages of forensic investigations. The dataset and all code required to replicate the results have also been made public to encourage further research on this topic.

</details>


### [148] [Adaptive Identification and Modeling of Clinical Pathways with Process Mining](https://arxiv.org/abs/2512.03787)
*Francesco Vitale,Nicola Mazzocca*

Main category: cs.LG

TL;DR: 提出基于过程挖掘的两阶段临床路径建模方法，通过一致性检查扩展临床路径知识库


<details>
  <summary>Details</summary>
Motivation: 临床路径的手动建模困难且难以反映实际最佳实践，需要自动化的方法来适应不同疾病变异和组合

Method: 两阶段建模方法：第一阶段收集历史数据构建参考过程模型；第二阶段通过一致性检查验证新数据，基于结果扩展知识库

Result: 在SARS-CoV-2感染模拟数据集上验证，方法能以95.62%的AUC精度扩展临床路径知识库，同时保持67.11%的弧度简单性

Conclusion: 提出的过程挖掘方法能够有效扩展临床路径知识库，为不同疾病变异和组合提供更精确的治疗路径模型

Abstract: Clinical pathways are specialized healthcare plans that model patient treatment procedures. They are developed to provide criteria-based progression and standardize patient treatment, thereby improving care, reducing resource use, and accelerating patient recovery. However, manual modeling of these pathways based on clinical guidelines and domain expertise is difficult and may not reflect the actual best practices for different variations or combinations of diseases. We propose a two-phase modeling method using process mining, which extends the knowledge base of clinical pathways by leveraging conformance checking diagnostics. In the first phase, historical data of a given disease is collected to capture treatment in the form of a process model. In the second phase, new data is compared against the reference model to verify conformance. Based on the conformance checking results, the knowledge base can be expanded with more specific models tailored to new variants or disease combinations. We demonstrate our approach using Synthea, a benchmark dataset simulating patient treatments for SARS-CoV-2 infections with varying COVID-19 complications. The results show that our method enables expanding the knowledge base of clinical pathways with sufficient precision, peaking to 95.62% AUC while maintaining an arc-degree simplicity of 67.11%.

</details>


### [149] [EfficientECG: Cross-Attention with Feature Fusion for Efficient Electrocardiogram Classification](https://arxiv.org/abs/2512.03804)
*Hanhui Deng,Xinglin Li,Jie Luo,Zhanpeng Jin,Di Wu*

Main category: cs.LG

TL;DR: 基于EfficientNet设计轻量级ECG分类模型EfficientECG，并提出跨注意力特征融合模型处理多导联ECG数据，实现高精度、多特征融合的ECG分析。


<details>
  <summary>Details</summary>
Motivation: 心电图（ECG）是一种快速、无创且信息丰富的诊断信号，但现有ECG模型误诊率高，医疗工作者负担重。需要开发能自动提取特征、准确快速诊断的深度学习模型。

Method: 1. 基于EfficientNet设计EfficientECG，处理高频长序列多导联ECG数据；2. 提出跨注意力特征融合模型，整合多导联ECG数据与多特征（如性别、年龄）。

Result: 在代表性ECG数据集上的评估验证了模型在精度、多特征融合和轻量化方面优于现有最先进方法。

Conclusion: 提出的深度学习方法能有效管理分析ECG数据，构建准确快速的诊断模型，显著减轻医疗工作者负担，为ECG分析提供了高精度、多特征融合的轻量级解决方案。

Abstract: Electrocardiogram is a useful diagnostic signal that can detect cardiac abnormalities by measuring the electrical activity generated by the heart. Due to its rapid, non-invasive, and richly informative characteristics, ECG has many emerging applications. In this paper, we study novel deep learning technologies to effectively manage and analyse ECG data, with the aim of building a diagnostic model, accurately and quickly, that can substantially reduce the burden on medical workers. Unlike the existing ECG models that exhibit a high misdiagnosis rate, our deep learning approaches can automatically extract the features of ECG data through end-to-end training. Specifically, we first devise EfficientECG, an accurate and lightweight classification model for ECG analysis based on the existing EfficientNet model, which can effectively handle high-frequency long-sequence ECG data with various leading types. On top of that, we next propose a cross-attention-based feature fusion model of EfficientECG for analysing multi-lead ECG data with multiple features (e.g., gender and age). Our evaluations on representative ECG datasets validate the superiority of our model against state-of-the-art works in terms of high precision, multi-feature fusion, and lightweights.

</details>


### [150] [Deep Reinforcement Learning for Dynamic Algorithm Configuration: A Case Study on Optimizing OneMax with the (1+($λ$,$λ$))-GA](https://arxiv.org/abs/2512.03805)
*Tai Nguyen,Phong Le,André Biedenkapp,Carola Doerr,Nguyen Dang*

Main category: cs.LG

TL;DR: 本文系统研究了深度强化学习在动态算法配置中的应用，针对(1+(λ,λ))-GA算法在OneMax问题上的种群大小参数控制，揭示了DDQN和PPO面临的扩展性下降和学习不稳定性问题，并提出自适应奖励偏移机制解决探索不足问题。


<details>
  <summary>Details</summary>
Motivation: 强化学习在动态算法配置中面临挑战，需要大量领域专业知识。本文旨在通过系统研究深度强化学习算法在DAC中的应用，识别并解决关键问题，提高算法配置的效率和效果。

Method: 使用DDQN和PPO两种深度强化学习算法控制(1+(λ,λ))-GA的种群大小参数，分析其性能瓶颈。针对探索不足问题提出自适应奖励偏移机制，利用奖励分布统计增强探索；针对规划视野覆盖问题采用无折扣学习策略。

Result: 发现DDQN和PPO存在扩展性下降和学习不稳定性问题，主要源于探索不足和规划视野覆盖。自适应奖励偏移机制有效解决了探索问题，无需实例特定超参数调优。DDQN配合该策略达到与理论推导策略相当的性能，样本效率提升数个数量级。

Conclusion: 深度强化学习在动态算法配置中面临探索不足和规划视野覆盖两大挑战。自适应奖励偏移机制能有效增强探索，DDQN配合该策略在DAC中表现出色，而PPO存在根本性方差问题需要替代算法设计。

Abstract: Dynamic Algorithm Configuration (DAC) studies the efficient identification of control policies for parameterized optimization algorithms. Numerous studies have leveraged the robustness of decision-making in Reinforcement Learning (RL) to address the optimization challenges in algorithm configuration. However, applying RL to DAC is challenging and often requires extensive domain expertise. We conduct a comprehensive study of deep-RL algorithms in DAC through a systematic analysis of controlling the population size parameter of the (1+($λ$,$λ$))-GA on OneMax instances. Our investigation of DDQN and PPO reveals two fundamental challenges that limit their effectiveness in DAC: scalability degradation and learning instability. We trace these issues to two primary causes: under-exploration and planning horizon coverage, each of which can be effectively addressed through targeted solutions. To address under-exploration, we introduce an adaptive reward shifting mechanism that leverages reward distribution statistics to enhance DDQN agent exploration, eliminating the need for instance-specific hyperparameter tuning and ensuring consistent effectiveness across different problem scales. In dealing with the planning horizon coverage problem, we demonstrate that undiscounted learning effectively resolves it in DDQN, while PPO faces fundamental variance issues that necessitate alternative algorithmic designs. We further analyze the hyperparameter dependencies of PPO, showing that while hyperparameter optimization enhances learning stability, it consistently falls short in identifying effective policies across various configurations. Finally, we demonstrate that DDQN equipped with our adaptive reward shifting strategy achieves performance comparable to theoretically derived policies with vastly improved sample efficiency, outperforming prior DAC approaches by several orders of magnitude.

</details>


### [151] [Log Probability Tracking of LLM APIs](https://arxiv.org/abs/2512.03816)
*Timothée Chauvin,Erwan Le Merrer,François Taïani,Gilles Tredan*

Main category: cs.LG

TL;DR: 提出一种基于logprobs的廉价LLM API监控方法，只需单个token输出即可检测微小模型变化，比现有方法敏感1000倍


<details>
  <summary>Details</summary>
Motivation: LLM API用户期望模型保持一致性，这对下游应用可靠性和研究可复现性至关重要。现有审计方法成本过高，无法定期应用于广泛的LLM API，导致模型更新在实践中基本未被监控。

Method: 利用LLM log probabilities（logprobs）作为基础，提出基于每个token logprob平均值的简单统计测试，只需请求单个token输出。这种方法成本极低但能检测微小变化。

Result: 该方法能检测小至一次微调步骤的模型变化，比现有方法更敏感，同时成本降低1000倍。作者还引入了TinyChange基准来衡量审计方法对小而现实的模型变化的敏感性。

Conclusion: 基于logprobs的简单统计测试提供了一种成本效益高的连续监控LLM API的方法，解决了现有审计方法成本过高的问题，能够有效检测微小模型变化。

Abstract: When using an LLM through an API provider, users expect the served model to remain consistent over time, a property crucial for the reliability of downstream applications and the reproducibility of research. Existing audit methods are too costly to apply at regular time intervals to the wide range of available LLM APIs. This means that model updates are left largely unmonitored in practice. In this work, we show that while LLM log probabilities (logprobs) are usually non-deterministic, they can still be used as the basis for cost-effective continuous monitoring of LLM APIs. We apply a simple statistical test based on the average value of each token logprob, requesting only a single token of output. This is enough to detect changes as small as one step of fine-tuning, making this approach more sensitive than existing methods while being 1,000x cheaper. We introduce the TinyChange benchmark as a way to measure the sensitivity of audit methods in the context of small, realistic model changes.

</details>


### [152] [Transmit Weights, Not Features: Orthogonal-Basis Aided Wireless Point-Cloud Transmission](https://arxiv.org/abs/2512.03819)
*Junlin Chang,Yubo Han,Hnag Yue,John S Thompson,Rongke Liu*

Main category: cs.LG

TL;DR: 提出基于深度联合信源信道编码的语义无线传输框架，通过预测接收端语义正交特征池的组合权重实现紧凑表示，使用折叠式解码器从2D网格变形为3D点云，在带宽受限场景下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着深度传感器的普及，点云获取门槛降低，但传统点云传输方法在带宽受限环境下效率不高。需要开发能够适应不同信道条件的语义感知传输方案，在有限带宽下保持几何保真度。

Method: 1) 基于DeepJSCC的语义无线传输框架；2) 发送端预测接收端语义正交特征池的组合权重而非原始特征；3) 使用折叠式解码器将2D网格变形为3D点云；4) 采用Chamfer距离和正交正则化进行训练。

Result: 在ModelNet40数据集上测试，高带宽时性能与SEPT相当，带宽受限时明显优于SEPT，在PSNR和CD指标上均有持续改进。消融实验证实正交化和折叠先验的有效性。

Conclusion: 提出的语义无线传输框架通过正交特征池和折叠解码器，在保持几何保真度的同时实现紧凑表示，特别适用于带宽受限的点云传输场景，为3D点云的高效语义通信提供了新思路。

Abstract: The widespread adoption of depth sensors has substantially lowered the barrier to point-cloud acquisition. This letter proposes a semantic wireless transmission framework for three dimension (3D) point clouds built on Deep Joint Source - Channel Coding (DeepJSCC). Instead of sending raw features, the transmitter predicts combination weights over a receiver-side semantic orthogonal feature pool, enabling compact representations and robust reconstruction. A folding-based decoder deforms a 2D grid into 3D, enforcing manifold continuity while preserving geometric fidelity. Trained with Chamfer Distance (CD) and an orthogonality regularizer, the system is evaluated on ModelNet40 across varying Signal-to-Noise Ratios (SNRs) and bandwidths. Results show performance on par with SEmantic Point cloud Transmission (SEPT) at high bandwidth and clear gains in bandwidth-constrained regimes, with consistent improvements in both Peak Signal-to-Noise Ratio (PSNR) and CD. Ablation experiments confirm the benefits of orthogonalization and the folding prior.

</details>


### [153] [Automatic Attack Discovery for Few-Shot Class-Incremental Learning via Large Language Models](https://arxiv.org/abs/2512.03882)
*Haidong Kang,Wei Wu,Hanling Wang*

Main category: cs.LG

TL;DR: 本文提出ACraft方法，利用大语言模型自动生成针对少样本类增量学习（FSCIL）的对抗攻击方法，无需人工专家参与，显著降低攻击成本并超越传统攻击效果。


<details>
  <summary>Details</summary>
Motivation: FSCIL作为持续学习中更具现实性和挑战性的范式，现有研究主要关注提升FSCIL方法效果，而忽视了其安全性问题。传统人工设计的攻击方法（如PGD、FGSM）要么无法有效攻击基础类，要么依赖大量专家知识导致成本高昂，因此需要专门针对FSCIL的攻击方法。

Method: 提出ACraft方法：1）利用大语言模型自动引导和发现针对FSCIL的最优攻击方法，无需人工专家；2）引入基于近端策略优化（PPO）的强化学习来优化学习过程，通过建立正反馈机制使LLM在下一代生成更好的攻击方法。

Result: 在主流的基准测试中，ACraft方法显著降低了最先进FSCIL方法的性能，大幅超越了人工专家设计的攻击方法，同时保持了最低的攻击成本。

Conclusion: 本文首次系统研究了FSCIL中的攻击问题，提出的ACraft方法通过结合LLM和强化学习，实现了对FSCIL的有效攻击，为FSCIL的安全性研究提供了新的视角和方法。

Abstract: Few-shot class incremental learning (FSCIL) is a more realistic and challenging paradigm in continual learning to incrementally learn unseen classes and overcome catastrophic forgetting on base classes with only a few training examples. Previous efforts have primarily centered around studying more effective FSCIL approaches. By contrast, less attention was devoted to thinking the security issues in contributing to FSCIL. This paper aims to provide a holistic study of the impact of attacks on FSCIL. We first derive insights by systematically exploring how human expert-designed attack methods (i.e., PGD, FGSM) affect FSCIL. We find that those methods either fail to attack base classes, or suffer from huge labor costs due to relying on huge expert knowledge. This highlights the need to craft a specialized attack method for FSCIL. Grounded in these insights, in this paper, we propose a simple yet effective ACraft method to automatically steer and discover optimal attack methods targeted at FSCIL by leveraging Large Language Models (LLMs) without human experts. Moreover, to improve the reasoning between LLMs and FSCIL, we introduce a novel Proximal Policy Optimization (PPO) based reinforcement learning to optimize learning, making LLMs generate better attack methods in the next generation by establishing positive feedback. Experiments on mainstream benchmarks show that our ACraft significantly degrades the performance of state-of-the-art FSCIL methods and dramatically beyond human expert-designed attack methods while maintaining the lowest costs of attack.

</details>


### [154] [Probabilistic Foundations of Fuzzy Simplicial Sets for Nonlinear Dimensionality Reduction](https://arxiv.org/abs/2512.03899)
*Janis Keck,Lukas Silvester Barth,Fatemeh,Fahimi,Parvaneh Joharinad,Jürgen Jost*

Main category: cs.LG

TL;DR: 该论文为模糊单纯形集提供了一个概率论框架，解释UMAP中的模糊权重来自生成模型，并展示了如何基于此框架推导新的降维方法。


<details>
  <summary>Details</summary>
Motivation: 模糊单纯形集在降维和流形学习中很重要（如UMAP），但其代数拓扑定义缺乏清晰的概率解释，脱离了这些领域常用的理论框架。

Method: 引入一个框架，将模糊单纯形集解释为单纯形集上概率测度的边际。具体展示了UMAP的模糊权重来自随机尺度上采样Vietoris-Rips滤液的生成模型，并连接了模糊单纯形集与面偏序集上的概率模型。

Result: 该框架为模糊单纯形集提供了统一的概率理论基础，阐明了UMAP在此框架中的角色，并能够系统推导新的降维方法（如使用Čech滤液和三元组采样的UMAP推广）。

Conclusion: 概率视角为模糊单纯形集提供了坚实的理论基础，澄清了UMAP的数学基础，并开启了基于此框架设计新降维方法的可能性。

Abstract: Fuzzy simplicial sets have become an object of interest in dimensionality reduction and manifold learning, most prominently through their role in UMAP. However, their definition through tools from algebraic topology without a clear probabilistic interpretation detaches them from commonly used theoretical frameworks in those areas. In this work we introduce a framework that explains fuzzy simplicial sets as marginals of probability measures on simplicial sets. In particular, this perspective shows that the fuzzy weights of UMAP arise from a generative model that samples Vietoris-Rips filtrations at random scales, yielding cumulative distribution functions of pairwise distances. More generally, the framework connects fuzzy simplicial sets to probabilistic models on the face poset, clarifies the relation between Kullback-Leibler divergence and fuzzy cross-entropy in this setting, and recovers standard t-norms and t-conorms via Boolean operations on the underlying simplicial sets. We then show how new embedding methods may be derived from this framework and illustrate this on an example where we generalize UMAP using Čech filtrations with triplet sampling. In summary, this probabilistic viewpoint provides a unified probabilistic theoretical foundation for fuzzy simplicial sets, clarifies the role of UMAP within this framework, and enables the systematic derivation of new dimensionality reduction methods.

</details>


### [155] [Quantum-Classical Physics-Informed Neural Networks for Solving Reservoir Seepage Equations](https://arxiv.org/abs/2512.03923)
*Xiang Rao,Yina Liu,Yuxuan Shen*

Main category: cs.LG

TL;DR: 提出了一种离散变量电路量子-经典物理信息神经网络（DV-QCPINN），首次应用于三种典型油藏渗流模型，相比传统PINNs具有更高的参数效率和更强的非线性拟合能力。


<details>
  <summary>Details</summary>
Motivation: 传统数值方法存在网格依赖误差和计算成本高的问题，而经典物理信息神经网络（PINNs）在参数效率、高维表达和强非线性拟合方面存在瓶颈。需要开发更高效的求解方法来解决油藏渗流偏微分方程。

Method: 提出DV-QCPINN，将经典预处理/后处理网络与离散变量量子核心集成，利用量子叠加和纠缠增强高维特征映射，同时嵌入物理约束确保解的一致性。测试了三种量子电路拓扑结构（级联、交叉网格、交替）。

Result: QCPINNs相比经典PINNs以更少的参数实现了高预测精度。交替拓扑在非均质单相流和两相BL方程模拟中表现最佳，级联拓扑在对流-弥散-吸附耦合的组分流中表现最优。

Conclusion: 验证了QCPINN在油藏工程应用中的可行性，弥合了量子计算研究与油气工程工业实践之间的差距。

Abstract: Solving partial differential equations (PDEs) for reservoir seepage is critical for optimizing oil and gas field development and predicting production performance. Traditional numerical methods suffer from mesh-dependent errors and high computational costs, while classical Physics-Informed Neural Networks (PINNs) face bottlenecks in parameter efficiency, high-dimensional expression, and strong nonlinear fitting. To address these limitations, we propose a Discrete Variable (DV)-Circuit Quantum-Classical Physics-Informed Neural Network (QCPINN) and apply it to three typical reservoir seepage models for the first time: the pressure diffusion equation for heterogeneous single-phase flow, the nonlinear Buckley-Leverett (BL) equation for two-phase waterflooding, and the convection-diffusion equation for compositional flow considering adsorption. The QCPINN integrates classical preprocessing/postprocessing networks with a DV quantum core, leveraging quantum superposition and entanglement to enhance high-dimensional feature mapping while embedding physical constraints to ensure solution consistency. We test three quantum circuit topologies (Cascade, Cross-mesh, Alternate) and demonstrate through numerical experiments that QCPINNs achieve high prediction accuracy with fewer parameters than classical PINNs. Specifically, the Alternate topology outperforms others in heterogeneous single-phase flow and two-phase BL equation simulations, while the Cascade topology excels in compositional flow with convection-dispersion-adsorption coupling. Our work verifies the feasibility of QCPINN for reservoir engineering applications, bridging the gap between quantum computing research and industrial practice in oil and gas engineering.

</details>


### [156] [Density-Informed VAE (DiVAE): Reliable Log-Prior Probability via Density Alignment Regularization](https://arxiv.org/abs/2512.03928)
*Michele Alessi,Alessio Ansuini,Alex Rodriguez*

Main category: cs.LG

TL;DR: DiVAE是一种轻量级VAE正则化器，通过将VAE先验概率与数据估计的密度对齐，改善潜在空间与数据空间的结构匹配。


<details>
  <summary>Details</summary>
Motivation: 传统VAE将潜在变量匹配到简单先验分布，忽略了数据空间中的密度结构，导致潜在空间与数据空间结构不匹配。

Method: 提出DiVAE，通过添加鲁棒的、精度加权的惩罚项到ELBO中，使编码器根据数据空间密度分配后验质量，并推动可学习先验向高密度区域靠拢。

Result: 在合成数据集上，DiVAE改善了潜在对数密度与真实分布的匹配、提高了先验覆盖度、增强了OOD不确定性校准。在MNIST上，改善了先验与外部密度估计的对齐，提高了可解释性和OOD检测性能。

Conclusion: DiVAE是一种计算开销可忽略的轻量级正则化方法，能有效改善VAE中潜在空间与数据空间的结构对齐，提升模型的可解释性和OOD检测能力。

Abstract: We introduce Density-Informed VAE (DiVAE), a lightweight, data-driven regularizer that aligns the VAE log-prior probability $\log p_Z(z)$ with a log-density estimated from data. Standard VAEs match latents to a simple prior, overlooking density structure in the data-space. DiVAE encourages the encoder to allocate posterior mass in proportion to data-space density and, when the prior is learnable, nudges the prior toward high-density regions. This is realized by adding a robust, precision-weighted penalty to the ELBO, incurring negligible computational overhead. On synthetic datasets, DiVAE (i) improves distributional alignment of latent log-densities to its ground truth counterpart, (ii) improves prior coverage, and (iii) yields better OOD uncertainty calibration. On MNIST, DiVAE improves alignment of the prior with external estimates of the density, providing better interpretability, and improves OOD detection for learnable priors.

</details>


### [157] [Technical Report on Text Dataset Distillation](https://arxiv.org/abs/2512.03967)
*Keith Ando Ogawa,Bruno Lopes Yamamoto,Lucas Lauton de Alcantara,Victor Zacarias,Edson Bollis,Lucas Pellicer,Rosimeire Pereira Costa,Anna Helena Reali Costa,Artur Jordao*

Main category: cs.LG

TL;DR: 本文综述了文本数据集蒸馏领域的发展历程，从最初借鉴视觉领域方法到形成独立研究方向，涵盖了基于Transformer的方法、离散文本生成、大规模模型扩展等关键里程碑，并指出了该领域在基准标准化、处理文本离散性、复杂任务处理和应用实例等方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 文本数据集蒸馏领域虽然已有一定发展，但相比视觉领域的丰富文献仍显不足。该领域从最初借鉴视觉方法逐渐发展为独立分支，面临文本模态的特殊性挑战，需要系统梳理发展历程、总结关键方法、明确当前挑战，以推动该领域的进一步发展。

Method: 采用文献综述方法，系统回顾文本数据集蒸馏领域的历史和最新进展。重点关注不同的蒸馏策略，包括基于Transformer模型的方法、离散合成文本生成技术、面向超过10亿参数解码器模型的扩展方法等，并对各种方法进行对比分析。

Result: 识别了文本数据集蒸馏发展的多个里程碑：1）引入Transformer模型的方法；2）生成离散合成文本的技术；3）扩展到超过10亿参数的仅解码器模型。同时总结了该领域的主要挑战：基准标准化不足、文本离散性处理困难、复杂任务处理能力有限、缺乏实际应用案例等。

Conclusion: 文本数据集蒸馏领域正处于成熟阶段，虽然取得了显著进展，但仍面临诸多挑战。未来需要在基准标准化、克服文本离散性、处理复杂任务、提供实际应用案例等方面进行改进，以推动该领域的进一步发展。

Abstract: In the vision domain, dataset distillation arises as a technique to condense a large dataset into a smaller synthetic one that exhibits a similar result in the training process. While image data presents an extensive literature of distillation methods, text dataset distillation has fewer works in comparison. Text dataset distillation initially grew as an adaptation of efforts from the vision universe, as the particularities of the modality became clear obstacles, it rose into a separate branch of research. Several milestones mark the development of this area, such as the introduction of methods that use transformer models, the generation of discrete synthetic text, and the scaling to decoder-only models with over 1B parameters. Despite major advances in modern approaches, the field remains in a maturing phase, with room for improvement on benchmarking standardization, approaches to overcome the discrete nature of text, handling complex tasks, and providing explicit examples of real-world applications. In this report, we review past and recent advances in dataset distillation for text, highlighting different distillation strategies, key contributions, and general challenges.

</details>


### [158] [Training-Free Policy Violation Detection via Activation-Space Whitening in LLMs](https://arxiv.org/abs/2512.03994)
*Oren Rachmil,Roy Betser,Itay Gershon,Omer Hofman,Nitay Yakoby,Yuval Meron,Idan Yankelev,Asaf Shabtai,Yuval Elovici,Roman Vainshtein*

Main category: cs.LG

TL;DR: 提出一种无需训练的高效方法，将政策违规检测视为分布外检测问题，通过白化技术处理隐藏激活，使用欧几里得范数作为合规分数，在政策基准上达到SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在敏感领域（法律、金融、医疗）的部署，组织需要可靠机制检测内部政策违规，现有方法（护栏、LLM-as-a-judge、微调）存在延迟高、可解释性差、鲁棒性不足等问题。

Method: 将政策违规检测视为OOD检测问题，采用白化技术对模型隐藏激活进行线性变换（去相关、标准化），在变换空间中使用欧几里得范数作为合规分数，仅需政策文本和少量示例样本。

Result: 在具有挑战性的政策基准上取得最先进结果，超越现有护栏和微调推理模型，方法轻量、易于部署。

Conclusion: 为组织提供了实用且统计基础的政策感知监督框架，推进可部署AI治理的广泛目标，代码已开源。

Abstract: Aligning proprietary large language models (LLMs) with internal organizational policies has become an urgent priority as organizations increasingly deploy LLMs in sensitive domains such as legal support, finance, and medical services. Beyond generic safety filters, enterprises require reliable mechanisms to detect policy violations within their regulatory and operational frameworks, where breaches can trigger legal and reputational risks. Existing content moderation frameworks, such as guardrails, remain largely confined to the safety domain and lack the robustness to capture nuanced organizational policies. LLM-as-a-judge and fine-tuning approaches, though flexible, introduce significant latency and lack interpretability. To address these limitations, we propose a training-free and efficient method that treats policy violation detection as an out-of-distribution (OOD) detection problem. Inspired by whitening techniques, we apply a linear transformation to decorrelate the model's hidden activations and standardize them to zero mean and unit variance, yielding near-identity covariance matrix. In this transformed space, we use the Euclidean norm as a compliance score to detect policy violations. The method requires only the policy text and a small number of illustrative samples, which makes it light-weight and easily deployable. On a challenging policy benchmark, our approach achieves state-of-the-art results, surpassing both existing guardrails and fine-tuned reasoning models. This work provides organizations with a practical and statistically grounded framework for policy-aware oversight of LLMs, advancing the broader goal of deployable AI governance. Code is available at: https://tinyurl.com/policy-violation-detection

</details>


### [159] [Physics-Embedded Gaussian Process for Traffic State Estimation](https://arxiv.org/abs/2512.04004)
*Yanlin Chen,Kehua Chen,Yinhai Wang*

Main category: cs.LG

TL;DR: 提出PEGP框架，通过设计基于经典交通流模型的多输出核函数，将物理知识嵌入高斯过程，解决稀疏观测下的交通状态估计问题


<details>
  <summary>Details</summary>
Motivation: 传统数据驱动方法在稀疏观测下缺乏物理解释和泛化能力，而物理模型难以整合不确定性和捕捉真实交通复杂性。现有结合方法依赖惩罚调参且缺乏不确定性校准，对模型误设敏感

Method: 提出物理嵌入高斯过程(PEGP)，设计两种基于经典交通流模型(LWR和ARZ)的多输出核函数，通过线性化微分算子的显式应用构建，将物理结构作为硬约束而非软约束

Result: 在HighD和NGSIM数据集上实验显示，PEGP相比非物理基线有持续改进。PEGP-ARZ在稀疏观测下更可靠，PEGP-LWR在密集观测下误差更低。消融研究表明PEGP-ARZ残差与物理更一致且不确定性可解释

Conclusion: PEGP框架成功结合物理先验和不确定性量化，为交通状态估计提供可靠支持，解决了现有方法对惩罚调参的依赖和不确定性校准不足的问题

Abstract: Traffic state estimation (TSE) becomes challenging when probe-vehicle penetration is low and observations are spatially sparse. Pure data-driven methods lack physical explanations and have poor generalization when observed data is sparse. In contrast, physical models have difficulty integrating uncertainties and capturing the real complexity of traffic. To bridge this gap, recent studies have explored combining them by embedding physical structure into Gaussian process. These approaches typically introduce the governing equations as soft constraints through pseudo-observations, enabling the integration of model structure within a variational framework. However, these methods rely heavily on penalty tuning and lack principled uncertainty calibration, which makes them sensitive to model mis-specification. In this work, we address these limitations by presenting a novel Physics-Embedded Gaussian Process (PEGP), designed to integrate domain knowledge with data-driven methods in traffic state estimation. Specifically, we design two multi-output kernels informed by classic traffic flow models, constructed via the explicit application of the linearized differential operator. Experiments on HighD, NGSIM show consistent improvements over non-physics baselines. PEGP-ARZ proves more reliable under sparse observation, while PEGP-LWR achieves lower errors with denser observation. Ablation study further reveals that PEGP-ARZ residuals align closely with physics and yield calibrated, interpretable uncertainty, whereas PEGP-LWR residuals are more orthogonal and produce nearly constant variance fields. This PEGP framework combines physical priors, uncertainty quantification, which can provide reliable support for TSE.

</details>


### [160] [Diagonalizing the Softmax: Hadamard Initialization for Tractable Cross-Entropy Dynamics](https://arxiv.org/abs/2512.04006)
*Connall Garrod,Jonathan P. Keating,Christos Thrampoulidis*

Main category: cs.LG

TL;DR: 该论文首次证明了在交叉熵损失下，梯度流会收敛到神经坍缩几何结构，通过分析两层线性神经网络，构建了显式Lyapunov函数来证明全局收敛性。


<details>
  <summary>Details</summary>
Motivation: 现有理论通常将交叉熵损失简化为平方损失或限制在凸模型，无法捕捉真实训练动态。交叉熵和平方损失产生根本不同的动态，凸线性模型无法捕捉非凸优化的复杂性。

Method: 分析具有标准基向量输入的两层线性神经网络（最简单的非凸扩展），构建显式Lyapunov函数证明全局收敛。关键发现：Hadamard初始化对角化softmax算子，冻结权重矩阵的奇异向量，将动态完全简化为奇异值。

Result: 首次证明了在交叉熵损失下，梯度流收敛到神经坍缩几何结构，尽管存在虚假临界点，但通过Lyapunov函数确保了全局收敛。

Conclusion: 该工作为分析交叉熵训练动态开辟了新途径，Hadamard初始化技术可用于分析更广泛场景下的CE训练动态，超越了当前特定设置。

Abstract: Cross-entropy (CE) training loss dominates deep learning practice, yet existing theory often relies on simplifications, either replacing it with squared loss or restricting to convex models, that miss essential behavior. CE and squared loss generate fundamentally different dynamics, and convex linear models cannot capture the complexities of non-convex optimization. We provide an in-depth characterization of multi-class CE optimization dynamics beyond the convex regime by analyzing a canonical two-layer linear neural network with standard-basis vectors as inputs: the simplest non-convex extension for which the implicit bias remained unknown. This model coincides with the unconstrained features model used to study neural collapse, making our work the first to prove that gradient flow on CE converges to the neural collapse geometry. We construct an explicit Lyapunov function that establishes global convergence, despite the presence of spurious critical points in the non-convex landscape. A key insight underlying our analysis is an inconspicuous finding: Hadamard Initialization diagonalizes the softmax operator, freezing the singular vectors of the weight matrices and reducing the dynamics entirely to their singular values. This technique opens a pathway for analyzing CE training dynamics well beyond our specific setting considered here.

</details>


### [161] [Efficient Public Verification of Private ML via Regularization](https://arxiv.org/abs/2512.04008)
*Zoë Ruha Bell,Anvith Thudi,Olive Franzese-McLaughlin,Nicolas Papernot,Shafi Goldwasser*

Main category: cs.LG

TL;DR: 提出首个差分隐私验证成本低于训练成本的DP-SCO算法，通过序列正则化目标实现最优隐私-效用权衡


<details>
  <summary>Details</summary>
Motivation: 现有差分隐私算法的验证成本与训练成本相同，数据提供者和公众缺乏高效验证DP保证的方法，需要降低验证成本

Method: 通过私有化最小化一系列正则化目标，仅使用标准DP组合边界，实现紧致的隐私-效用权衡

Result: 获得首个具有近最优隐私-效用权衡的DP-SCO算法，其DP验证成本显著低于训练成本，在大数据集上大幅减少验证开销

Conclusion: 该方法为差分隐私验证提供了更高效的解决方案，使数据提供者能够以较低成本验证模型隐私保证

Abstract: Training with differential privacy (DP) provides a guarantee to members in a dataset that they cannot be identified by users of the released model. However, those data providers, and, in general, the public, lack methods to efficiently verify that models trained on their data satisfy DP guarantees. The amount of compute needed to verify DP guarantees for current algorithms scales with the amount of compute required to train the model. In this paper we design the first DP algorithm with near optimal privacy-utility trade-offs but whose DP guarantees can be verified cheaper than training. We focus on DP stochastic convex optimization (DP-SCO), where optimal privacy-utility trade-offs are known. Here we show we can obtain tight privacy-utility trade-offs by privately minimizing a series of regularized objectives and only using the standard DP composition bound. Crucially, this method can be verified with much less compute than training. This leads to the first known DP-SCO algorithm with near optimal privacy-utility whose DP verification scales better than training cost, significantly reducing verification costs on large datasets.

</details>


### [162] [Domain Feature Collapse: Implications for Out-of-Distribution Detection and Solutions](https://arxiv.org/abs/2512.04034)
*Hong Yang,Devroop Kar,Qi Yu,Alex Ororbia,Travis Desell*

Main category: cs.LG

TL;DR: 单域训练导致域特征崩溃，使OOD检测失效；通过信息论证明保留域信息可解决此问题


<details>
  <summary>Details</summary>
Motivation: 解释为何在单域数据集上训练的SOTA OOD检测方法会出现灾难性失败现象

Method: 从信息论角度分析，证明单域监督学习必然导致域特征崩溃(I(x_d; z)=0)，使用Fano不等式量化部分崩溃，并通过Domain Bench基准验证理论

Result: 理论证明单域训练会完全丢弃域特征信息，导致OOD检测失败(如MNIST上FPR@95仅53%)；通过域过滤保留I(x_d; z)>0可解决此问题

Conclusion: 揭示了监督学习在窄域中的根本局限性，解释了OOD检测失败现象，对迁移学习及何时微调/冻结预训练模型有广泛意义

Abstract: Why do state-of-the-art OOD detection methods exhibit catastrophic failure when models are trained on single-domain datasets? We provide the first theoretical explanation for this phenomenon through the lens of information theory. We prove that supervised learning on single-domain data inevitably produces domain feature collapse -- representations where I(x_d; z) = 0, meaning domain-specific information is completely discarded. This is a fundamental consequence of information bottleneck optimization: models trained on single domains (e.g., medical images) learn to rely solely on class-specific features while discarding domain features, leading to catastrophic failure when detecting out-of-domain samples (e.g., achieving only 53% FPR@95 on MNIST). We extend our analysis using Fano's inequality to quantify partial collapse in practical scenarios. To validate our theory, we introduce Domain Bench, a benchmark of single-domain datasets, and demonstrate that preserving I(x_d; z) > 0 through domain filtering (using pretrained representations) resolves the failure mode. While domain filtering itself is conceptually straightforward, its effectiveness provides strong empirical evidence for our information-theoretic framework. Our work explains a puzzling empirical phenomenon, reveals fundamental limitations of supervised learning in narrow domains, and has broader implications for transfer learning and when to fine-tune versus freeze pretrained models.

</details>


### [163] [Convergence for Discrete Parameter Updates](https://arxiv.org/abs/2512.04051)
*Paul Wilson,Fabio Zanasi,George Constantinides*

Main category: cs.LG

TL;DR: 提出一种离散更新规则的量化训练方法，避免传统量化训练中对连续更新的离散化，为具有固有离散结构的模型提供新的高效训练途径。


<details>
  <summary>Details</summary>
Motivation: 现代深度学习模型需要巨大的计算资源，这促使了对低精度训练的研究。传统的量化训练通过用低比特整数表示训练组件来解决这个问题，但通常依赖于对实值更新的离散化。

Method: 引入了一种替代方法，其中更新规则本身是离散的，通过设计避免了连续更新的量化。建立了一类此类离散方案的收敛保证，并提出了多项式更新规则作为具体示例。

Result: 通过经验评估支持了该方法，展示了离散更新规则在量化训练中的有效性。

Conclusion: 这种离散更新视角为高效训练开辟了新途径，特别是对于具有固有离散结构的模型。

Abstract: Modern deep learning models require immense computational resources, motivating research into low-precision training. Quantised training addresses this by representing training components in low-bit integers, but typically relies on discretising real-valued updates. We introduce an alternative approach where the update rule itself is discrete, avoiding the quantisation of continuous updates by design. We establish convergence guarantees for a general class of such discrete schemes, and present a multinomial update rule as a concrete example, supported by empirical evaluation. This perspective opens new avenues for efficient training, particularly for models with inherently discrete structure.

</details>


### [164] [Eval Factsheets: A Structured Framework for Documenting AI Evaluations](https://arxiv.org/abs/2512.04062)
*Florian Bordes,Candace Ross,Justine T Kao,Evangelia Spiliopoulou,Adina Williams*

Main category: cs.LG

TL;DR: Eval Factsheets：为AI系统评估方法设计的结构化文档框架，包含五个维度的分类法和问卷，旨在提高评估的透明度、可复现性和可比性。


<details>
  <summary>Details</summary>
Motivation: 当前AI领域基准测试激增，但评估方法缺乏系统化的文档标准，而数据集和模型已有Datasheets和Model Cards等框架。这导致可复现性、透明度和决策制定方面的挑战。

Method: 提出Eval Factsheets框架，通过五个核心维度（Context、Scope、Structure、Method、Alignment）构建评估特征分类法，并实现为包含强制和推荐元素的实用问卷。

Result: 通过多个基准测试的案例研究证明，Eval Factsheets能有效捕捉从传统基准到LLM-as-judge等多种评估范式，同时保持一致性和可比性。

Conclusion: 希望Eval Factsheets能被纳入现有和新的评估框架中，从而提高评估的透明度和可复现性。

Abstract: The rapid proliferation of benchmarks has created significant challenges in reproducibility, transparency, and informed decision-making. However, unlike datasets and models -- which benefit from structured documentation frameworks like Datasheets and Model Cards -- evaluation methodologies lack systematic documentation standards. We introduce Eval Factsheets, a structured, descriptive framework for documenting AI system evaluations through a comprehensive taxonomy and questionnaire-based approach. Our framework organizes evaluation characteristics across five fundamental dimensions: Context (Who made the evaluation and when?), Scope (What does it evaluate?), Structure (With what the evaluation is built?), Method (How does it work?) and Alignment (In what ways is it reliable/valid/robust?). We implement this taxonomy as a practical questionnaire spanning five sections with mandatory and recommended documentation elements. Through case studies on multiple benchmarks, we demonstrate that Eval Factsheets effectively captures diverse evaluation paradigms -- from traditional benchmarks to LLM-as-judge methodologies -- while maintaining consistency and comparability. We hope Eval Factsheets are incorporated into both existing and newly released evaluation frameworks and lead to more transparency and reproducibility.

</details>


### [165] [Learning Steerable Clarification Policies with Collaborative Self-play](https://arxiv.org/abs/2512.04068)
*Jonathan Berant,Maximillian Chen,Adam Fisch,Reza Aghajani,Fantine Huot,Mirella Lapata,Jacob Eisenstein*

Main category: cs.LG

TL;DR: 训练可调控的对话策略来处理模糊查询，通过自博弈学习在猜测意图、枚举可能性和提问澄清之间做出最优决策，策略可根据不同成本设置进行调整。


<details>
  <summary>Details</summary>
Motivation: AI助手处理模糊查询时需要智能的决策策略，但现有方法缺乏对上下文因素（如用户偏好、设备模态）的适应性。例如，在小屏幕或语音场景中枚举多个意图会显得笨拙，需要一种可根据不同成本条件灵活调整的策略。

Method: 采用自博弈训练方法，让两个智能体分别模拟用户和AI助手进行对话。用户发出可能模糊的查询，助手需要决定如何回应。模型以澄清问题成本和生成词成本作为输入，通过强化自训练（ReST）优化最终奖励（成本惩罚后的准确率），学习最大化奖励的决策策略。

Result: 训练出的策略可根据提供的成本预测性地调整行为，实现更高的奖励和准确率。更重要的是，该方法能泛化到训练时未观察到的成本数值，展现了良好的泛化能力。

Conclusion: 通过自博弈和强化自训练，成功开发出可调控的对话不确定性管理策略，能够根据上下文成本条件灵活选择最佳回应方式，并在未见过的成本设置上保持良好性能。

Abstract: To handle underspecified or ambiguous queries, AI assistants need a policy for managing their uncertainty to determine (a) when to guess the user intent and answer directly, (b) when to enumerate and answer multiple possible intents, and (c) when to ask a clarifying question. However, such policies are contextually dependent on factors such as user preferences or modality. For example, enumerating multiple possible user intentions is cumbersome on small screens or in a voice setting. In this work, we propose to train steerable policies for managing this uncertainty using self-play. Given two agents, one simulating a user and the other an AI assistant, we generate conversations where the user issues a potentially ambiguous query, and the assistant needs to determine how to respond. Importantly, the model takes as input the numerical cost of each clarification question, and each generated word, and is asked to take the action that will maximize its final reward, which is the cost-penalized accuracy. We use Reinforced Self-Training (ReST) to train our model to achieve high reward and show this leads to a steerable policy that changes its behavior predictably conditioned on the provided costs, leading to higher reward and accuracy. Moreover, our procedure also generalizes to numerical cost values that were unobserved at training time.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [166] [vop_poc_nz: A Python Framework for Distributional Cost-Effectiveness and Value of Perspective Analysis](https://arxiv.org/abs/2512.03596)
*Dylan A Mordaunt*

Main category: econ.GN

TL;DR: 开发了一个Python包vop_poc_nz，用于实施分布成本效果分析框架，通过"视角价值"指标量化视角选择的不确定性，允许同时评估多个分析视角


<details>
  <summary>Details</summary>
Motivation: 卫生经济评估对分析视角选择敏感，但相关不确定性很少被量化。现有工具将视角视为固定输入，无法评估视角错位的机会成本

Method: 开发vop_poc_nz Python包，实现分布成本效果分析框架，引入"视角价值"指标，提供马尔可夫建模、概率敏感性分析、信息价值分析和公平影响评估工具

Result: 该包能够同时评估多个分析视角，使决策者能够估计视角错位的机会成本，并通过新西兰案例研究展示了其功能

Conclusion: vop_poc_nz包为量化卫生经济评估中的视角不确定性提供了实用工具，有助于改善决策过程，特别是在考虑不同利益相关者视角时

Abstract: Health economic evaluations are sensitive to the choice of analytical perspective (e.g., health system vs. societal). While guidelines often recommend specific perspectives, the uncertainty associated with this choice - and the potential decision discordance it creates - is rarely quantified. We present vop_poc_nz, a Python package that implements a framework for Distributional Cost-Effectiveness Analysis (DCEA) and operationalizes the quantification of perspective uncertainty through the Value of Perspective (VoP) metric. The package provides tools for Markov modeling, probabilistic sensitivity analysis, value of information analysis, and equity impact assessment. Unlike existing tools that treat perspective as a fixed input, vop_poc_nz allows for the simultaneous evaluation of multiple perspectives. This enables decision-makers to estimate the opportunity cost of perspective misalignment. We demonstrate the package's capabilities using case studies from Aotearoa New Zealand.

</details>


### [167] [Is Jobless Growth Valid in Turkiye? A Sectoral Analysis of the Relationship between Unemployment and Economic Growth](https://arxiv.org/abs/2512.03821)
*Emre Akusta*

Main category: econ.GN

TL;DR: 该研究分析了土耳其是否存在无就业增长现象，发现所有部门的增长都能减少失业，其中服务业部门对降低失业率的影响最大，短期和长期都显示经济增长对降低失业有重要作用。


<details>
  <summary>Details</summary>
Motivation: 研究旨在验证土耳其是否存在"无就业增长"现象，即经济增长是否未能创造就业机会。通过分析不同部门对失业的影响，为土耳其的就业政策提供实证依据。

Method: 使用2000-2022年的年度数据，采用ARDL（自回归分布滞后）方法分析农业、工业、建筑和服务业部门对失业的影响，并用FMOLS和CCR方法进行稳健性检验。

Result: 所有部门的增长都能显著降低失业率。短期影响：农业部门GDP占比每增加1单位，失业率下降0.471点；工业0.680点；建筑业0.899点；服务业1.383点。长期影响更强：农业2.380点；工业4.057点；建筑业1.761点；服务业3.664点。

Conclusion: 土耳其不存在无就业增长现象，相反，经济增长在减少失业方面发挥着重要作用。服务业部门对降低失业率的影响最大，且长期效应比短期效应更强。

Abstract: This study analyzes the validity of jobless growth in Turkiye on sectoral basis. It analyzes the impacts of agriculture, industry, construction and services sectors on unemployment using annual data for the period 2000-2022. ARDL method is applied within the scope of the analysis. The findings are tested with FMOLS and CCR methods. The results show that growth in all sectors reduces the unemployment. A one-unit increase in the share of agriculture sector in GDP decreases the unemployment rate by 0.471 points, 0.680 points in the industrial sector, 0.899 points in the construction sector and 1.383 points in the services sector in the short-run. The long-run coefficients reveal that the impacts of sectoral growth on unemployment are stronger in the long-run than in the short-run. A one unit increase in the share of the agricultural sector in GDP decreases the unemployment rate by 2.380 points, 4.057 points in the industrial sector, 1.761 points in the construction sector and 3.664 points in the services sector in the long-run. These findings show that jobless growth is not valid in Turkiye in general. On the contrary, economic growth plays an important role in reducing unemployment.

</details>


### [168] [Does Globalization Promote or Hinder Sustainable Development? Evidence from Turkiye on the Three Dimensions of Globalization](https://arxiv.org/abs/2512.03822)
*Emre Akusta*

Main category: econ.GN

TL;DR: 使用ARDL方法分析2000-2021年土耳其全球化对可持续发展的影响，发现经济、政治和总体全球化对可持续发展有积极影响，社会全球化短期负向但长期转为正向。


<details>
  <summary>Details</summary>
Motivation: 研究全球化对土耳其可持续发展的影响，分析不同维度全球化（经济、社会、政治）的短期和长期效应，为政策制定提供实证依据。

Method: 采用ARDL（自回归分布滞后）方法，使用2000-2021年的年度数据，分析全球化各维度对可持续发展的影响。

Result: 经济全球化短期系数0.144、长期0.153；社会全球化短期-0.150、长期0.080；政治全球化短期0.254、长期2.634；总体全球化短期0.339、长期0.196，均对可持续发展有正向影响。

Conclusion: 全球化总体上促进土耳其可持续发展，特别是政治全球化长期效应显著，社会全球化需要时间才能发挥积极作用，政策应关注全球化各维度的协调推进。

Abstract: This study analyzes the impact of globalization on sustainable development in Turkiye. We used the ARDL method with annual data for the period 2000-2021. Results reveal that economic globalization promotes positively to sustainable development in the short run with a coefficient of 0.144 and in the long run with a 0.153 coefficient. Although social globalization has a negative impact with a coefficient of -0.150 in the short run, this effect turns positive with a coefficient of 0.080 in the long run. Political globalization strongly supports sustainable development with a coefficient of 0.254 in the short run and 2.634 in the long run. Finally, total globalization has a positive impact on sustainable development in the short and long run with coefficients of 0.339 and 0.196, respectively.

</details>


### [169] [Equalizer or amplifier? How AI may reshape human cognitive differences](https://arxiv.org/abs/2512.03902)
*Maria Bigoni,Andrea Ichino,Aldo Rustichini,Giulio Zanella*

Main category: econ.GN

TL;DR: AI可能缩小或扩大认知能力差距，早期研究表明生成式AI对低技能工作者生产力提升更大，教育系统面临是否允许学生使用AI的紧迫决策


<details>
  <summary>Details</summary>
Motivation: 探讨AI作为认知能力均衡器还是放大器的影响，特别是对教育系统的意义，因为雇主越来越看重有效利用AI而非独立工作的能力

Method: 基于信息通信技术革命的历史证据和早期生成式AI研究，分析AI对认知能力差距的影响机制

Result: 计算机按教育程度增加了不平等但按认知能力减少了不平等；生成式AI对低技能工作者的生产力提升更大

Conclusion: AI最终是均衡器还是放大器尚不确定，但教育系统需要紧急决定是否允许学生使用AI，因为职场已重视AI应用能力

Abstract: Machines have at times equalized physical strength by substituting for human effort, and at other times amplified these differences. Artificial intelligence (AI) may likewise narrow or widen disparities in cognitive ability. Recent evidence from the Information and Communication Technology (ICT) revolution suggests that computers increased inequality by education but reduced it by cognitive ability. Early research on generative AI shows larger productivity gains for less-skilled than for high-skilled workers. Whether AI ultimately acts as an equalizer or an amplifier of human cognitive differences is especially crucial for education systems, which must decide whether -- and how -- to allow students to use AI in coursework and exams. This decision is urgent because employers value workers who can leverage AI effectively rather than operate independently of it.

</details>


### [170] [Polarization by Design: How Elites Could Shape Mass Preferences as AI Reduces Persuasion Costs](https://arxiv.org/abs/2512.04047)
*Nadav Kunievsky*

Main category: econ.GN

TL;DR: AI驱动的说服技术降低了塑造公众意见的成本，使精英能够战略性地操纵政策偏好分布，导致极化成为治理工具而非社会副产品。


<details>
  <summary>Details</summary>
Motivation: 研究AI说服技术如何改变民主政治中精英塑造公众支持的方式，探讨技术进步对意见分布和民主稳定的影响。

Method: 建立动态模型，分析精英在多数规则约束和说服成本下如何重塑政策偏好分布，考虑单精英和双精英交替执政两种情景。

Result: 单精英情境下，最优干预倾向于推动社会走向更极化的意见分布（"极化拉力"），技术进步加速这一趋势；双精英情境下，技术可能创造"半锁定"区域，使意见更凝聚且难以被对手推翻，技术进步可能加剧或抑制极化。

Conclusion: 廉价的说服技术将极化重塑为治理的战略工具而非纯粹的社会副产品，随着AI能力发展，这对民主稳定具有重要影响。

Abstract: In democracies, major policy decisions typically require some form of majority or consensus, so elites must secure mass support to govern. Historically, elites could shape support only through limited instruments like schooling and mass media; advances in AI-driven persuasion sharply reduce the cost and increase the precision of shaping public opinion, making the distribution of preferences itself an object of deliberate design. We develop a dynamic model in which elites choose how much to reshape the distribution of policy preferences, subject to persuasion costs and a majority rule constraint. With a single elite, any optimal intervention tends to push society toward more polarized opinion profiles - a ``polarization pull'' - and improvements in persuasion technology accelerate this drift. When two opposed elites alternate in power, the same technology also creates incentives to park society in ``semi-lock'' regions where opinions are more cohesive and harder for a rival to overturn, so advances in persuasion can either heighten or dampen polarization depending on the environment. Taken together, cheaper persuasion technologies recast polarization as a strategic instrument of governance rather than a purely emergent social byproduct, with important implications for democratic stability as AI capabilities advance.

</details>
